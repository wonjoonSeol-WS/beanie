{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview Beanie - is an asynchronous Python object-document mapper (ODM) for MongoDB. Data models are based on Pydantic . When using Beanie each database collection has a corresponding Document that is used to interact with that collection. In addition to retrieving data, Beanie allows you to add, update, or delete documents from the collection as well. Beanie saves you time by removing boilerplate code, and it helps you focus on the parts of your app that actually matter. Data and schema migrations are supported by Beanie out of the box. There is a synchronous version of Beanie ODM - Bunnet Installation PIP pip install beanie Poetry poetry add beanie Example import asyncio from typing import Optional from motor.motor_asyncio import AsyncIOMotorClient from pydantic import BaseModel from beanie import Document , Indexed , init_beanie class Category ( BaseModel ): name : str description : str class Product ( Document ): name : str # You can use normal types just like in pydantic description : Optional [ str ] = None price : Indexed ( float ) # You can also specify that a field should correspond to an index category : Category # You can include pydantic models as well # This is an asynchronous example, so we will access it from an async function async def example (): # Beanie uses Motor async client under the hood client = AsyncIOMotorClient ( \"mongodb://user:pass@host:27017\" ) # Initialize beanie with the Product document class await init_beanie ( database = client . db_name , document_models = [ Product ]) chocolate = Category ( name = \"Chocolate\" , description = \"A preparation of roasted and ground cacao seeds.\" ) # Beanie documents work just like pydantic models tonybar = Product ( name = \"Tony's\" , price = 5.95 , category = chocolate ) # And can be inserted into the database await tonybar . insert () # You can find documents with pythonic syntax product = await Product . find_one ( Product . price < 10 ) # And update them await product . set ({ Product . name : \"Gold bar\" }) if __name__ == \"__main__\" : asyncio . run ( example ()) Links Documentation Doc - Tutorial, API documentation, and development guidelines. Example Projects fastapi-cosmos-beanie - FastAPI + Beanie ODM + Azure Cosmos Demo Application by Anthony Shaw fastapi-beanie-jwt - Sample FastAPI server with JWT auth and Beanie ODM by Michael duPont Shortify - URL shortener RESTful API (FastAPI + Beanie ODM + JWT & OAuth2) by Iliya Hosseini Articles Announcing Beanie - MongoDB ODM Build a Cocktail API with Beanie and MongoDB MongoDB indexes with Beanie Beanie Projections. Reducing network and database load. Beanie 1.0 - Query Builder Beanie 1.8 - Relations, Cache, Actions and more! Resources GitHub - GitHub page of the project Changelog - list of all the valuable changes Discord - ask your questions, share ideas or just say Hello!! Supported by JetBrains","title":"Overview"},{"location":"#overview","text":"Beanie - is an asynchronous Python object-document mapper (ODM) for MongoDB. Data models are based on Pydantic . When using Beanie each database collection has a corresponding Document that is used to interact with that collection. In addition to retrieving data, Beanie allows you to add, update, or delete documents from the collection as well. Beanie saves you time by removing boilerplate code, and it helps you focus on the parts of your app that actually matter. Data and schema migrations are supported by Beanie out of the box. There is a synchronous version of Beanie ODM - Bunnet","title":"Overview"},{"location":"#installation","text":"","title":"Installation"},{"location":"#pip","text":"pip install beanie","title":"PIP"},{"location":"#poetry","text":"poetry add beanie","title":"Poetry"},{"location":"#example","text":"import asyncio from typing import Optional from motor.motor_asyncio import AsyncIOMotorClient from pydantic import BaseModel from beanie import Document , Indexed , init_beanie class Category ( BaseModel ): name : str description : str class Product ( Document ): name : str # You can use normal types just like in pydantic description : Optional [ str ] = None price : Indexed ( float ) # You can also specify that a field should correspond to an index category : Category # You can include pydantic models as well # This is an asynchronous example, so we will access it from an async function async def example (): # Beanie uses Motor async client under the hood client = AsyncIOMotorClient ( \"mongodb://user:pass@host:27017\" ) # Initialize beanie with the Product document class await init_beanie ( database = client . db_name , document_models = [ Product ]) chocolate = Category ( name = \"Chocolate\" , description = \"A preparation of roasted and ground cacao seeds.\" ) # Beanie documents work just like pydantic models tonybar = Product ( name = \"Tony's\" , price = 5.95 , category = chocolate ) # And can be inserted into the database await tonybar . insert () # You can find documents with pythonic syntax product = await Product . find_one ( Product . price < 10 ) # And update them await product . set ({ Product . name : \"Gold bar\" }) if __name__ == \"__main__\" : asyncio . run ( example ())","title":"Example"},{"location":"#links","text":"","title":"Links"},{"location":"#documentation","text":"Doc - Tutorial, API documentation, and development guidelines.","title":"Documentation"},{"location":"#example-projects","text":"fastapi-cosmos-beanie - FastAPI + Beanie ODM + Azure Cosmos Demo Application by Anthony Shaw fastapi-beanie-jwt - Sample FastAPI server with JWT auth and Beanie ODM by Michael duPont Shortify - URL shortener RESTful API (FastAPI + Beanie ODM + JWT & OAuth2) by Iliya Hosseini","title":"Example Projects"},{"location":"#articles","text":"Announcing Beanie - MongoDB ODM Build a Cocktail API with Beanie and MongoDB MongoDB indexes with Beanie Beanie Projections. Reducing network and database load. Beanie 1.0 - Query Builder Beanie 1.8 - Relations, Cache, Actions and more!","title":"Articles"},{"location":"#resources","text":"GitHub - GitHub page of the project Changelog - list of all the valuable changes Discord - ask your questions, share ideas or just say Hello!! Supported by JetBrains","title":"Resources"},{"location":"changelog/","text":"Changelog Beanie project 1.16.6 - 2022-12-27 Feature Previous saved state Implementation Author - Paul Renvois\u00e9 PR https://github.com/roman-right/beanie/pull/305 1.16.5 - 2022-12-27 Deprecation Raises exception if Collection inner class was used as it is not supported more Backported to 1.15.5 1.14.1 Implementation PR https://github.com/roman-right/beanie/pull/460 1.16.4 - 2022-12-20 Fix [BUG] Initiating self-referencing documents with nested links breaks due to uncaught request loop Nested lookups for direct links Implementation PR https://github.com/roman-right/beanie/pull/455 1.16.3 - 2022-12-19 Fix [BUG] revision_id field saved in MongoDB using save()/replace() on an existing document even if use_revision is False Implementation PR https://github.com/roman-right/beanie/pull/452 1.16.2 - 2022-12-19 Fix [BUG] find_one projection link [BUG]: Link fields interference/contamination [BUG]: ElemMatch on Document property of Type List[Link] fails with IndexError in relations.py convert_ids() Implementation PR https://github.com/roman-right/beanie/pull/448 1.16.1 - 2022-12-17 Feature Remove yarl dependency Implementation PR https://github.com/roman-right/beanie/pull/448 1.16.0 - 2022-12-17 Feature Support for fetching deep-nested Links Implementation Author - Courtney Sanders PR https://github.com/roman-right/beanie/pull/419 1.16.0b3 - 2022-11-28 Feature Lazy parsing for find many Implementation PR https://github.com/roman-right/beanie/pull/436 1.15.4 - 2022-11-18 Fix Wrong inheritance behavior with non-rooted documents Implementation ISSUE https://github.com/roman-right/beanie/issues/422 1.15.3 - 2022-11-10 Fix Deepcopy dict before encode it to save the original Implementation ISSUE https://github.com/roman-right/beanie/issues/412 1.15.2 - 2022-11-09 Fix Use Settings inner class in migrations internals Fix inheritance: mark root docs with _inheritance_inited = True Implementation PR https://github.com/roman-right/beanie/pull/409 1.15.1 - 2022-11-07 Fix Pass pymongo kwargs to the bulk writer Implementation PR https://github.com/roman-right/beanie/pull/406 1.15.0 - 2022-11-05 Feature The sync version was moved to a separate project Breaking change There is no sync version here more. Please use Bunnet instead Implementation PR https://github.com/roman-right/beanie/pull/395 1.14.0 - 2022-11-04 Feature Multi-model behavior for inherited documents Breaking change The inner class Collection is not supported more. Please, use Settings instead. Implementation Author - Vitaliy Ivanov PR https://github.com/roman-right/beanie/pull/395 1.13.1 - 2022-10-26 Fix Remove redundant async things from sync interface Implementation ISSUE https://github.com/roman-right/beanie/issues/390 1.13.0 - 2022-10-22 Improvement Sync interface Implementation PR https://github.com/roman-right/beanie/pull/386 1.12.1 - 2022-10-17 Improvement Clone interface for query objects Implementation PR https://github.com/roman-right/beanie/pull/378 1.12.0 - 2022-10-06 Improvement Optional list of links field Implementation Author - Alex Deng PR https://github.com/roman-right/beanie/pull/358 1.11.12 - 2022-09-28 Improvement Change before_event, after_event signature to be more pythonic Implementation DISCUSSION https://github.com/roman-right/beanie/discussions/354 1.11.11 - 2022-09-26 Fix Remove prints Implementation ISSUE https://github.com/roman-right/beanie/issues/355/ 1.11.10 - 2022-09-20 Improvement Adding Update Action Implementation Author - schwannden PR https://github.com/roman-right/beanie/pull/291/ 1.11.9 - 2022-08-19 Fix Move set state and swap revision to init to avoid problems with subdocs Issue https://github.com/roman-right/beanie/issues/294 Issue https://github.com/roman-right/beanie/issues/310 1.11.8 - 2022-08-17 Improvement Skip sync parameter for instance updates 1.11.7 - 2022-08-02 Improvement Decimal128 encoding Implementation Author - Teslim Olunlade PR https://github.com/roman-right/beanie/pull/321 1.11.6 - 2022-06-24 Fix Roll back projections fix, as it was valid 1.11.5 - 2022-06-24 Fix Projection fix for aggregations 1.11.4 - 2022-06-13 Improvement Link as FastAPI output 1.11.3 - 2022-06-10 Improvement Motor3 support Implementation ISSUE https://github.com/roman-right/beanie/issues/262 1.11.2 - 2022-06-06 Fix Dnt inherit excludes Implementation PR https://github.com/roman-right/beanie/pull/279 1.11.1 - 2022-05-31 Features Allow extra Distinct Implementation Author - Robert Rosca PR https://github.com/roman-right/beanie/pull/263 Author - \u041d\u0438\u043a\u0438\u0442\u0430 PR https://github.com/roman-right/beanie/pull/268 1.11.0 - 2022-05-06 Features Multi-model mode Views 1.10.9 - 2022-05-06 Improvement pymongo_kwargs for insert many 1.10.8 - 2022-04-13 Fix Match step after limit step Implementation ISSUE https://github.com/roman-right/beanie/issues/241 1.10.7 - 2022-04-12 Fix Empty update fails on revision id turned on Implementation ISSUE https://github.com/roman-right/beanie/issues/239 1.10.6 - 2022-04-12 Improvement Single syntax for find by id Implementation PR https://github.com/roman-right/beanie/pull/238 1.10.5 - 2022-04-11 Improvement Avoid creating redundant query object Implementation Author - amos402 PR https://github.com/roman-right/beanie/pull/235 1.10.4 - 2022-03-24 Improvement Allow custom MigrationNode for build Implementation Author - amos402 PR https://github.com/roman-right/beanie/pull/234 1.10.3 - 2022-02-29 Improvement Delete action Implementation ISSUE https://github.com/roman-right/beanie/issues/225 1.10.2 - 2022-02-28 Improvement Bulk writer for upsert Implementation ISSUE https://github.com/roman-right/beanie/issues/224 1.10.1 - 2022-02-24 Improvement Skip actions Implementation Author - Paul Renvois\u00e9 PR https://github.com/roman-right/beanie/pull/218 1.10.0 - 2022-02-24 Improvement Timeseries collections support Pymongo kwargs for find, aggregate, update and delete operations Implementation PR https://github.com/roman-right/beanie/pull/214 1.9.2 - 2022-02-22 Improvement First or None for find queries Implementation ISSUE - https://github.com/roman-right/beanie/issues/207 1.9.1 - 2022-02-11 Improvement Add support for py.typed file Implementation Author - Nicholas Smith PR - https://github.com/roman-right/beanie/pull/201 1.9.0 - 2022-02-11 Breaking Change Property allow_index_dropping to be default False. Indexes will not be deleted by default Implementation Author - Nicholas Smith PR - https://github.com/roman-right/beanie/pull/196 1.8.13 - 2022-02-10 Improvement Add state_management_replace_objects setting Implementation Author - Paul Renvois\u00e9 PR - https://github.com/roman-right/beanie/pull/197 1.8.12 - 2022-01-06 Improvement Add exclude_hidden to dict() to be able to keep hidden fields hidden when the exclude parameter set Implementation Author - Yallxe PR - https://github.com/roman-right/beanie/pull/178 1.8.11 - 2021-12-30 Improvement Only safe pydantic version are allowed. https://github.com/samuelcolvin/pydantic/security/advisories/GHSA-5jqp-qgf6-3pvh 1.8.10 - 2021-12-29 Fix Revision didn't swap previous revision id and the current one on getting objects from db 1.8.9 - 2021-12-23 Improvement Deep search of updates for the save_changes() method Kudos Thanks, Tigran Khazhakyan for the deep search algo here 1.8.8 - 2021-12-17 Added Search by linked documents fields (for pre-fetching search only) 1.8.7 - 2021-12-12 Fixed Binary encoder issue 1.8.6 - 2021-12-14 Improved Encoder 1.8.5 - 2021-12-09 Added Optional[Link[Sample]] is allowed field type syntax now 1.8.4 - 2021-12-12 Fixed DateTime bson type 1.8.3 - 2021-12-07 Added Subclasses inherit event-based actions 1.8.2 - 2021-12-04 Fixed Encoder priority 1.8.1 - 2021-11-30 Added Key-based call of subfields in the query builders 1.8.0 - 2021-11-30 Added Relations Implementation PR https://github.com/roman-right/beanie/pull/149 1.7.2 - 2021-11-03 Fixed revision_id is hidden in the api schema Implementation ISSUE https://github.com/roman-right/beanie/issues/136 1.7.1 - 2021-11-02 Fixed revision_id is hidden in the outputs Implementation ISSUE https://github.com/roman-right/beanie/issues/136 1.7.0 - 2021-10-12 Added Cache Bulk write exists - find query's method Implementation PR - https://github.com/roman-right/beanie/pull/123 PR - https://github.com/roman-right/beanie/pull/122 PR - https://github.com/roman-right/beanie/pull/129 1.6.1 - 2021-10-06 Update Customization support. It is possible to change query builder classes, used in the classes, which are inherited from the Document class Implementation PR - https://github.com/roman-right/beanie/pull/125 1.6.0 - 2021-09-30 Update Validate on save Implementation PR - https://github.com/roman-right/beanie/pull/118 1.5.1 - 2021-09-27 Update Simplification for init_beanie function Implementation PR - https://github.com/roman-right/beanie/pull/104 1.5.0 - 2021-09-27 Update Custom encoders to be able to configure, how specific type should be presented in the database Implementation Author - Nazar Vovk PR - https://github.com/roman-right/beanie/pull/91 1.4.0 - 2021-09-13 Added Document state management Implementation PR - https://github.com/roman-right/beanie/pull/114 1.3.0 - 2021-09-08 Added Active record pattern Implementation Issue - https://github.com/roman-right/beanie/issues/110 1.2.8 - 2021-09-01 Fix Delete's return annotation Implementation PR - https://github.com/roman-right/beanie/pull/109 1.2.7 - 2021-09-01 Update Annotations for update and delete Implementation Author - Anthony Shaw PR - https://github.com/roman-right/beanie/pull/106 1.2.6 - 2021-08-25 Fixed MongoDB 5.0 in GH actions Implementation PR - https://github.com/roman-right/beanie/pull/100 1.2.5 - 2021-07-21 Fixed Indexed fields work with aliases now Implementation Author - Kira Issue - https://github.com/roman-right/beanie/issues/96 1.2.4 - 2021-07-13 Fixed Aggregation preset method outputs Implementation Issue - https://github.com/roman-right/beanie/issues/91 1.2.3 - 2021-07-08 Fixed Pyright issues Added Doc publishing on merge to the main branch Implementation Issue - https://github.com/roman-right/beanie/issues/87 Issue - https://github.com/roman-right/beanie/issues/70 1.2.2 - 2021-07-06 Fixed Bool types in search criteria Implementation Issue - https://github.com/roman-right/beanie/issues/85 1.2.1 - 2021-07-06 Fixed Document, FindQuery, Aggregation typings Implementation Author - Kira Issue - https://github.com/roman-right/beanie/issues/69 1.2.0 - 2021-06-25 Added Upsert Implementation Issue - https://github.com/roman-right/beanie/issues/64 1.1.6 - 2021-06-21 Fix Pydantic dependency version ^1.5 Implementation PR - https://github.com/roman-right/beanie/pull/71 1.1.5 - 2021-06-17 Fix Convert document id to the right type in the get() method Implementation ISSUE - https://github.com/roman-right/beanie/issues/65 1.1.4 - 2021-06-15 Changed Stricter flake8 and fixing resulting errors Implementation Author - Joran van Apeldoorn PR - https://github.com/roman-right/beanie/pull/62 1.1.3 - 2021-06-15 Added MyPy to pre-commit Fixed Typing errors Implementation Author - Joran van Apeldoorn PR - https://github.com/roman-right/beanie/pull/54 1.1.2 - 2021-06-14 Changed Skip migration test when transactions not available Implementation Author - Joran van Apeldoorn PR - https://github.com/roman-right/beanie/pull/50 1.1.1 - 2021-06-14 Added Save method Implementation Author - Joran van Apeldoorn PR - https://github.com/roman-right/beanie/pull/47 1.1.0 - 2021-06-02 Added Custom id types. Implementation Issue - https://github.com/roman-right/beanie/issues/12 1.0.6 - 2021-06-01 Fixed Typo in the module name. Implementation Author - Joran van Apeldoorn PR - https://github.com/roman-right/beanie/pull/44 1.0.5 - 2021-05-25 Fixed Typing. Implementation PR - https://github.com/roman-right/beanie/pull/40 1.0.4 - 2021-05-18 Fixed aggregation_model -> projection_model Implementation PR - https://github.com/roman-right/beanie/pull/39 1.0.3 - 2021-05-16 Added Index kwargs in the Indexed field Implementation Author - Michael duPont PR - https://github.com/roman-right/beanie/pull/32 1.0.2 - 2021-05-16 Fixed Deprecated import Implementation Author - Oliver Andrich PR - https://github.com/roman-right/beanie/pull/33 1.0.1 - 2021-05-14 Fixed Document self annotation Implementation Issue - https://github.com/roman-right/beanie/issues/29 1.0.0 - 2021-05-10 Added QueryBuilder Changed Document class was reworked. Documentation Implementation PR - https://github.com/roman-right/beanie/pull/27 0.4.3 - 2021-04-25 Fixed PydanticObjectId openapi generation 0.4.2 - 2021-04-20 Added Python ^3.6.1 support. Fixed Documents init order in migrations 0.4.1 - 2021-04-19 Added Projections support to reduce database load Implementation Author - Nicholas Smith Issue - https://github.com/roman-right/beanie/issues/16 0.4.0 - 2021-04-18 Added ODM Documentation Changed Documentation 0.4.0b1 - 2021-04-14 Added Migrations inspect_collection Document method count_documents Document method Changed Session can be provided to the most of the Document methods Removed Internal DocumentMeta class. 0.3.4 - 2021-04-09 Changed Indexed(...) field supports index types. Implementation Author - Joran van Apeldoorn 0.3.3 - 2021-04-09 Added Simple indexes via type hints. Implementation Author - Joran van Apeldoorn 0.3.2 - 2021-03-25 Added init_beanie supports also lists of strings with model paths as the document_models parameter. Implementation Author - Mohamed Nesredin 0.3.1 - 2021-03-21 Added skip , limit and sort parameters in the find_many and find_all methods. Documentation 0.3.0 - 2021-03-19 Added Collection - internal class of the Document to set up additional properties. Indexes support. Changed Breaking change: init_beanie is async function now. Deprecated Internal DocumentMeta class. Will be removed in 0.4.0 .","title":"Changelog"},{"location":"changelog/#changelog","text":"Beanie project","title":"Changelog"},{"location":"changelog/#1166-2022-12-27","text":"","title":"1.16.6 - 2022-12-27"},{"location":"changelog/#feature","text":"Previous saved state","title":"Feature"},{"location":"changelog/#implementation","text":"Author - Paul Renvois\u00e9 PR https://github.com/roman-right/beanie/pull/305","title":"Implementation"},{"location":"changelog/#1165-2022-12-27","text":"","title":"1.16.5 - 2022-12-27"},{"location":"changelog/#deprecation","text":"Raises exception if Collection inner class was used as it is not supported more","title":"Deprecation"},{"location":"changelog/#backported-to","text":"1.15.5 1.14.1","title":"Backported to"},{"location":"changelog/#implementation_1","text":"PR https://github.com/roman-right/beanie/pull/460","title":"Implementation"},{"location":"changelog/#1164-2022-12-20","text":"","title":"1.16.4 - 2022-12-20"},{"location":"changelog/#fix","text":"[BUG] Initiating self-referencing documents with nested links breaks due to uncaught request loop Nested lookups for direct links","title":"Fix"},{"location":"changelog/#implementation_2","text":"PR https://github.com/roman-right/beanie/pull/455","title":"Implementation"},{"location":"changelog/#1163-2022-12-19","text":"","title":"1.16.3 - 2022-12-19"},{"location":"changelog/#fix_1","text":"[BUG] revision_id field saved in MongoDB using save()/replace() on an existing document even if use_revision is False","title":"Fix"},{"location":"changelog/#implementation_3","text":"PR https://github.com/roman-right/beanie/pull/452","title":"Implementation"},{"location":"changelog/#1162-2022-12-19","text":"","title":"1.16.2 - 2022-12-19"},{"location":"changelog/#fix_2","text":"[BUG] find_one projection link [BUG]: Link fields interference/contamination [BUG]: ElemMatch on Document property of Type List[Link] fails with IndexError in relations.py convert_ids()","title":"Fix"},{"location":"changelog/#implementation_4","text":"PR https://github.com/roman-right/beanie/pull/448","title":"Implementation"},{"location":"changelog/#1161-2022-12-17","text":"","title":"1.16.1 - 2022-12-17"},{"location":"changelog/#feature_1","text":"Remove yarl dependency","title":"Feature"},{"location":"changelog/#implementation_5","text":"PR https://github.com/roman-right/beanie/pull/448","title":"Implementation"},{"location":"changelog/#1160-2022-12-17","text":"","title":"1.16.0 - 2022-12-17"},{"location":"changelog/#feature_2","text":"Support for fetching deep-nested Links","title":"Feature"},{"location":"changelog/#implementation_6","text":"Author - Courtney Sanders PR https://github.com/roman-right/beanie/pull/419","title":"Implementation"},{"location":"changelog/#1160b3-2022-11-28","text":"","title":"1.16.0b3 - 2022-11-28"},{"location":"changelog/#feature_3","text":"Lazy parsing for find many","title":"Feature"},{"location":"changelog/#implementation_7","text":"PR https://github.com/roman-right/beanie/pull/436","title":"Implementation"},{"location":"changelog/#1154-2022-11-18","text":"","title":"1.15.4 - 2022-11-18"},{"location":"changelog/#fix_3","text":"Wrong inheritance behavior with non-rooted documents","title":"Fix"},{"location":"changelog/#implementation_8","text":"ISSUE https://github.com/roman-right/beanie/issues/422","title":"Implementation"},{"location":"changelog/#1153-2022-11-10","text":"","title":"1.15.3 - 2022-11-10"},{"location":"changelog/#fix_4","text":"Deepcopy dict before encode it to save the original","title":"Fix"},{"location":"changelog/#implementation_9","text":"ISSUE https://github.com/roman-right/beanie/issues/412","title":"Implementation"},{"location":"changelog/#1152-2022-11-09","text":"","title":"1.15.2 - 2022-11-09"},{"location":"changelog/#fix_5","text":"Use Settings inner class in migrations internals Fix inheritance: mark root docs with _inheritance_inited = True","title":"Fix"},{"location":"changelog/#implementation_10","text":"PR https://github.com/roman-right/beanie/pull/409","title":"Implementation"},{"location":"changelog/#1151-2022-11-07","text":"","title":"1.15.1 - 2022-11-07"},{"location":"changelog/#fix_6","text":"Pass pymongo kwargs to the bulk writer","title":"Fix"},{"location":"changelog/#implementation_11","text":"PR https://github.com/roman-right/beanie/pull/406","title":"Implementation"},{"location":"changelog/#1150-2022-11-05","text":"","title":"1.15.0 - 2022-11-05"},{"location":"changelog/#feature_4","text":"The sync version was moved to a separate project","title":"Feature"},{"location":"changelog/#breaking-change","text":"There is no sync version here more. Please use Bunnet instead","title":"Breaking change"},{"location":"changelog/#implementation_12","text":"PR https://github.com/roman-right/beanie/pull/395","title":"Implementation"},{"location":"changelog/#1140-2022-11-04","text":"","title":"1.14.0 - 2022-11-04"},{"location":"changelog/#feature_5","text":"Multi-model behavior for inherited documents","title":"Feature"},{"location":"changelog/#breaking-change_1","text":"The inner class Collection is not supported more. Please, use Settings instead.","title":"Breaking change"},{"location":"changelog/#implementation_13","text":"Author - Vitaliy Ivanov PR https://github.com/roman-right/beanie/pull/395","title":"Implementation"},{"location":"changelog/#1131-2022-10-26","text":"","title":"1.13.1 - 2022-10-26"},{"location":"changelog/#fix_7","text":"Remove redundant async things from sync interface","title":"Fix"},{"location":"changelog/#implementation_14","text":"ISSUE https://github.com/roman-right/beanie/issues/390","title":"Implementation"},{"location":"changelog/#1130-2022-10-22","text":"","title":"1.13.0 - 2022-10-22"},{"location":"changelog/#improvement","text":"Sync interface","title":"Improvement"},{"location":"changelog/#implementation_15","text":"PR https://github.com/roman-right/beanie/pull/386","title":"Implementation"},{"location":"changelog/#1121-2022-10-17","text":"","title":"1.12.1 - 2022-10-17"},{"location":"changelog/#improvement_1","text":"Clone interface for query objects","title":"Improvement"},{"location":"changelog/#implementation_16","text":"PR https://github.com/roman-right/beanie/pull/378","title":"Implementation"},{"location":"changelog/#1120-2022-10-06","text":"","title":"1.12.0 - 2022-10-06"},{"location":"changelog/#improvement_2","text":"Optional list of links field","title":"Improvement"},{"location":"changelog/#implementation_17","text":"Author - Alex Deng PR https://github.com/roman-right/beanie/pull/358","title":"Implementation"},{"location":"changelog/#11112-2022-09-28","text":"","title":"1.11.12 - 2022-09-28"},{"location":"changelog/#improvement_3","text":"Change before_event, after_event signature to be more pythonic","title":"Improvement"},{"location":"changelog/#implementation_18","text":"DISCUSSION https://github.com/roman-right/beanie/discussions/354","title":"Implementation"},{"location":"changelog/#11111-2022-09-26","text":"","title":"1.11.11 - 2022-09-26"},{"location":"changelog/#fix_8","text":"Remove prints","title":"Fix"},{"location":"changelog/#implementation_19","text":"ISSUE https://github.com/roman-right/beanie/issues/355/","title":"Implementation"},{"location":"changelog/#11110-2022-09-20","text":"","title":"1.11.10 - 2022-09-20"},{"location":"changelog/#improvement_4","text":"Adding Update Action","title":"Improvement"},{"location":"changelog/#implementation_20","text":"Author - schwannden PR https://github.com/roman-right/beanie/pull/291/","title":"Implementation"},{"location":"changelog/#1119-2022-08-19","text":"","title":"1.11.9 - 2022-08-19"},{"location":"changelog/#fix_9","text":"Move set state and swap revision to init to avoid problems with subdocs Issue https://github.com/roman-right/beanie/issues/294 Issue https://github.com/roman-right/beanie/issues/310","title":"Fix"},{"location":"changelog/#1118-2022-08-17","text":"","title":"1.11.8 - 2022-08-17"},{"location":"changelog/#improvement_5","text":"Skip sync parameter for instance updates","title":"Improvement"},{"location":"changelog/#1117-2022-08-02","text":"","title":"1.11.7 - 2022-08-02"},{"location":"changelog/#improvement_6","text":"Decimal128 encoding","title":"Improvement"},{"location":"changelog/#implementation_21","text":"Author - Teslim Olunlade PR https://github.com/roman-right/beanie/pull/321","title":"Implementation"},{"location":"changelog/#1116-2022-06-24","text":"","title":"1.11.6 - 2022-06-24"},{"location":"changelog/#fix_10","text":"Roll back projections fix, as it was valid","title":"Fix"},{"location":"changelog/#1115-2022-06-24","text":"","title":"1.11.5 - 2022-06-24"},{"location":"changelog/#fix_11","text":"Projection fix for aggregations","title":"Fix"},{"location":"changelog/#1114-2022-06-13","text":"","title":"1.11.4 - 2022-06-13"},{"location":"changelog/#improvement_7","text":"Link as FastAPI output","title":"Improvement"},{"location":"changelog/#1113-2022-06-10","text":"","title":"1.11.3 - 2022-06-10"},{"location":"changelog/#improvement_8","text":"Motor3 support","title":"Improvement"},{"location":"changelog/#implementation_22","text":"ISSUE https://github.com/roman-right/beanie/issues/262","title":"Implementation"},{"location":"changelog/#1112-2022-06-06","text":"","title":"1.11.2 - 2022-06-06"},{"location":"changelog/#fix_12","text":"Dnt inherit excludes","title":"Fix"},{"location":"changelog/#implementation_23","text":"PR https://github.com/roman-right/beanie/pull/279","title":"Implementation"},{"location":"changelog/#1111-2022-05-31","text":"","title":"1.11.1 - 2022-05-31"},{"location":"changelog/#features","text":"Allow extra Distinct","title":"Features"},{"location":"changelog/#implementation_24","text":"Author - Robert Rosca PR https://github.com/roman-right/beanie/pull/263 Author - \u041d\u0438\u043a\u0438\u0442\u0430 PR https://github.com/roman-right/beanie/pull/268","title":"Implementation"},{"location":"changelog/#1110-2022-05-06","text":"","title":"1.11.0 - 2022-05-06"},{"location":"changelog/#features_1","text":"Multi-model mode Views","title":"Features"},{"location":"changelog/#1109-2022-05-06","text":"","title":"1.10.9 - 2022-05-06"},{"location":"changelog/#improvement_9","text":"pymongo_kwargs for insert many","title":"Improvement"},{"location":"changelog/#1108-2022-04-13","text":"","title":"1.10.8 - 2022-04-13"},{"location":"changelog/#fix_13","text":"Match step after limit step","title":"Fix"},{"location":"changelog/#implementation_25","text":"ISSUE https://github.com/roman-right/beanie/issues/241","title":"Implementation"},{"location":"changelog/#1107-2022-04-12","text":"","title":"1.10.7 - 2022-04-12"},{"location":"changelog/#fix_14","text":"Empty update fails on revision id turned on","title":"Fix"},{"location":"changelog/#implementation_26","text":"ISSUE https://github.com/roman-right/beanie/issues/239","title":"Implementation"},{"location":"changelog/#1106-2022-04-12","text":"","title":"1.10.6 - 2022-04-12"},{"location":"changelog/#improvement_10","text":"Single syntax for find by id","title":"Improvement"},{"location":"changelog/#implementation_27","text":"PR https://github.com/roman-right/beanie/pull/238","title":"Implementation"},{"location":"changelog/#1105-2022-04-11","text":"","title":"1.10.5 - 2022-04-11"},{"location":"changelog/#improvement_11","text":"Avoid creating redundant query object","title":"Improvement"},{"location":"changelog/#implementation_28","text":"Author - amos402 PR https://github.com/roman-right/beanie/pull/235","title":"Implementation"},{"location":"changelog/#1104-2022-03-24","text":"","title":"1.10.4 - 2022-03-24"},{"location":"changelog/#improvement_12","text":"Allow custom MigrationNode for build","title":"Improvement"},{"location":"changelog/#implementation_29","text":"Author - amos402 PR https://github.com/roman-right/beanie/pull/234","title":"Implementation"},{"location":"changelog/#1103-2022-02-29","text":"","title":"1.10.3 - 2022-02-29"},{"location":"changelog/#improvement_13","text":"Delete action","title":"Improvement"},{"location":"changelog/#implementation_30","text":"ISSUE https://github.com/roman-right/beanie/issues/225","title":"Implementation"},{"location":"changelog/#1102-2022-02-28","text":"","title":"1.10.2 - 2022-02-28"},{"location":"changelog/#improvement_14","text":"Bulk writer for upsert","title":"Improvement"},{"location":"changelog/#implementation_31","text":"ISSUE https://github.com/roman-right/beanie/issues/224","title":"Implementation"},{"location":"changelog/#1101-2022-02-24","text":"","title":"1.10.1 - 2022-02-24"},{"location":"changelog/#improvement_15","text":"Skip actions","title":"Improvement"},{"location":"changelog/#implementation_32","text":"Author - Paul Renvois\u00e9 PR https://github.com/roman-right/beanie/pull/218","title":"Implementation"},{"location":"changelog/#1100-2022-02-24","text":"","title":"1.10.0 - 2022-02-24"},{"location":"changelog/#improvement_16","text":"Timeseries collections support Pymongo kwargs for find, aggregate, update and delete operations","title":"Improvement"},{"location":"changelog/#implementation_33","text":"PR https://github.com/roman-right/beanie/pull/214","title":"Implementation"},{"location":"changelog/#192-2022-02-22","text":"","title":"1.9.2 - 2022-02-22"},{"location":"changelog/#improvement_17","text":"First or None for find queries","title":"Improvement"},{"location":"changelog/#implementation_34","text":"ISSUE - https://github.com/roman-right/beanie/issues/207","title":"Implementation"},{"location":"changelog/#191-2022-02-11","text":"","title":"1.9.1 - 2022-02-11"},{"location":"changelog/#improvement_18","text":"Add support for py.typed file","title":"Improvement"},{"location":"changelog/#implementation_35","text":"Author - Nicholas Smith PR - https://github.com/roman-right/beanie/pull/201","title":"Implementation"},{"location":"changelog/#190-2022-02-11","text":"","title":"1.9.0 - 2022-02-11"},{"location":"changelog/#breaking-change_2","text":"Property allow_index_dropping to be default False. Indexes will not be deleted by default","title":"Breaking Change"},{"location":"changelog/#implementation_36","text":"Author - Nicholas Smith PR - https://github.com/roman-right/beanie/pull/196","title":"Implementation"},{"location":"changelog/#1813-2022-02-10","text":"","title":"1.8.13 - 2022-02-10"},{"location":"changelog/#improvement_19","text":"Add state_management_replace_objects setting","title":"Improvement"},{"location":"changelog/#implementation_37","text":"Author - Paul Renvois\u00e9 PR - https://github.com/roman-right/beanie/pull/197","title":"Implementation"},{"location":"changelog/#1812-2022-01-06","text":"","title":"1.8.12 - 2022-01-06"},{"location":"changelog/#improvement_20","text":"Add exclude_hidden to dict() to be able to keep hidden fields hidden when the exclude parameter set","title":"Improvement"},{"location":"changelog/#implementation_38","text":"Author - Yallxe PR - https://github.com/roman-right/beanie/pull/178","title":"Implementation"},{"location":"changelog/#1811-2021-12-30","text":"","title":"1.8.11 - 2021-12-30"},{"location":"changelog/#improvement_21","text":"Only safe pydantic version are allowed. https://github.com/samuelcolvin/pydantic/security/advisories/GHSA-5jqp-qgf6-3pvh","title":"Improvement"},{"location":"changelog/#1810-2021-12-29","text":"","title":"1.8.10 - 2021-12-29"},{"location":"changelog/#fix_15","text":"Revision didn't swap previous revision id and the current one on getting objects from db","title":"Fix"},{"location":"changelog/#189-2021-12-23","text":"","title":"1.8.9 - 2021-12-23"},{"location":"changelog/#improvement_22","text":"Deep search of updates for the save_changes() method","title":"Improvement"},{"location":"changelog/#kudos","text":"Thanks, Tigran Khazhakyan for the deep search algo here","title":"Kudos"},{"location":"changelog/#188-2021-12-17","text":"","title":"1.8.8 - 2021-12-17"},{"location":"changelog/#added","text":"Search by linked documents fields (for pre-fetching search only)","title":"Added"},{"location":"changelog/#187-2021-12-12","text":"","title":"1.8.7 - 2021-12-12"},{"location":"changelog/#fixed","text":"Binary encoder issue","title":"Fixed"},{"location":"changelog/#186-2021-12-14","text":"","title":"1.8.6 - 2021-12-14"},{"location":"changelog/#improved","text":"Encoder","title":"Improved"},{"location":"changelog/#185-2021-12-09","text":"","title":"1.8.5 - 2021-12-09"},{"location":"changelog/#added_1","text":"Optional[Link[Sample]] is allowed field type syntax now","title":"Added"},{"location":"changelog/#184-2021-12-12","text":"","title":"1.8.4 - 2021-12-12"},{"location":"changelog/#fixed_1","text":"DateTime bson type","title":"Fixed"},{"location":"changelog/#183-2021-12-07","text":"","title":"1.8.3 - 2021-12-07"},{"location":"changelog/#added_2","text":"Subclasses inherit event-based actions","title":"Added"},{"location":"changelog/#182-2021-12-04","text":"","title":"1.8.2 - 2021-12-04"},{"location":"changelog/#fixed_2","text":"Encoder priority","title":"Fixed"},{"location":"changelog/#181-2021-11-30","text":"","title":"1.8.1 - 2021-11-30"},{"location":"changelog/#added_3","text":"Key-based call of subfields in the query builders","title":"Added"},{"location":"changelog/#180-2021-11-30","text":"","title":"1.8.0 - 2021-11-30"},{"location":"changelog/#added_4","text":"Relations","title":"Added"},{"location":"changelog/#implementation_39","text":"PR https://github.com/roman-right/beanie/pull/149","title":"Implementation"},{"location":"changelog/#172-2021-11-03","text":"","title":"1.7.2 - 2021-11-03"},{"location":"changelog/#fixed_3","text":"revision_id is hidden in the api schema","title":"Fixed"},{"location":"changelog/#implementation_40","text":"ISSUE https://github.com/roman-right/beanie/issues/136","title":"Implementation"},{"location":"changelog/#171-2021-11-02","text":"","title":"1.7.1 - 2021-11-02"},{"location":"changelog/#fixed_4","text":"revision_id is hidden in the outputs","title":"Fixed"},{"location":"changelog/#implementation_41","text":"ISSUE https://github.com/roman-right/beanie/issues/136","title":"Implementation"},{"location":"changelog/#170-2021-10-12","text":"","title":"1.7.0 - 2021-10-12"},{"location":"changelog/#added_5","text":"Cache Bulk write exists - find query's method","title":"Added"},{"location":"changelog/#implementation_42","text":"PR - https://github.com/roman-right/beanie/pull/123 PR - https://github.com/roman-right/beanie/pull/122 PR - https://github.com/roman-right/beanie/pull/129","title":"Implementation"},{"location":"changelog/#161-2021-10-06","text":"","title":"1.6.1 - 2021-10-06"},{"location":"changelog/#update","text":"Customization support. It is possible to change query builder classes, used in the classes, which are inherited from the Document class","title":"Update"},{"location":"changelog/#implementation_43","text":"PR - https://github.com/roman-right/beanie/pull/125","title":"Implementation"},{"location":"changelog/#160-2021-09-30","text":"","title":"1.6.0 - 2021-09-30"},{"location":"changelog/#update_1","text":"Validate on save","title":"Update"},{"location":"changelog/#implementation_44","text":"PR - https://github.com/roman-right/beanie/pull/118","title":"Implementation"},{"location":"changelog/#151-2021-09-27","text":"","title":"1.5.1 - 2021-09-27"},{"location":"changelog/#update_2","text":"Simplification for init_beanie function","title":"Update"},{"location":"changelog/#implementation_45","text":"PR - https://github.com/roman-right/beanie/pull/104","title":"Implementation"},{"location":"changelog/#150-2021-09-27","text":"","title":"1.5.0 - 2021-09-27"},{"location":"changelog/#update_3","text":"Custom encoders to be able to configure, how specific type should be presented in the database","title":"Update"},{"location":"changelog/#implementation_46","text":"Author - Nazar Vovk PR - https://github.com/roman-right/beanie/pull/91","title":"Implementation"},{"location":"changelog/#140-2021-09-13","text":"","title":"1.4.0 - 2021-09-13"},{"location":"changelog/#added_6","text":"Document state management","title":"Added"},{"location":"changelog/#implementation_47","text":"PR - https://github.com/roman-right/beanie/pull/114","title":"Implementation"},{"location":"changelog/#130-2021-09-08","text":"","title":"1.3.0 - 2021-09-08"},{"location":"changelog/#added_7","text":"Active record pattern","title":"Added"},{"location":"changelog/#implementation_48","text":"Issue - https://github.com/roman-right/beanie/issues/110","title":"Implementation"},{"location":"changelog/#128-2021-09-01","text":"","title":"1.2.8 - 2021-09-01"},{"location":"changelog/#fix_16","text":"Delete's return annotation","title":"Fix"},{"location":"changelog/#implementation_49","text":"PR - https://github.com/roman-right/beanie/pull/109","title":"Implementation"},{"location":"changelog/#127-2021-09-01","text":"","title":"1.2.7 - 2021-09-01"},{"location":"changelog/#update_4","text":"Annotations for update and delete","title":"Update"},{"location":"changelog/#implementation_50","text":"Author - Anthony Shaw PR - https://github.com/roman-right/beanie/pull/106","title":"Implementation"},{"location":"changelog/#126-2021-08-25","text":"","title":"1.2.6 - 2021-08-25"},{"location":"changelog/#fixed_5","text":"MongoDB 5.0 in GH actions","title":"Fixed"},{"location":"changelog/#implementation_51","text":"PR - https://github.com/roman-right/beanie/pull/100","title":"Implementation"},{"location":"changelog/#125-2021-07-21","text":"","title":"1.2.5 - 2021-07-21"},{"location":"changelog/#fixed_6","text":"Indexed fields work with aliases now","title":"Fixed"},{"location":"changelog/#implementation_52","text":"Author - Kira Issue - https://github.com/roman-right/beanie/issues/96","title":"Implementation"},{"location":"changelog/#124-2021-07-13","text":"","title":"1.2.4 - 2021-07-13"},{"location":"changelog/#fixed_7","text":"Aggregation preset method outputs","title":"Fixed"},{"location":"changelog/#implementation_53","text":"Issue - https://github.com/roman-right/beanie/issues/91","title":"Implementation"},{"location":"changelog/#123-2021-07-08","text":"","title":"1.2.3 - 2021-07-08"},{"location":"changelog/#fixed_8","text":"Pyright issues","title":"Fixed"},{"location":"changelog/#added_8","text":"Doc publishing on merge to the main branch","title":"Added"},{"location":"changelog/#implementation_54","text":"Issue - https://github.com/roman-right/beanie/issues/87 Issue - https://github.com/roman-right/beanie/issues/70","title":"Implementation"},{"location":"changelog/#122-2021-07-06","text":"","title":"1.2.2 - 2021-07-06"},{"location":"changelog/#fixed_9","text":"Bool types in search criteria","title":"Fixed"},{"location":"changelog/#implementation_55","text":"Issue - https://github.com/roman-right/beanie/issues/85","title":"Implementation"},{"location":"changelog/#121-2021-07-06","text":"","title":"1.2.1 - 2021-07-06"},{"location":"changelog/#fixed_10","text":"Document, FindQuery, Aggregation typings","title":"Fixed"},{"location":"changelog/#implementation_56","text":"Author - Kira Issue - https://github.com/roman-right/beanie/issues/69","title":"Implementation"},{"location":"changelog/#120-2021-06-25","text":"","title":"1.2.0 - 2021-06-25"},{"location":"changelog/#added_9","text":"Upsert","title":"Added"},{"location":"changelog/#implementation_57","text":"Issue - https://github.com/roman-right/beanie/issues/64","title":"Implementation"},{"location":"changelog/#116-2021-06-21","text":"","title":"1.1.6 - 2021-06-21"},{"location":"changelog/#fix_17","text":"Pydantic dependency version ^1.5","title":"Fix"},{"location":"changelog/#implementation_58","text":"PR - https://github.com/roman-right/beanie/pull/71","title":"Implementation"},{"location":"changelog/#115-2021-06-17","text":"","title":"1.1.5 - 2021-06-17"},{"location":"changelog/#fix_18","text":"Convert document id to the right type in the get() method","title":"Fix"},{"location":"changelog/#implementation_59","text":"ISSUE - https://github.com/roman-right/beanie/issues/65","title":"Implementation"},{"location":"changelog/#114-2021-06-15","text":"","title":"1.1.4 - 2021-06-15"},{"location":"changelog/#changed","text":"Stricter flake8 and fixing resulting errors","title":"Changed"},{"location":"changelog/#implementation_60","text":"Author - Joran van Apeldoorn PR - https://github.com/roman-right/beanie/pull/62","title":"Implementation"},{"location":"changelog/#113-2021-06-15","text":"","title":"1.1.3 - 2021-06-15"},{"location":"changelog/#added_10","text":"MyPy to pre-commit","title":"Added"},{"location":"changelog/#fixed_11","text":"Typing errors","title":"Fixed"},{"location":"changelog/#implementation_61","text":"Author - Joran van Apeldoorn PR - https://github.com/roman-right/beanie/pull/54","title":"Implementation"},{"location":"changelog/#112-2021-06-14","text":"","title":"1.1.2 - 2021-06-14"},{"location":"changelog/#changed_1","text":"Skip migration test when transactions not available","title":"Changed"},{"location":"changelog/#implementation_62","text":"Author - Joran van Apeldoorn PR - https://github.com/roman-right/beanie/pull/50","title":"Implementation"},{"location":"changelog/#111-2021-06-14","text":"","title":"1.1.1 - 2021-06-14"},{"location":"changelog/#added_11","text":"Save method","title":"Added"},{"location":"changelog/#implementation_63","text":"Author - Joran van Apeldoorn PR - https://github.com/roman-right/beanie/pull/47","title":"Implementation"},{"location":"changelog/#110-2021-06-02","text":"","title":"1.1.0 - 2021-06-02"},{"location":"changelog/#added_12","text":"Custom id types.","title":"Added"},{"location":"changelog/#implementation_64","text":"Issue - https://github.com/roman-right/beanie/issues/12","title":"Implementation"},{"location":"changelog/#106-2021-06-01","text":"","title":"1.0.6 - 2021-06-01"},{"location":"changelog/#fixed_12","text":"Typo in the module name.","title":"Fixed"},{"location":"changelog/#implementation_65","text":"Author - Joran van Apeldoorn PR - https://github.com/roman-right/beanie/pull/44","title":"Implementation"},{"location":"changelog/#105-2021-05-25","text":"","title":"1.0.5 - 2021-05-25"},{"location":"changelog/#fixed_13","text":"Typing.","title":"Fixed"},{"location":"changelog/#implementation_66","text":"PR - https://github.com/roman-right/beanie/pull/40","title":"Implementation"},{"location":"changelog/#104-2021-05-18","text":"","title":"1.0.4 - 2021-05-18"},{"location":"changelog/#fixed_14","text":"aggregation_model -> projection_model","title":"Fixed"},{"location":"changelog/#implementation_67","text":"PR - https://github.com/roman-right/beanie/pull/39","title":"Implementation"},{"location":"changelog/#103-2021-05-16","text":"","title":"1.0.3 - 2021-05-16"},{"location":"changelog/#added_13","text":"Index kwargs in the Indexed field","title":"Added"},{"location":"changelog/#implementation_68","text":"Author - Michael duPont PR - https://github.com/roman-right/beanie/pull/32","title":"Implementation"},{"location":"changelog/#102-2021-05-16","text":"","title":"1.0.2 - 2021-05-16"},{"location":"changelog/#fixed_15","text":"Deprecated import","title":"Fixed"},{"location":"changelog/#implementation_69","text":"Author - Oliver Andrich PR - https://github.com/roman-right/beanie/pull/33","title":"Implementation"},{"location":"changelog/#101-2021-05-14","text":"","title":"1.0.1 - 2021-05-14"},{"location":"changelog/#fixed_16","text":"Document self annotation","title":"Fixed"},{"location":"changelog/#implementation_70","text":"Issue - https://github.com/roman-right/beanie/issues/29","title":"Implementation"},{"location":"changelog/#100-2021-05-10","text":"","title":"1.0.0 - 2021-05-10"},{"location":"changelog/#added_14","text":"QueryBuilder","title":"Added"},{"location":"changelog/#changed_2","text":"Document class was reworked. Documentation","title":"Changed"},{"location":"changelog/#implementation_71","text":"PR - https://github.com/roman-right/beanie/pull/27","title":"Implementation"},{"location":"changelog/#043-2021-04-25","text":"","title":"0.4.3 - 2021-04-25"},{"location":"changelog/#fixed_17","text":"PydanticObjectId openapi generation","title":"Fixed"},{"location":"changelog/#042-2021-04-20","text":"","title":"0.4.2 - 2021-04-20"},{"location":"changelog/#added_15","text":"Python ^3.6.1 support.","title":"Added"},{"location":"changelog/#fixed_18","text":"Documents init order in migrations","title":"Fixed"},{"location":"changelog/#041-2021-04-19","text":"","title":"0.4.1 - 2021-04-19"},{"location":"changelog/#added_16","text":"Projections support to reduce database load","title":"Added"},{"location":"changelog/#implementation_72","text":"Author - Nicholas Smith Issue - https://github.com/roman-right/beanie/issues/16","title":"Implementation"},{"location":"changelog/#040-2021-04-18","text":"","title":"0.4.0 - 2021-04-18"},{"location":"changelog/#added_17","text":"ODM Documentation","title":"Added"},{"location":"changelog/#changed_3","text":"Documentation","title":"Changed"},{"location":"changelog/#040b1-2021-04-14","text":"","title":"0.4.0b1 - 2021-04-14"},{"location":"changelog/#added_18","text":"Migrations inspect_collection Document method count_documents Document method","title":"Added"},{"location":"changelog/#changed_4","text":"Session can be provided to the most of the Document methods","title":"Changed"},{"location":"changelog/#removed","text":"Internal DocumentMeta class.","title":"Removed"},{"location":"changelog/#034-2021-04-09","text":"","title":"0.3.4 - 2021-04-09"},{"location":"changelog/#changed_5","text":"Indexed(...) field supports index types.","title":"Changed"},{"location":"changelog/#implementation_73","text":"Author - Joran van Apeldoorn","title":"Implementation"},{"location":"changelog/#033-2021-04-09","text":"","title":"0.3.3 - 2021-04-09"},{"location":"changelog/#added_19","text":"Simple indexes via type hints.","title":"Added"},{"location":"changelog/#implementation_74","text":"Author - Joran van Apeldoorn","title":"Implementation"},{"location":"changelog/#032-2021-03-25","text":"","title":"0.3.2 - 2021-03-25"},{"location":"changelog/#added_20","text":"init_beanie supports also lists of strings with model paths as the document_models parameter.","title":"Added"},{"location":"changelog/#implementation_75","text":"Author - Mohamed Nesredin","title":"Implementation"},{"location":"changelog/#031-2021-03-21","text":"","title":"0.3.1 - 2021-03-21"},{"location":"changelog/#added_21","text":"skip , limit and sort parameters in the find_many and find_all methods. Documentation","title":"Added"},{"location":"changelog/#030-2021-03-19","text":"","title":"0.3.0 - 2021-03-19"},{"location":"changelog/#added_22","text":"Collection - internal class of the Document to set up additional properties. Indexes support.","title":"Added"},{"location":"changelog/#changed_6","text":"Breaking change: init_beanie is async function now.","title":"Changed"},{"location":"changelog/#deprecated","text":"Internal DocumentMeta class. Will be removed in 0.4.0 .","title":"Deprecated"},{"location":"code-of-conduct/","text":"Contributor Covenant Code of Conduct Our Pledge We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at roman-right@protonmail.com. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html. Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.","title":"Code of conduct"},{"location":"code-of-conduct/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"code-of-conduct/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"code-of-conduct/#our-standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"code-of-conduct/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"code-of-conduct/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"code-of-conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at roman-right@protonmail.com. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"code-of-conduct/#enforcement-guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"code-of-conduct/#1-correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"code-of-conduct/#2-warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"code-of-conduct/#3-temporary-ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"code-of-conduct/#4-permanent-ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"code-of-conduct/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html. Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.","title":"Attribution"},{"location":"development/","text":"Development Hopefully you have landed here because you would like to help out with the development of Beanie. Whether through adding new features, fixing bugs, or extending documentation, your help is really appreciated! Please read this page carefully. If you have any questions, drop by on the discord. Also please read the Code of conduct . Setting up the development environment We assume you are familiar with the general forking and pull request workflow for submitting to open-source projects. If not, don't worry, there are plenty of good guides available, maybe check out this one . Beanie uses poetry to manage dependencies and packaging. If you are not familiar with poetry, it might be helpful to check it out before working on Beanie, but here is a quick guide to get you started. Make sure poetry is installed globally: pip install --user poetry To install all required dependencies in a virtual environment, run the following command in the root directory of the Beanie project: poetry install To add a dependency you can use: poetry add <package name> which takes an optional -D flag for development only dependencies. To run commands like pytest or black you have to run them using the virtual environment which contains the dependencies and Beanie. You can do this in two ways, you may run poetry shell to activate the environment for the current shell, or you can run them in a one-off fashion as such poetry run pytest . Database connection To run tests, and use Beanie in general, you will need an accessible MongoDB database. To use migrations you will need a connection to a Replica Set or Mongos instance. All tests assume that the database is hosted locally on port 27017 and does not require authentication. Testing Beanie uses pytest for unit testing. To ensure the stability of Beanie, each added feature must be tested in a separate unit test. Even if it looks like other tests are covering it now. This strategy guarantees that: All the features will be covered and stay covered. Independence from other features and test cases. To run the test suit, make sure that you have MongoDB running and run poetry run pytest . Submitting new code You can submit your changes through a pull request on GitHub. Please take into account the following sections. Use pre-commit To ensure code consistency Beanie uses Black and Flake8 through pre-commit. To set it up, run: poetry install poetry run pre-commit install This will add the pre-commit command to your git's pre-commit hooks and makes sure you can never forget to run these. Single commit To make the pull request reviewing easier and keep the version tree clean your pull request should consist of a single commit. It is natural that your branch might contain multiple commits, so you will need to squash these into a single commit. Instructions can be found here or here Add documentation Please write clear documentation for any new functionality you add. Docstrings will be converted to the API documentation, but more human friendly documentation might also be needed! See the section below. Working on the documentation The documentation is generated using pydoc-markdown . To see a preview of any edits you make you can run: poetry run pydoc-markdown --server and visit the printed address (usually localhost:8000 ) in your browser. Beware, the auto recompiling might not work for everyone. This will automatically generate the API documentation from source. All other documentation should be written by hand. The documentation is compiled using mkdocs behind the scenes. To change the table of contents or other options, check out pydoc-markdown.yml .","title":"Development"},{"location":"development/#development","text":"Hopefully you have landed here because you would like to help out with the development of Beanie. Whether through adding new features, fixing bugs, or extending documentation, your help is really appreciated! Please read this page carefully. If you have any questions, drop by on the discord. Also please read the Code of conduct .","title":"Development"},{"location":"development/#setting-up-the-development-environment","text":"We assume you are familiar with the general forking and pull request workflow for submitting to open-source projects. If not, don't worry, there are plenty of good guides available, maybe check out this one . Beanie uses poetry to manage dependencies and packaging. If you are not familiar with poetry, it might be helpful to check it out before working on Beanie, but here is a quick guide to get you started. Make sure poetry is installed globally: pip install --user poetry To install all required dependencies in a virtual environment, run the following command in the root directory of the Beanie project: poetry install To add a dependency you can use: poetry add <package name> which takes an optional -D flag for development only dependencies. To run commands like pytest or black you have to run them using the virtual environment which contains the dependencies and Beanie. You can do this in two ways, you may run poetry shell to activate the environment for the current shell, or you can run them in a one-off fashion as such poetry run pytest .","title":"Setting up the development environment"},{"location":"development/#database-connection","text":"To run tests, and use Beanie in general, you will need an accessible MongoDB database. To use migrations you will need a connection to a Replica Set or Mongos instance. All tests assume that the database is hosted locally on port 27017 and does not require authentication.","title":"Database connection"},{"location":"development/#testing","text":"Beanie uses pytest for unit testing. To ensure the stability of Beanie, each added feature must be tested in a separate unit test. Even if it looks like other tests are covering it now. This strategy guarantees that: All the features will be covered and stay covered. Independence from other features and test cases. To run the test suit, make sure that you have MongoDB running and run poetry run pytest .","title":"Testing"},{"location":"development/#submitting-new-code","text":"You can submit your changes through a pull request on GitHub. Please take into account the following sections.","title":"Submitting new code"},{"location":"development/#use-pre-commit","text":"To ensure code consistency Beanie uses Black and Flake8 through pre-commit. To set it up, run: poetry install poetry run pre-commit install This will add the pre-commit command to your git's pre-commit hooks and makes sure you can never forget to run these.","title":"Use pre-commit"},{"location":"development/#single-commit","text":"To make the pull request reviewing easier and keep the version tree clean your pull request should consist of a single commit. It is natural that your branch might contain multiple commits, so you will need to squash these into a single commit. Instructions can be found here or here","title":"Single commit"},{"location":"development/#add-documentation","text":"Please write clear documentation for any new functionality you add. Docstrings will be converted to the API documentation, but more human friendly documentation might also be needed! See the section below.","title":"Add documentation"},{"location":"development/#working-on-the-documentation","text":"The documentation is generated using pydoc-markdown . To see a preview of any edits you make you can run: poetry run pydoc-markdown --server and visit the printed address (usually localhost:8000 ) in your browser. Beware, the auto recompiling might not work for everyone. This will automatically generate the API documentation from source. All other documentation should be written by hand. The documentation is compiled using mkdocs behind the scenes. To change the table of contents or other options, check out pydoc-markdown.yml .","title":"Working on the documentation"},{"location":"getting-started/","text":"Getting started Installing beanie You can simply install Beanie from the PyPI : PIP pip install beanie Poetry poetry add beanie Initialization Getting Beanie setup in your code is really easy: Write your database model as a Pydantic class but use beanie.Document instead of pydantic.BaseModel . Initialize Motor, as Beanie uses this as an async database engine under the hood. Call beanie.init_beanie with the Motor client and list of Beanie models The code below should get you started and shows some of the field types that you can use with beanie. from typing import Optional import motor.motor_asyncio from motor.motor_asyncio import AsyncIOMotorClient from pydantic import BaseModel from beanie import Document , Indexed , init_beanie class Category ( BaseModel ): name : str description : str # This is the model that will be saved to the database class Product ( Document ): name : str # You can use normal types just like in pydantic description : Optional [ str ] = None price : Indexed ( float ) # You can also specify that a field should correspond to an index category : Category # You can include pydantic models as well # Call this from within your event loop to get beanie setup. async def init (): # Create Motor client client = AsyncIOMotorClient ( \"mongodb://user:pass@host:27017\" ) # Init beanie with the Product document class await init_beanie ( database = client . db_name , document_models = [ Product ])","title":"Getting started"},{"location":"getting-started/#getting-started","text":"","title":"Getting started"},{"location":"getting-started/#installing-beanie","text":"You can simply install Beanie from the PyPI :","title":"Installing beanie"},{"location":"getting-started/#pip","text":"pip install beanie","title":"PIP"},{"location":"getting-started/#poetry","text":"poetry add beanie","title":"Poetry"},{"location":"getting-started/#initialization","text":"Getting Beanie setup in your code is really easy: Write your database model as a Pydantic class but use beanie.Document instead of pydantic.BaseModel . Initialize Motor, as Beanie uses this as an async database engine under the hood. Call beanie.init_beanie with the Motor client and list of Beanie models The code below should get you started and shows some of the field types that you can use with beanie. from typing import Optional import motor.motor_asyncio from motor.motor_asyncio import AsyncIOMotorClient from pydantic import BaseModel from beanie import Document , Indexed , init_beanie class Category ( BaseModel ): name : str description : str # This is the model that will be saved to the database class Product ( Document ): name : str # You can use normal types just like in pydantic description : Optional [ str ] = None price : Indexed ( float ) # You can also specify that a field should correspond to an index category : Category # You can include pydantic models as well # Call this from within your event loop to get beanie setup. async def init (): # Create Motor client client = AsyncIOMotorClient ( \"mongodb://user:pass@host:27017\" ) # Init beanie with the Product document class await init_beanie ( database = client . db_name , document_models = [ Product ])","title":"Initialization"},{"location":"api-documentation/document/","text":"beanie.odm.documents Document class Document ( LazyModel , SettersInterface , InheritanceInterface , FindInterface , AggregateInterface , OtherGettersInterface ) Document Mapping class. Fields: id - MongoDB document ObjectID \"_id\" field. Mapped to the PydanticObjectId class Inherited from: Pydantic BaseModel UpdateMethods Document.get | @classmethod | async get ( cls : Type [ \"DocType\" ], document_id : PydanticObjectId , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , fetch_links : bool = False , with_children : bool = False , ** pymongo_kwargs , ,) -> Optional [ \"DocType\" ] Get document by id, returns None if document does not exist Arguments : :param **pymongo_kwargs: pymongo native parameters for find operation - document_id : PydanticObjectId - document id - session : Optional[ClientSession] - pymongo session - ignore_cache : bool - ignore cache (if it is turned on) Returns : Union[\"Document\", None] Document.insert | @wrap_with_actions ( EventTypes . INSERT ) | @save_state_after | @swap_revision_after | @validate_self_before | async insert ( * , link_rule : WriteRules = WriteRules . DO_NOTHING , session : Optional [ ClientSession ] = None , skip_actions : Optional [ List [ Union [ ActionDirections , str ]]] = None ) -> DocType Insert the document (self) to the collection Returns : Document Document.create | async create ( session : Optional [ ClientSession ] = None ) -> DocType The same as self.insert() Returns : Document Document.insert_one | @classmethod | async insert_one ( cls : Type [ DocType ], document : DocType , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ \"BulkWriter\" ] = None , link_rule : WriteRules = WriteRules . DO_NOTHING ) -> Optional [ DocType ] Insert one document to the collection Arguments : document : Document - document to insert session : ClientSession - pymongo session bulk_writer : \"BulkWriter\" - Beanie bulk writer link_rule : InsertRules - hot to manage link fields Returns : DocType Document.insert_many | @classmethod | async insert_many ( cls : Type [ DocType ], documents : List [ DocType ], session : Optional [ ClientSession ] = None , link_rule : WriteRules = WriteRules . DO_NOTHING , ** pymongo_kwargs , ,) -> InsertManyResult Insert many documents to the collection Arguments : documents : List[\"Document\"] - documents to insert session : ClientSession - pymongo session link_rule : InsertRules - how to manage link fields Returns : InsertManyResult Document.replace | @wrap_with_actions ( EventTypes . REPLACE ) | @save_state_after | @swap_revision_after | @validate_self_before | async replace ( ignore_revision : bool = False , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , link_rule : WriteRules = WriteRules . DO_NOTHING , skip_actions : Optional [ List [ Union [ ActionDirections , str ]]] = None ) -> DocType Fully update the document in the database Arguments : Used when revision based protection is turned on. session : Optional[ClientSession] - pymongo session. ignore_revision : bool - do force replace. bulk_writer : \"BulkWriter\" - Beanie bulk writer Returns : self Document.save | async save ( session : Optional [ ClientSession ] = None , link_rule : WriteRules = WriteRules . DO_NOTHING , ** kwargs , ,) -> DocType Update an existing model in the database or insert it if it does not yet exist. Arguments : session : Optional[ClientSession] - pymongo session. Returns : None Document.save_changes | @saved_state_needed | @wrap_with_actions ( EventTypes . SAVE_CHANGES ) | @validate_self_before | async save_changes ( ignore_revision : bool = False , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , skip_actions : Optional [ List [ Union [ ActionDirections , str ]]] = None ) -> None Save changes. State management usage must be turned on Arguments : ignore_revision : bool - ignore revision id, if revision is turned on bulk_writer : \"BulkWriter\" - Beanie bulk writer Returns : None Document.replace_many | @classmethod | async replace_many ( cls : Type [ DocType ], documents : List [ DocType ], session : Optional [ ClientSession ] = None ) -> None Replace list of documents Arguments : documents : List[\"Document\"] session : Optional[ClientSession] - pymongo session. Returns : None Document.update | @wrap_with_actions ( EventTypes . UPDATE ) | @save_state_after | async update ( * args , * , ignore_revision : bool = False , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , skip_sync : bool = False , skip_actions : Optional [ List [ Union [ ActionDirections , str ]]] = None , ** pymongo_kwargs , ,) -> None Partially update the document in the database Arguments : :param * pymongo_kwargs: pymongo native parameters for update operation - args : Union[dict, Mapping] - the modifications to apply. - session : ClientSession - pymongo session. - ignore_revision : bool - force update. Will update even if revision id is not the same, as stored - bulk_writer : \"BulkWriter\" - Beanie bulk writer Returns : None Document.update_all | @classmethod | update_all ( cls , * args : Union [ dict , Mapping ], * , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) -> UpdateMany Partially update all the documents Arguments : :param * pymongo_kwargs: pymongo native parameters for find operation - args : Union[dict, Mapping] - the modifications to apply. - session : ClientSession - pymongo session. - bulk_writer : \"BulkWriter\" - Beanie bulk writer Returns : UpdateMany query Document.set | set ( expression : Dict [ Union [ ExpressionField , str ], Any ], session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , skip_sync : bool = False , ** kwargs , ,) Set values Example: class Sample ( Document ): one : int await Document . find ( Sample . one == 1 ) . set ({ Sample . one : 100 }) Uses Set operator Arguments : values to set - expression : Dict[Union[ExpressionField, str], Any] - keys and - session : Optional[ClientSession] - pymongo session - bulk_writer : Optional[BulkWriter] - bulk writer - skip_sync : bool - skip doc syncing. Available for the direct instances only Returns : self Document.current_date | current_date ( expression : Dict [ Union [ ExpressionField , str ], Any ], session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , skip_sync : bool = False , ** kwargs , ,) Set current date Uses CurrentDate operator Arguments : expression : Dict[Union[ExpressionField, str], Any] session : Optional[ClientSession] - pymongo session bulk_writer : Optional[BulkWriter] - bulk writer skip_sync : bool - skip doc syncing. Available for the direct instances only Returns : self Document.inc | inc ( expression : Dict [ Union [ ExpressionField , str ], Any ], session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , skip_sync : bool = False , ** kwargs , ,) Increment Example: class Sample ( Document ): one : int await Document . find ( Sample . one == 1 ) . inc ({ Sample . one : 100 }) Uses Inc operator Arguments : expression : Dict[Union[ExpressionField, str], Any] session : Optional[ClientSession] - pymongo session bulk_writer : Optional[BulkWriter] - bulk writer skip_sync : bool - skip doc syncing. Available for the direct instances only Returns : self Document.delete | @wrap_with_actions ( EventTypes . DELETE ) | async delete ( session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , link_rule : DeleteRules = DeleteRules . DO_NOTHING , skip_actions : Optional [ List [ Union [ ActionDirections , str ]]] = None , ** pymongo_kwargs , ,) -> Optional [ DeleteResult ] Delete the document Arguments : :param **pymongo_kwargs: pymongo native parameters for delete operation - session : Optional[ClientSession] - pymongo session. - bulk_writer : \"BulkWriter\" - Beanie bulk writer - link_rule : DeleteRules - rules for link fields Returns : Optional[DeleteResult] - pymongo DeleteResult instance. Document.delete_all | @classmethod | async delete_all ( cls , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) -> Optional [ DeleteResult ] Delete all the documents Arguments : :param **pymongo_kwargs: pymongo native parameters for delete operation - session : Optional[ClientSession] - pymongo session. - bulk_writer : \"BulkWriter\" - Beanie bulk writer Returns : Optional[DeleteResult] - pymongo DeleteResult instance. Document.use_state_management | @classmethod | use_state_management ( cls ) -> bool Is state management turned on Returns : bool Document.state_management_save_previous | @classmethod | state_management_save_previous ( cls ) -> bool Should we save the previous state after a commit to database Returns : bool Document.state_management_replace_objects | @classmethod | state_management_replace_objects ( cls ) -> bool Should objects be replaced when using state management Returns : bool Document.get_saved_state | get_saved_state () -> Optional [ Dict [ str , Any ]] Saved state getter. It is protected property. Returns : Optional[Dict[str, Any]] - saved state Document.get_previous_saved_state | get_previous_saved_state () -> Optional [ Dict [ str , Any ]] Previous state getter. It is a protected property. Returns : Optional[Dict[str, Any]] - previous state Document.get_settings | @classmethod | get_settings ( cls ) -> DocumentSettings Get document settings, which was created on the initialization step Returns : DocumentSettings class Document.inspect_collection | @classmethod | async inspect_collection ( cls , session : Optional [ ClientSession ] = None ) -> InspectionResult Check, if documents, stored in the MongoDB collection are compatible with the Document schema Returns : InspectionResult Document.dict | dict ( * , include : Union [ \"AbstractSetIntStr\" , \"MappingIntStrAny\" ] = None , exclude : Union [ \"AbstractSetIntStr\" , \"MappingIntStrAny\" ] = None , by_alias : bool = False , skip_defaults : bool = False , exclude_hidden : bool = True , exclude_unset : bool = False , exclude_defaults : bool = False , exclude_none : bool = False ) -> \"DictStrAny\" Overriding of the respective method from Pydantic Hides fields, marked as \"hidden","title":"Document"},{"location":"api-documentation/document/#beanieodmdocuments","text":"","title":"beanie.odm.documents"},{"location":"api-documentation/document/#document","text":"class Document ( LazyModel , SettersInterface , InheritanceInterface , FindInterface , AggregateInterface , OtherGettersInterface ) Document Mapping class. Fields: id - MongoDB document ObjectID \"_id\" field. Mapped to the PydanticObjectId class Inherited from: Pydantic BaseModel UpdateMethods","title":"Document"},{"location":"api-documentation/document/#documentget","text":"| @classmethod | async get ( cls : Type [ \"DocType\" ], document_id : PydanticObjectId , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , fetch_links : bool = False , with_children : bool = False , ** pymongo_kwargs , ,) -> Optional [ \"DocType\" ] Get document by id, returns None if document does not exist Arguments : :param **pymongo_kwargs: pymongo native parameters for find operation - document_id : PydanticObjectId - document id - session : Optional[ClientSession] - pymongo session - ignore_cache : bool - ignore cache (if it is turned on) Returns : Union[\"Document\", None]","title":"Document.get"},{"location":"api-documentation/document/#documentinsert","text":"| @wrap_with_actions ( EventTypes . INSERT ) | @save_state_after | @swap_revision_after | @validate_self_before | async insert ( * , link_rule : WriteRules = WriteRules . DO_NOTHING , session : Optional [ ClientSession ] = None , skip_actions : Optional [ List [ Union [ ActionDirections , str ]]] = None ) -> DocType Insert the document (self) to the collection Returns : Document","title":"Document.insert"},{"location":"api-documentation/document/#documentcreate","text":"| async create ( session : Optional [ ClientSession ] = None ) -> DocType The same as self.insert() Returns : Document","title":"Document.create"},{"location":"api-documentation/document/#documentinsert_one","text":"| @classmethod | async insert_one ( cls : Type [ DocType ], document : DocType , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ \"BulkWriter\" ] = None , link_rule : WriteRules = WriteRules . DO_NOTHING ) -> Optional [ DocType ] Insert one document to the collection Arguments : document : Document - document to insert session : ClientSession - pymongo session bulk_writer : \"BulkWriter\" - Beanie bulk writer link_rule : InsertRules - hot to manage link fields Returns : DocType","title":"Document.insert_one"},{"location":"api-documentation/document/#documentinsert_many","text":"| @classmethod | async insert_many ( cls : Type [ DocType ], documents : List [ DocType ], session : Optional [ ClientSession ] = None , link_rule : WriteRules = WriteRules . DO_NOTHING , ** pymongo_kwargs , ,) -> InsertManyResult Insert many documents to the collection Arguments : documents : List[\"Document\"] - documents to insert session : ClientSession - pymongo session link_rule : InsertRules - how to manage link fields Returns : InsertManyResult","title":"Document.insert_many"},{"location":"api-documentation/document/#documentreplace","text":"| @wrap_with_actions ( EventTypes . REPLACE ) | @save_state_after | @swap_revision_after | @validate_self_before | async replace ( ignore_revision : bool = False , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , link_rule : WriteRules = WriteRules . DO_NOTHING , skip_actions : Optional [ List [ Union [ ActionDirections , str ]]] = None ) -> DocType Fully update the document in the database Arguments : Used when revision based protection is turned on. session : Optional[ClientSession] - pymongo session. ignore_revision : bool - do force replace. bulk_writer : \"BulkWriter\" - Beanie bulk writer Returns : self","title":"Document.replace"},{"location":"api-documentation/document/#documentsave","text":"| async save ( session : Optional [ ClientSession ] = None , link_rule : WriteRules = WriteRules . DO_NOTHING , ** kwargs , ,) -> DocType Update an existing model in the database or insert it if it does not yet exist. Arguments : session : Optional[ClientSession] - pymongo session. Returns : None","title":"Document.save"},{"location":"api-documentation/document/#documentsave_changes","text":"| @saved_state_needed | @wrap_with_actions ( EventTypes . SAVE_CHANGES ) | @validate_self_before | async save_changes ( ignore_revision : bool = False , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , skip_actions : Optional [ List [ Union [ ActionDirections , str ]]] = None ) -> None Save changes. State management usage must be turned on Arguments : ignore_revision : bool - ignore revision id, if revision is turned on bulk_writer : \"BulkWriter\" - Beanie bulk writer Returns : None","title":"Document.save_changes"},{"location":"api-documentation/document/#documentreplace_many","text":"| @classmethod | async replace_many ( cls : Type [ DocType ], documents : List [ DocType ], session : Optional [ ClientSession ] = None ) -> None Replace list of documents Arguments : documents : List[\"Document\"] session : Optional[ClientSession] - pymongo session. Returns : None","title":"Document.replace_many"},{"location":"api-documentation/document/#documentupdate","text":"| @wrap_with_actions ( EventTypes . UPDATE ) | @save_state_after | async update ( * args , * , ignore_revision : bool = False , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , skip_sync : bool = False , skip_actions : Optional [ List [ Union [ ActionDirections , str ]]] = None , ** pymongo_kwargs , ,) -> None Partially update the document in the database Arguments : :param * pymongo_kwargs: pymongo native parameters for update operation - args : Union[dict, Mapping] - the modifications to apply. - session : ClientSession - pymongo session. - ignore_revision : bool - force update. Will update even if revision id is not the same, as stored - bulk_writer : \"BulkWriter\" - Beanie bulk writer Returns : None","title":"Document.update"},{"location":"api-documentation/document/#documentupdate_all","text":"| @classmethod | update_all ( cls , * args : Union [ dict , Mapping ], * , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) -> UpdateMany Partially update all the documents Arguments : :param * pymongo_kwargs: pymongo native parameters for find operation - args : Union[dict, Mapping] - the modifications to apply. - session : ClientSession - pymongo session. - bulk_writer : \"BulkWriter\" - Beanie bulk writer Returns : UpdateMany query","title":"Document.update_all"},{"location":"api-documentation/document/#documentset","text":"| set ( expression : Dict [ Union [ ExpressionField , str ], Any ], session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , skip_sync : bool = False , ** kwargs , ,) Set values Example: class Sample ( Document ): one : int await Document . find ( Sample . one == 1 ) . set ({ Sample . one : 100 }) Uses Set operator Arguments : values to set - expression : Dict[Union[ExpressionField, str], Any] - keys and - session : Optional[ClientSession] - pymongo session - bulk_writer : Optional[BulkWriter] - bulk writer - skip_sync : bool - skip doc syncing. Available for the direct instances only Returns : self","title":"Document.set"},{"location":"api-documentation/document/#documentcurrent_date","text":"| current_date ( expression : Dict [ Union [ ExpressionField , str ], Any ], session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , skip_sync : bool = False , ** kwargs , ,) Set current date Uses CurrentDate operator Arguments : expression : Dict[Union[ExpressionField, str], Any] session : Optional[ClientSession] - pymongo session bulk_writer : Optional[BulkWriter] - bulk writer skip_sync : bool - skip doc syncing. Available for the direct instances only Returns : self","title":"Document.current_date"},{"location":"api-documentation/document/#documentinc","text":"| inc ( expression : Dict [ Union [ ExpressionField , str ], Any ], session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , skip_sync : bool = False , ** kwargs , ,) Increment Example: class Sample ( Document ): one : int await Document . find ( Sample . one == 1 ) . inc ({ Sample . one : 100 }) Uses Inc operator Arguments : expression : Dict[Union[ExpressionField, str], Any] session : Optional[ClientSession] - pymongo session bulk_writer : Optional[BulkWriter] - bulk writer skip_sync : bool - skip doc syncing. Available for the direct instances only Returns : self","title":"Document.inc"},{"location":"api-documentation/document/#documentdelete","text":"| @wrap_with_actions ( EventTypes . DELETE ) | async delete ( session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , link_rule : DeleteRules = DeleteRules . DO_NOTHING , skip_actions : Optional [ List [ Union [ ActionDirections , str ]]] = None , ** pymongo_kwargs , ,) -> Optional [ DeleteResult ] Delete the document Arguments : :param **pymongo_kwargs: pymongo native parameters for delete operation - session : Optional[ClientSession] - pymongo session. - bulk_writer : \"BulkWriter\" - Beanie bulk writer - link_rule : DeleteRules - rules for link fields Returns : Optional[DeleteResult] - pymongo DeleteResult instance.","title":"Document.delete"},{"location":"api-documentation/document/#documentdelete_all","text":"| @classmethod | async delete_all ( cls , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) -> Optional [ DeleteResult ] Delete all the documents Arguments : :param **pymongo_kwargs: pymongo native parameters for delete operation - session : Optional[ClientSession] - pymongo session. - bulk_writer : \"BulkWriter\" - Beanie bulk writer Returns : Optional[DeleteResult] - pymongo DeleteResult instance.","title":"Document.delete_all"},{"location":"api-documentation/document/#documentuse_state_management","text":"| @classmethod | use_state_management ( cls ) -> bool Is state management turned on Returns : bool","title":"Document.use_state_management"},{"location":"api-documentation/document/#documentstate_management_save_previous","text":"| @classmethod | state_management_save_previous ( cls ) -> bool Should we save the previous state after a commit to database Returns : bool","title":"Document.state_management_save_previous"},{"location":"api-documentation/document/#documentstate_management_replace_objects","text":"| @classmethod | state_management_replace_objects ( cls ) -> bool Should objects be replaced when using state management Returns : bool","title":"Document.state_management_replace_objects"},{"location":"api-documentation/document/#documentget_saved_state","text":"| get_saved_state () -> Optional [ Dict [ str , Any ]] Saved state getter. It is protected property. Returns : Optional[Dict[str, Any]] - saved state","title":"Document.get_saved_state"},{"location":"api-documentation/document/#documentget_previous_saved_state","text":"| get_previous_saved_state () -> Optional [ Dict [ str , Any ]] Previous state getter. It is a protected property. Returns : Optional[Dict[str, Any]] - previous state","title":"Document.get_previous_saved_state"},{"location":"api-documentation/document/#documentget_settings","text":"| @classmethod | get_settings ( cls ) -> DocumentSettings Get document settings, which was created on the initialization step Returns : DocumentSettings class","title":"Document.get_settings"},{"location":"api-documentation/document/#documentinspect_collection","text":"| @classmethod | async inspect_collection ( cls , session : Optional [ ClientSession ] = None ) -> InspectionResult Check, if documents, stored in the MongoDB collection are compatible with the Document schema Returns : InspectionResult","title":"Document.inspect_collection"},{"location":"api-documentation/document/#documentdict","text":"| dict ( * , include : Union [ \"AbstractSetIntStr\" , \"MappingIntStrAny\" ] = None , exclude : Union [ \"AbstractSetIntStr\" , \"MappingIntStrAny\" ] = None , by_alias : bool = False , skip_defaults : bool = False , exclude_hidden : bool = True , exclude_unset : bool = False , exclude_defaults : bool = False , exclude_none : bool = False ) -> \"DictStrAny\" Overriding of the respective method from Pydantic Hides fields, marked as \"hidden","title":"Document.dict"},{"location":"api-documentation/fields/","text":"beanie.odm.fields Indexed Indexed ( typ , index_type = ASCENDING , ** kwargs ) Returns a subclass of typ with an extra attribute _indexed as a tuple: - Index 0: index_type such as pymongo.ASCENDING - Index 1: kwargs passed to IndexModel When instantiated the type of the result will actually be typ . PydanticObjectId class PydanticObjectId ( ObjectId ) Object Id field. Compatible with Pydantic. ExpressionField class ExpressionField ( str ) ExpressionField.__getitem__ | __getitem__ ( item ) Get sub field Arguments : item : name of the subfield Returns : ExpressionField ExpressionField.__getattr__ | __getattr__ ( item ) Get sub field Arguments : item : name of the subfield Returns : ExpressionField","title":"Fields"},{"location":"api-documentation/fields/#beanieodmfields","text":"","title":"beanie.odm.fields"},{"location":"api-documentation/fields/#indexed","text":"Indexed ( typ , index_type = ASCENDING , ** kwargs ) Returns a subclass of typ with an extra attribute _indexed as a tuple: - Index 0: index_type such as pymongo.ASCENDING - Index 1: kwargs passed to IndexModel When instantiated the type of the result will actually be typ .","title":"Indexed"},{"location":"api-documentation/fields/#pydanticobjectid","text":"class PydanticObjectId ( ObjectId ) Object Id field. Compatible with Pydantic.","title":"PydanticObjectId"},{"location":"api-documentation/fields/#expressionfield","text":"class ExpressionField ( str )","title":"ExpressionField"},{"location":"api-documentation/fields/#expressionfield__getitem__","text":"| __getitem__ ( item ) Get sub field Arguments : item : name of the subfield Returns : ExpressionField","title":"ExpressionField.__getitem__"},{"location":"api-documentation/fields/#expressionfield__getattr__","text":"| __getattr__ ( item ) Get sub field Arguments : item : name of the subfield Returns : ExpressionField","title":"ExpressionField.__getattr__"},{"location":"api-documentation/interfaces/","text":"beanie.odm.interfaces.aggregate AggregateInterface class AggregateInterface () AggregateInterface.aggregate | @classmethod | aggregate ( cls : Type [ DocType ], aggregation_pipeline : list , projection_model : Optional [ Type [ DocumentProjectionType ]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , ** pymongo_kwargs , ,) -> Union [ | AggregationQuery [ Dict [ str , Any ]], | AggregationQuery [ DocumentProjectionType ], | ] Aggregate over collection. Returns AggregationQuery query object Arguments : :param **pymongo_kwargs: pymongo native parameters for aggregate operation - aggregation_pipeline : list - aggregation pipeline - projection_model : Type[BaseModel] - session : Optional[ClientSession] - ignore_cache : bool Returns : AggregationQuery beanie.odm.interfaces.inheritance beanie.odm.interfaces.update UpdateMethods class UpdateMethods () Update methods UpdateMethods.set | set ( expression : Dict [ Union [ ExpressionField , str ], Any ], session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** kwargs ) Set values Example: class Sample ( Document ): one : int await Document . find ( Sample . one == 1 ) . set ({ Sample . one : 100 }) Uses Set operator Arguments : values to set - expression : Dict[Union[ExpressionField, str], Any] - keys and - session : Optional[ClientSession] - pymongo session - bulk_writer : Optional[BulkWriter] - bulk writer Returns : self UpdateMethods.current_date | current_date ( expression : Dict [ Union [ ExpressionField , str ], Any ], session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** kwargs ) Set current date Uses CurrentDate operator Arguments : expression : Dict[Union[ExpressionField, str], Any] session : Optional[ClientSession] - pymongo session bulk_writer : Optional[BulkWriter] - bulk writer Returns : self UpdateMethods.inc | inc ( expression : Dict [ Union [ ExpressionField , str ], Any ], session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** kwargs ) Increment Example: class Sample ( Document ): one : int await Document . find ( Sample . one == 1 ) . inc ({ Sample . one : 100 }) Uses Inc operator Arguments : expression : Dict[Union[ExpressionField, str], Any] session : Optional[ClientSession] - pymongo session bulk_writer : Optional[BulkWriter] - bulk writer Returns : self beanie.odm.interfaces.aggregation_methods AggregateMethods class AggregateMethods () Aggregate methods AggregateMethods.sum | async sum ( field : Union [ str , ExpressionField ], session : Optional [ ClientSession ] = None , ignore_cache : bool = False ) -> Optional [ float ] Sum of values of the given field Example: class Sample ( Document ): price : int count : int sum_count = await Document . find ( Sample . price <= 100 ) . sum ( Sample . count ) Arguments : field : Union[str, ExpressionField] session : Optional[ClientSession] - pymongo session ignore_cache : bool Returns : float - sum. None if there are no items. AggregateMethods.avg | async avg ( field , session : Optional [ ClientSession ] = None , ignore_cache : bool = False ) -> Optional [ float ] Average of values of the given field Example: class Sample ( Document ): price : int count : int avg_count = await Document . find ( Sample . price <= 100 ) . avg ( Sample . count ) Arguments : field : Union[str, ExpressionField] session : Optional[ClientSession] - pymongo session ignore_cache : bool Returns : Optional[float] - avg. None if there are no items. AggregateMethods.max | async max ( field : Union [ str , ExpressionField ], session : Optional [ ClientSession ] = None , ignore_cache : bool = False ) -> Optional [ float ] Max of the values of the given field Example: class Sample ( Document ): price : int count : int max_count = await Document . find ( Sample . price <= 100 ) . max ( Sample . count ) Arguments : field : Union[str, ExpressionField] session : Optional[ClientSession] - pymongo session Returns : float - max. None if there are no items. AggregateMethods.min | async min ( field : Union [ str , ExpressionField ], session : Optional [ ClientSession ] = None , ignore_cache : bool = False ) -> Optional [ float ] Min of the values of the given field Example: class Sample ( Document ): price : int count : int min_count = await Document . find ( Sample . price <= 100 ) . min ( Sample . count ) Arguments : field : Union[str, ExpressionField] session : Optional[ClientSession] - pymongo session Returns : float - min. None if there are no items. beanie.odm.interfaces.session SessionMethods class SessionMethods () Session methods SessionMethods.set_session | set_session ( session : Optional [ ClientSession ] = None ) Set pymongo session Arguments : session : Optional[ClientSession] - pymongo session Returns : beanie.odm.interfaces.getters beanie.odm.interfaces.find FindInterface class FindInterface () FindInterface.find_one | @classmethod | find_one ( cls : Type [ \"DocType\" ], * args : Union [ Mapping [ str , Any ], bool ], * , projection_model : Optional [ Type [ \"DocumentProjectionType\" ]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , fetch_links : bool = False , with_children : bool = False , ** pymongo_kwargs , ,) -> Union [ FindOne [ \"DocType\" ], FindOne [ \"DocumentProjectionType\" ]] Find one document by criteria. Returns FindOne query object. When awaited this will either return a document or None if no document exists for the search criteria. Arguments : :param * pymongo_kwargs: pymongo native parameters for find operation (if Document class contains links, this parameter must fit the respective parameter of the aggregate MongoDB function) - args : Mapping[str, Any] - search criteria - projection_model : Optional[Type[BaseModel]] - projection model - session : Optional[ClientSession] - pymongo session instance - ignore_cache : bool Returns : FindOne - find query instance FindInterface.find_many | @classmethod | find_many ( cls : Type [ \"DocType\" ], * args : Union [ Mapping [ str , Any ], bool ], * , projection_model : Optional [ Type [ \"DocumentProjectionType\" ]] = None , skip : Optional [ int ] = None , limit : Optional [ int ] = None , sort : Union [ None , str , List [ Tuple [ str , SortDirection ]]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , fetch_links : bool = False , with_children : bool = False , lazy_parse : bool = False , ** pymongo_kwargs , ,) -> Union [ FindMany [ \"DocType\" ], FindMany [ \"DocumentProjectionType\" ]] Find many documents by criteria. Returns FindMany query object Arguments : :param * pymongo_kwargs: pymongo native parameters for find operation (if Document class contains links, this parameter must fit the respective parameter of the aggregate MongoDB function) - args : Mapping[str, Any] - search criteria - skip : Optional[int] - The number of documents to omit. - limit : Optional[int] - The maximum number of results to return. - sort : Union[None, str, List[Tuple[str, SortDirection]]] - A key or a list of (key, direction) pairs specifying the sort order for this query. - projection_model : Optional[Type[BaseModel]] - projection model - session : Optional[ClientSession] - pymongo session - ignore_cache : bool - lazy_parse : bool Returns : FindMany - query instance FindInterface.find | @classmethod | find ( cls : Type [ \"DocType\" ], * args : Union [ Mapping [ str , Any ], bool ], * , projection_model : Optional [ Type [ \"DocumentProjectionType\" ]] = None , skip : Optional [ int ] = None , limit : Optional [ int ] = None , sort : Union [ None , str , List [ Tuple [ str , SortDirection ]]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , fetch_links : bool = False , with_children : bool = False , lazy_parse : bool = False , ** pymongo_kwargs , ,) -> Union [ FindMany [ \"DocType\" ], FindMany [ \"DocumentProjectionType\" ]] The same as find_many FindInterface.find_all | @classmethod | find_all ( cls : Type [ \"DocType\" ], skip : Optional [ int ] = None , limit : Optional [ int ] = None , sort : Union [ None , str , List [ Tuple [ str , SortDirection ]]] = None , projection_model : Optional [ Type [ \"DocumentProjectionType\" ]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , with_children : bool = False , lazy_parse : bool = False , ** pymongo_kwargs , ,) -> Union [ FindMany [ \"DocType\" ], FindMany [ \"DocumentProjectionType\" ]] Get all the documents Arguments : :param **pymongo_kwargs: pymongo native parameters for find operation (if Document class contains links, this parameter must fit the respective parameter of the aggregate MongoDB function) - skip : Optional[int] - The number of documents to omit. - limit : Optional[int] - The maximum number of results to return. - sort : Union[None, str, List[Tuple[str, SortDirection]]] - A key or a list of (key, direction) pairs specifying the sort order for this query. - projection_model : Optional[Type[BaseModel]] - projection model - session : Optional[ClientSession] - pymongo session Returns : FindMany - query instance FindInterface.all | @classmethod | all ( cls : Type [ \"DocType\" ], projection_model : Optional [ Type [ \"DocumentProjectionType\" ]] = None , skip : Optional [ int ] = None , limit : Optional [ int ] = None , sort : Union [ None , str , List [ Tuple [ str , SortDirection ]]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , with_children : bool = False , lazy_parse : bool = False , ** pymongo_kwargs , ,) -> Union [ FindMany [ \"DocType\" ], FindMany [ \"DocumentProjectionType\" ]] the same as find_all FindInterface.count | @classmethod | async count ( cls ) -> int Number of documents in the collections The same as find_all().count() Returns : int beanie.odm.interfaces.clone beanie.odm.interfaces.setters SettersInterface class SettersInterface () SettersInterface.set_collection | @classmethod | set_collection ( cls , collection ) Collection setter SettersInterface.set_database | @classmethod | set_database ( cls , database ) Database setter SettersInterface.set_collection_name | @classmethod | set_collection_name ( cls , name : str ) Collection name setter beanie.odm.interfaces.detector","title":"Interfaces"},{"location":"api-documentation/interfaces/#beanieodminterfacesaggregate","text":"","title":"beanie.odm.interfaces.aggregate"},{"location":"api-documentation/interfaces/#aggregateinterface","text":"class AggregateInterface ()","title":"AggregateInterface"},{"location":"api-documentation/interfaces/#aggregateinterfaceaggregate","text":"| @classmethod | aggregate ( cls : Type [ DocType ], aggregation_pipeline : list , projection_model : Optional [ Type [ DocumentProjectionType ]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , ** pymongo_kwargs , ,) -> Union [ | AggregationQuery [ Dict [ str , Any ]], | AggregationQuery [ DocumentProjectionType ], | ] Aggregate over collection. Returns AggregationQuery query object Arguments : :param **pymongo_kwargs: pymongo native parameters for aggregate operation - aggregation_pipeline : list - aggregation pipeline - projection_model : Type[BaseModel] - session : Optional[ClientSession] - ignore_cache : bool Returns : AggregationQuery","title":"AggregateInterface.aggregate"},{"location":"api-documentation/interfaces/#beanieodminterfacesinheritance","text":"","title":"beanie.odm.interfaces.inheritance"},{"location":"api-documentation/interfaces/#beanieodminterfacesupdate","text":"","title":"beanie.odm.interfaces.update"},{"location":"api-documentation/interfaces/#updatemethods","text":"class UpdateMethods () Update methods","title":"UpdateMethods"},{"location":"api-documentation/interfaces/#updatemethodsset","text":"| set ( expression : Dict [ Union [ ExpressionField , str ], Any ], session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** kwargs ) Set values Example: class Sample ( Document ): one : int await Document . find ( Sample . one == 1 ) . set ({ Sample . one : 100 }) Uses Set operator Arguments : values to set - expression : Dict[Union[ExpressionField, str], Any] - keys and - session : Optional[ClientSession] - pymongo session - bulk_writer : Optional[BulkWriter] - bulk writer Returns : self","title":"UpdateMethods.set"},{"location":"api-documentation/interfaces/#updatemethodscurrent_date","text":"| current_date ( expression : Dict [ Union [ ExpressionField , str ], Any ], session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** kwargs ) Set current date Uses CurrentDate operator Arguments : expression : Dict[Union[ExpressionField, str], Any] session : Optional[ClientSession] - pymongo session bulk_writer : Optional[BulkWriter] - bulk writer Returns : self","title":"UpdateMethods.current_date"},{"location":"api-documentation/interfaces/#updatemethodsinc","text":"| inc ( expression : Dict [ Union [ ExpressionField , str ], Any ], session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** kwargs ) Increment Example: class Sample ( Document ): one : int await Document . find ( Sample . one == 1 ) . inc ({ Sample . one : 100 }) Uses Inc operator Arguments : expression : Dict[Union[ExpressionField, str], Any] session : Optional[ClientSession] - pymongo session bulk_writer : Optional[BulkWriter] - bulk writer Returns : self","title":"UpdateMethods.inc"},{"location":"api-documentation/interfaces/#beanieodminterfacesaggregation_methods","text":"","title":"beanie.odm.interfaces.aggregation_methods"},{"location":"api-documentation/interfaces/#aggregatemethods","text":"class AggregateMethods () Aggregate methods","title":"AggregateMethods"},{"location":"api-documentation/interfaces/#aggregatemethodssum","text":"| async sum ( field : Union [ str , ExpressionField ], session : Optional [ ClientSession ] = None , ignore_cache : bool = False ) -> Optional [ float ] Sum of values of the given field Example: class Sample ( Document ): price : int count : int sum_count = await Document . find ( Sample . price <= 100 ) . sum ( Sample . count ) Arguments : field : Union[str, ExpressionField] session : Optional[ClientSession] - pymongo session ignore_cache : bool Returns : float - sum. None if there are no items.","title":"AggregateMethods.sum"},{"location":"api-documentation/interfaces/#aggregatemethodsavg","text":"| async avg ( field , session : Optional [ ClientSession ] = None , ignore_cache : bool = False ) -> Optional [ float ] Average of values of the given field Example: class Sample ( Document ): price : int count : int avg_count = await Document . find ( Sample . price <= 100 ) . avg ( Sample . count ) Arguments : field : Union[str, ExpressionField] session : Optional[ClientSession] - pymongo session ignore_cache : bool Returns : Optional[float] - avg. None if there are no items.","title":"AggregateMethods.avg"},{"location":"api-documentation/interfaces/#aggregatemethodsmax","text":"| async max ( field : Union [ str , ExpressionField ], session : Optional [ ClientSession ] = None , ignore_cache : bool = False ) -> Optional [ float ] Max of the values of the given field Example: class Sample ( Document ): price : int count : int max_count = await Document . find ( Sample . price <= 100 ) . max ( Sample . count ) Arguments : field : Union[str, ExpressionField] session : Optional[ClientSession] - pymongo session Returns : float - max. None if there are no items.","title":"AggregateMethods.max"},{"location":"api-documentation/interfaces/#aggregatemethodsmin","text":"| async min ( field : Union [ str , ExpressionField ], session : Optional [ ClientSession ] = None , ignore_cache : bool = False ) -> Optional [ float ] Min of the values of the given field Example: class Sample ( Document ): price : int count : int min_count = await Document . find ( Sample . price <= 100 ) . min ( Sample . count ) Arguments : field : Union[str, ExpressionField] session : Optional[ClientSession] - pymongo session Returns : float - min. None if there are no items.","title":"AggregateMethods.min"},{"location":"api-documentation/interfaces/#beanieodminterfacessession","text":"","title":"beanie.odm.interfaces.session"},{"location":"api-documentation/interfaces/#sessionmethods","text":"class SessionMethods () Session methods","title":"SessionMethods"},{"location":"api-documentation/interfaces/#sessionmethodsset_session","text":"| set_session ( session : Optional [ ClientSession ] = None ) Set pymongo session Arguments : session : Optional[ClientSession] - pymongo session Returns :","title":"SessionMethods.set_session"},{"location":"api-documentation/interfaces/#beanieodminterfacesgetters","text":"","title":"beanie.odm.interfaces.getters"},{"location":"api-documentation/interfaces/#beanieodminterfacesfind","text":"","title":"beanie.odm.interfaces.find"},{"location":"api-documentation/interfaces/#findinterface","text":"class FindInterface ()","title":"FindInterface"},{"location":"api-documentation/interfaces/#findinterfacefind_one","text":"| @classmethod | find_one ( cls : Type [ \"DocType\" ], * args : Union [ Mapping [ str , Any ], bool ], * , projection_model : Optional [ Type [ \"DocumentProjectionType\" ]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , fetch_links : bool = False , with_children : bool = False , ** pymongo_kwargs , ,) -> Union [ FindOne [ \"DocType\" ], FindOne [ \"DocumentProjectionType\" ]] Find one document by criteria. Returns FindOne query object. When awaited this will either return a document or None if no document exists for the search criteria. Arguments : :param * pymongo_kwargs: pymongo native parameters for find operation (if Document class contains links, this parameter must fit the respective parameter of the aggregate MongoDB function) - args : Mapping[str, Any] - search criteria - projection_model : Optional[Type[BaseModel]] - projection model - session : Optional[ClientSession] - pymongo session instance - ignore_cache : bool Returns : FindOne - find query instance","title":"FindInterface.find_one"},{"location":"api-documentation/interfaces/#findinterfacefind_many","text":"| @classmethod | find_many ( cls : Type [ \"DocType\" ], * args : Union [ Mapping [ str , Any ], bool ], * , projection_model : Optional [ Type [ \"DocumentProjectionType\" ]] = None , skip : Optional [ int ] = None , limit : Optional [ int ] = None , sort : Union [ None , str , List [ Tuple [ str , SortDirection ]]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , fetch_links : bool = False , with_children : bool = False , lazy_parse : bool = False , ** pymongo_kwargs , ,) -> Union [ FindMany [ \"DocType\" ], FindMany [ \"DocumentProjectionType\" ]] Find many documents by criteria. Returns FindMany query object Arguments : :param * pymongo_kwargs: pymongo native parameters for find operation (if Document class contains links, this parameter must fit the respective parameter of the aggregate MongoDB function) - args : Mapping[str, Any] - search criteria - skip : Optional[int] - The number of documents to omit. - limit : Optional[int] - The maximum number of results to return. - sort : Union[None, str, List[Tuple[str, SortDirection]]] - A key or a list of (key, direction) pairs specifying the sort order for this query. - projection_model : Optional[Type[BaseModel]] - projection model - session : Optional[ClientSession] - pymongo session - ignore_cache : bool - lazy_parse : bool Returns : FindMany - query instance","title":"FindInterface.find_many"},{"location":"api-documentation/interfaces/#findinterfacefind","text":"| @classmethod | find ( cls : Type [ \"DocType\" ], * args : Union [ Mapping [ str , Any ], bool ], * , projection_model : Optional [ Type [ \"DocumentProjectionType\" ]] = None , skip : Optional [ int ] = None , limit : Optional [ int ] = None , sort : Union [ None , str , List [ Tuple [ str , SortDirection ]]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , fetch_links : bool = False , with_children : bool = False , lazy_parse : bool = False , ** pymongo_kwargs , ,) -> Union [ FindMany [ \"DocType\" ], FindMany [ \"DocumentProjectionType\" ]] The same as find_many","title":"FindInterface.find"},{"location":"api-documentation/interfaces/#findinterfacefind_all","text":"| @classmethod | find_all ( cls : Type [ \"DocType\" ], skip : Optional [ int ] = None , limit : Optional [ int ] = None , sort : Union [ None , str , List [ Tuple [ str , SortDirection ]]] = None , projection_model : Optional [ Type [ \"DocumentProjectionType\" ]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , with_children : bool = False , lazy_parse : bool = False , ** pymongo_kwargs , ,) -> Union [ FindMany [ \"DocType\" ], FindMany [ \"DocumentProjectionType\" ]] Get all the documents Arguments : :param **pymongo_kwargs: pymongo native parameters for find operation (if Document class contains links, this parameter must fit the respective parameter of the aggregate MongoDB function) - skip : Optional[int] - The number of documents to omit. - limit : Optional[int] - The maximum number of results to return. - sort : Union[None, str, List[Tuple[str, SortDirection]]] - A key or a list of (key, direction) pairs specifying the sort order for this query. - projection_model : Optional[Type[BaseModel]] - projection model - session : Optional[ClientSession] - pymongo session Returns : FindMany - query instance","title":"FindInterface.find_all"},{"location":"api-documentation/interfaces/#findinterfaceall","text":"| @classmethod | all ( cls : Type [ \"DocType\" ], projection_model : Optional [ Type [ \"DocumentProjectionType\" ]] = None , skip : Optional [ int ] = None , limit : Optional [ int ] = None , sort : Union [ None , str , List [ Tuple [ str , SortDirection ]]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , with_children : bool = False , lazy_parse : bool = False , ** pymongo_kwargs , ,) -> Union [ FindMany [ \"DocType\" ], FindMany [ \"DocumentProjectionType\" ]] the same as find_all","title":"FindInterface.all"},{"location":"api-documentation/interfaces/#findinterfacecount","text":"| @classmethod | async count ( cls ) -> int Number of documents in the collections The same as find_all().count() Returns : int","title":"FindInterface.count"},{"location":"api-documentation/interfaces/#beanieodminterfacesclone","text":"","title":"beanie.odm.interfaces.clone"},{"location":"api-documentation/interfaces/#beanieodminterfacessetters","text":"","title":"beanie.odm.interfaces.setters"},{"location":"api-documentation/interfaces/#settersinterface","text":"class SettersInterface ()","title":"SettersInterface"},{"location":"api-documentation/interfaces/#settersinterfaceset_collection","text":"| @classmethod | set_collection ( cls , collection ) Collection setter","title":"SettersInterface.set_collection"},{"location":"api-documentation/interfaces/#settersinterfaceset_database","text":"| @classmethod | set_database ( cls , database ) Database setter","title":"SettersInterface.set_database"},{"location":"api-documentation/interfaces/#settersinterfaceset_collection_name","text":"| @classmethod | set_collection_name ( cls , name : str ) Collection name setter","title":"SettersInterface.set_collection_name"},{"location":"api-documentation/interfaces/#beanieodminterfacesdetector","text":"","title":"beanie.odm.interfaces.detector"},{"location":"api-documentation/query/","text":"beanie.odm.queries.update UpdateQuery class UpdateQuery ( UpdateMethods , SessionMethods , CloneInterface ) Update Query base class Inherited from: SessionMethods UpdateMethods UpdateQuery.update | update ( * args : Mapping [ str , Any ], * , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) -> \"UpdateQuery\" Provide modifications to the update query. Arguments : :param * pymongo_kwargs: pymongo native parameters for update operation - args : Union[dict, Mapping] - the modifications to apply. - session : Optional[ClientSession] - bulk_writer : Optional[BulkWriter] Returns : UpdateMany query UpdateQuery.upsert | upsert ( * args : Mapping [ str , Any ], * , on_insert : \"DocType\" , session : Optional [ ClientSession ] = None , ** pymongo_kwargs , ,) -> \"UpdateQuery\" Provide modifications to the upsert query. Arguments : document in the collection :param * pymongo_kwargs: pymongo native parameters for update operation - args : Union[dict, Mapping] - the modifications to apply. - on_insert : DocType - document to insert if there is no matched - session : Optional[ClientSession] Returns : UpdateMany query UpdateQuery.__await__ | __await__ () -> Generator [ | Any , None , Union [ UpdateResult , InsertOneResult , Optional [ \"DocType\" ]] | ] Run the query Returns : UpdateMany class UpdateMany ( UpdateQuery ) Update Many query class Inherited from: UpdateQuery UpdateMany.update_many | update_many ( * args : Mapping [ str , Any ], * , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) Provide modifications to the update query Arguments : :param * pymongo_kwargs: pymongo native parameters for update operation - args : Union[dict, Mapping] - the modifications to apply. - session : Optional[ClientSession] - bulk_writer : \"BulkWriter\" - Beanie bulk writer Returns : UpdateMany query UpdateOne class UpdateOne ( UpdateQuery ) Update One query class Inherited from: UpdateQuery UpdateOne.update_one | update_one ( * args : Mapping [ str , Any ], * , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) Provide modifications to the update query. The same as update() Arguments : :param * pymongo_kwargs: pymongo native parameters for update operation - args : Union[dict, Mapping] - the modifications to apply. - session : Optional[ClientSession] - bulk_writer : \"BulkWriter\" - Beanie bulk writer Returns : UpdateMany query beanie.odm.queries.delete DeleteQuery class DeleteQuery ( SessionMethods , CloneInterface ) Deletion Query DeleteMany class DeleteMany ( DeleteQuery ) DeleteMany.__await__ | __await__ () -> Generator [ DeleteResult , None , Optional [ DeleteResult ]] Run the query Returns : DeleteOne class DeleteOne ( DeleteQuery ) DeleteOne.__await__ | __await__ () -> Generator [ DeleteResult , None , Optional [ DeleteResult ]] Run the query Returns : beanie.odm.queries.cursor BaseCursorQuery class BaseCursorQuery ( Generic [ CursorResultType ]) BaseCursorQuery class. Wrapper over AsyncIOMotorCursor, which parse result with model BaseCursorQuery.to_list | async to_list ( length : Optional [ int ] = None ) -> List [ CursorResultType ] Get list of documents Arguments : length : Optional[int] - length of the list Returns : Union[List[BaseModel], List[Dict[str, Any]]] beanie.odm.queries.find FindQuery class FindQuery ( Generic [ FindQueryResultType ], UpdateMethods , SessionMethods , CloneInterface ) Find Query base class Inherited from: SessionMethods UpdateMethods FindQuery.get_filter_query | get_filter_query () -> Mapping [ str , Any ] Returns: MongoDB filter query FindQuery.update | update ( * args : Mapping [ str , Any ], * , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) Create Update with modifications query and provide search criteria there Arguments : args : *Mapping[str,Any] - the modifications to apply. session : Optional[ClientSession] bulk_writer : Optional[BulkWriter] Returns : UpdateMany query FindQuery.upsert | upsert ( * args : Mapping [ str , Any ], * , on_insert : \"DocType\" , session : Optional [ ClientSession ] = None , ** pymongo_kwargs , ,) Create Update with modifications query and provide search criteria there Arguments : document in the collection - args : *Mapping[str,Any] - the modifications to apply. - on_insert : DocType - document to insert if there is no matched - session : Optional[ClientSession] Returns : UpdateMany query FindQuery.delete | delete ( session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) -> Union [ DeleteOne , DeleteMany ] Provide search criteria to the Delete query Arguments : session : Optional[ClientSession] Returns : Union[DeleteOne, DeleteMany] FindQuery.project | project ( projection_model ) Apply projection parameter Arguments : projection_model : Optional[Type[BaseModel]] - projection model Returns : self FindQuery.count | async count () -> int Number of found documents Returns : int FindQuery.exists | async exists () -> bool If find query will return anything Returns : bool FindMany class FindMany ( FindQuery [ FindQueryResultType ], BaseCursorQuery [ FindQueryResultType ], AggregateMethods ) Find Many query class Inherited from: FindQuery BaseCursorQuery - async generator AggregateMethods FindMany.find_many | find_many ( * args : Union [ Mapping [ str , Any ], bool ], * , projection_model : Optional [ Type [ FindQueryProjectionType ]] = None , skip : Optional [ int ] = None , limit : Optional [ int ] = None , sort : Union [ None , str , List [ Tuple [ str , SortDirection ]]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , fetch_links : bool = False , lazy_parse : bool = False , ** pymongo_kwargs , ,) -> Union [ | \"FindMany[FindQueryResultType]\" , \"FindMany[FindQueryProjectionType]\" | ] Find many documents by criteria Arguments : or a list of (key, direction) pairs specifying the sort order for this query. :param * pymongo_kwargs: pymongo native parameters for find operation (if Document class contains links, this parameter must fit the respective parameter of the aggregate MongoDB function) - args : Mapping[str, Any] - search criteria - skip : Optional[int] - The number of documents to omit. - limit : Optional[int] - The maximum number of results to return. - sort : Union[None, str, List[Tuple[str, SortDirection]]] - A key - projection_model : Optional[Type[BaseModel]] - projection model - session : Optional[ClientSession] - pymongo session - ignore_cache : bool Returns : FindMany - query instance FindMany.project | project ( projection_model : Optional [ Type [ FindQueryProjectionType ]]) -> Union [ | \"FindMany[FindQueryResultType]\" , \"FindMany[FindQueryProjectionType]\" | ] Apply projection parameter Arguments : projection_model : Optional[Type[BaseModel]] - projection model Returns : self FindMany.find | find ( * args : Union [ Mapping [ str , Any ], bool ], * , projection_model : Optional [ Type [ FindQueryProjectionType ]] = None , skip : Optional [ int ] = None , limit : Optional [ int ] = None , sort : Union [ None , str , List [ Tuple [ str , SortDirection ]]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , fetch_links : bool = False , lazy_parse : bool = False , ** pymongo_kwargs , ,) -> Union [ | \"FindMany[FindQueryResultType]\" , \"FindMany[FindQueryProjectionType]\" | ] The same as find_many(...) FindMany.sort | sort ( * args : Optional [ | Union [ | str , Tuple [ str , SortDirection ], List [ Tuple [ str , SortDirection ]] | ] | ]) -> \"FindMany[FindQueryResultType]\" Add sort parameters Arguments : List[Tuple[str, SortDirection]]] - A key or a tuple (key, direction) or a list of (key, direction) pairs specifying the sort order for this query. - args : Union[str, Tuple[str, SortDirection], Returns : self FindMany.skip | skip ( n : Optional [ int ]) -> \"FindMany[FindQueryResultType]\" Set skip parameter Arguments : n : int Returns : self FindMany.limit | limit ( n : Optional [ int ]) -> \"FindMany[FindQueryResultType]\" Set limit parameter Arguments : n : int Returns : FindMany.update_many | update_many ( * args : Mapping [ str , Any ], * , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) -> UpdateMany Provide search criteria to the UpdateMany query Arguments : args : *Mapping[str,Any] - the modifications to apply. session : Optional[ClientSession] Returns : UpdateMany query FindMany.delete_many | delete_many ( session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) -> DeleteMany Provide search criteria to the DeleteMany query Arguments : session : Returns : DeleteMany query FindMany.aggregate | aggregate ( aggregation_pipeline : List [ Any ], projection_model : Optional [ Type [ FindQueryProjectionType ]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , ** pymongo_kwargs , ,) -> Union [ | AggregationQuery [ Dict [ str , Any ]], | AggregationQuery [ FindQueryProjectionType ], | ] Provide search criteria to the AggregationQuery Arguments : https://docs.mongodb.com/manual/core/aggregation-pipeline/ - aggregation_pipeline : list - aggregation pipeline. MongoDB doc: - projection_model : Type[BaseModel] - Projection Model - session : Optional[ClientSession] - PyMongo session - ignore_cache : bool Returns : AggregationQuery FindMany.first_or_none | async first_or_none () -> Optional [ FindQueryResultType ] Returns the first found element or None if no elements were found FindOne class FindOne ( FindQuery [ FindQueryResultType ]) Find One query class Inherited from: FindQuery FindOne.project | project ( projection_model : Optional [ Type [ FindQueryProjectionType ]] = None ) -> Union [ | \"FindOne[FindQueryResultType]\" , \"FindOne[FindQueryProjectionType]\" | ] Apply projection parameter Arguments : projection_model : Optional[Type[BaseModel]] - projection model Returns : self FindOne.find_one | find_one ( * args : Union [ Mapping [ str , Any ], bool ], * , projection_model : Optional [ Type [ FindQueryProjectionType ]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , fetch_links : bool = False , ** pymongo_kwargs , ,) -> Union [ | \"FindOne[FindQueryResultType]\" , \"FindOne[FindQueryProjectionType]\" | ] Find one document by criteria Arguments : :param * pymongo_kwargs: pymongo native parameters for find operation (if Document class contains links, this parameter must fit the respective parameter of the aggregate MongoDB function) - args : Mapping[str, Any] - search criteria - projection_model : Optional[Type[BaseModel]] - projection model - session : Optional[ClientSession] - pymongo session - ignore_cache : bool Returns : FindOne - query instance FindOne.update_one | update_one ( * args : Mapping [ str , Any ], * , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) -> UpdateOne Create UpdateOne query using modifications and provide search criteria there Arguments : args : *Mapping[str,Any] - the modifications to apply session : Optional[ClientSession] - PyMongo sessions Returns : UpdateOne query FindOne.delete_one | delete_one ( session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) -> DeleteOne Provide search criteria to the DeleteOne query Arguments : session : Optional[ClientSession] - PyMongo sessions Returns : DeleteOne query FindOne.replace_one | async replace_one ( document : \"DocType\" , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None ) -> Optional [ UpdateResult ] Replace found document by provided Arguments : document : Document - document, which will replace the found one session : Optional[ClientSession] - PyMongo session bulk_writer : Optional[BulkWriter] - Beanie bulk writer Returns : UpdateResult FindOne.__await__ | __await__ () -> Generator [ Coroutine , Any , Optional [ FindQueryResultType ]] Run the query Returns : BaseModel beanie.odm.queries.aggregation AggregationQuery class AggregationQuery ( Generic [ AggregationProjectionType ], BaseCursorQuery [ AggregationProjectionType ], SessionMethods , CloneInterface ) Aggregation Query Inherited from: SessionMethods - session methods BaseCursorQuery - async generator","title":"Query"},{"location":"api-documentation/query/#beanieodmqueriesupdate","text":"","title":"beanie.odm.queries.update"},{"location":"api-documentation/query/#updatequery","text":"class UpdateQuery ( UpdateMethods , SessionMethods , CloneInterface ) Update Query base class Inherited from: SessionMethods UpdateMethods","title":"UpdateQuery"},{"location":"api-documentation/query/#updatequeryupdate","text":"| update ( * args : Mapping [ str , Any ], * , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) -> \"UpdateQuery\" Provide modifications to the update query. Arguments : :param * pymongo_kwargs: pymongo native parameters for update operation - args : Union[dict, Mapping] - the modifications to apply. - session : Optional[ClientSession] - bulk_writer : Optional[BulkWriter] Returns : UpdateMany query","title":"UpdateQuery.update"},{"location":"api-documentation/query/#updatequeryupsert","text":"| upsert ( * args : Mapping [ str , Any ], * , on_insert : \"DocType\" , session : Optional [ ClientSession ] = None , ** pymongo_kwargs , ,) -> \"UpdateQuery\" Provide modifications to the upsert query. Arguments : document in the collection :param * pymongo_kwargs: pymongo native parameters for update operation - args : Union[dict, Mapping] - the modifications to apply. - on_insert : DocType - document to insert if there is no matched - session : Optional[ClientSession] Returns : UpdateMany query","title":"UpdateQuery.upsert"},{"location":"api-documentation/query/#updatequery__await__","text":"| __await__ () -> Generator [ | Any , None , Union [ UpdateResult , InsertOneResult , Optional [ \"DocType\" ]] | ] Run the query Returns :","title":"UpdateQuery.__await__"},{"location":"api-documentation/query/#updatemany","text":"class UpdateMany ( UpdateQuery ) Update Many query class Inherited from: UpdateQuery","title":"UpdateMany"},{"location":"api-documentation/query/#updatemanyupdate_many","text":"| update_many ( * args : Mapping [ str , Any ], * , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) Provide modifications to the update query Arguments : :param * pymongo_kwargs: pymongo native parameters for update operation - args : Union[dict, Mapping] - the modifications to apply. - session : Optional[ClientSession] - bulk_writer : \"BulkWriter\" - Beanie bulk writer Returns : UpdateMany query","title":"UpdateMany.update_many"},{"location":"api-documentation/query/#updateone","text":"class UpdateOne ( UpdateQuery ) Update One query class Inherited from: UpdateQuery","title":"UpdateOne"},{"location":"api-documentation/query/#updateoneupdate_one","text":"| update_one ( * args : Mapping [ str , Any ], * , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) Provide modifications to the update query. The same as update() Arguments : :param * pymongo_kwargs: pymongo native parameters for update operation - args : Union[dict, Mapping] - the modifications to apply. - session : Optional[ClientSession] - bulk_writer : \"BulkWriter\" - Beanie bulk writer Returns : UpdateMany query","title":"UpdateOne.update_one"},{"location":"api-documentation/query/#beanieodmqueriesdelete","text":"","title":"beanie.odm.queries.delete"},{"location":"api-documentation/query/#deletequery","text":"class DeleteQuery ( SessionMethods , CloneInterface ) Deletion Query","title":"DeleteQuery"},{"location":"api-documentation/query/#deletemany","text":"class DeleteMany ( DeleteQuery )","title":"DeleteMany"},{"location":"api-documentation/query/#deletemany__await__","text":"| __await__ () -> Generator [ DeleteResult , None , Optional [ DeleteResult ]] Run the query Returns :","title":"DeleteMany.__await__"},{"location":"api-documentation/query/#deleteone","text":"class DeleteOne ( DeleteQuery )","title":"DeleteOne"},{"location":"api-documentation/query/#deleteone__await__","text":"| __await__ () -> Generator [ DeleteResult , None , Optional [ DeleteResult ]] Run the query Returns :","title":"DeleteOne.__await__"},{"location":"api-documentation/query/#beanieodmqueriescursor","text":"","title":"beanie.odm.queries.cursor"},{"location":"api-documentation/query/#basecursorquery","text":"class BaseCursorQuery ( Generic [ CursorResultType ]) BaseCursorQuery class. Wrapper over AsyncIOMotorCursor, which parse result with model","title":"BaseCursorQuery"},{"location":"api-documentation/query/#basecursorqueryto_list","text":"| async to_list ( length : Optional [ int ] = None ) -> List [ CursorResultType ] Get list of documents Arguments : length : Optional[int] - length of the list Returns : Union[List[BaseModel], List[Dict[str, Any]]]","title":"BaseCursorQuery.to_list"},{"location":"api-documentation/query/#beanieodmqueriesfind","text":"","title":"beanie.odm.queries.find"},{"location":"api-documentation/query/#findquery","text":"class FindQuery ( Generic [ FindQueryResultType ], UpdateMethods , SessionMethods , CloneInterface ) Find Query base class Inherited from: SessionMethods UpdateMethods","title":"FindQuery"},{"location":"api-documentation/query/#findqueryget_filter_query","text":"| get_filter_query () -> Mapping [ str , Any ] Returns: MongoDB filter query","title":"FindQuery.get_filter_query"},{"location":"api-documentation/query/#findqueryupdate","text":"| update ( * args : Mapping [ str , Any ], * , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) Create Update with modifications query and provide search criteria there Arguments : args : *Mapping[str,Any] - the modifications to apply. session : Optional[ClientSession] bulk_writer : Optional[BulkWriter] Returns : UpdateMany query","title":"FindQuery.update"},{"location":"api-documentation/query/#findqueryupsert","text":"| upsert ( * args : Mapping [ str , Any ], * , on_insert : \"DocType\" , session : Optional [ ClientSession ] = None , ** pymongo_kwargs , ,) Create Update with modifications query and provide search criteria there Arguments : document in the collection - args : *Mapping[str,Any] - the modifications to apply. - on_insert : DocType - document to insert if there is no matched - session : Optional[ClientSession] Returns : UpdateMany query","title":"FindQuery.upsert"},{"location":"api-documentation/query/#findquerydelete","text":"| delete ( session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) -> Union [ DeleteOne , DeleteMany ] Provide search criteria to the Delete query Arguments : session : Optional[ClientSession] Returns : Union[DeleteOne, DeleteMany]","title":"FindQuery.delete"},{"location":"api-documentation/query/#findqueryproject","text":"| project ( projection_model ) Apply projection parameter Arguments : projection_model : Optional[Type[BaseModel]] - projection model Returns : self","title":"FindQuery.project"},{"location":"api-documentation/query/#findquerycount","text":"| async count () -> int Number of found documents Returns : int","title":"FindQuery.count"},{"location":"api-documentation/query/#findqueryexists","text":"| async exists () -> bool If find query will return anything Returns : bool","title":"FindQuery.exists"},{"location":"api-documentation/query/#findmany","text":"class FindMany ( FindQuery [ FindQueryResultType ], BaseCursorQuery [ FindQueryResultType ], AggregateMethods ) Find Many query class Inherited from: FindQuery BaseCursorQuery - async generator AggregateMethods","title":"FindMany"},{"location":"api-documentation/query/#findmanyfind_many","text":"| find_many ( * args : Union [ Mapping [ str , Any ], bool ], * , projection_model : Optional [ Type [ FindQueryProjectionType ]] = None , skip : Optional [ int ] = None , limit : Optional [ int ] = None , sort : Union [ None , str , List [ Tuple [ str , SortDirection ]]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , fetch_links : bool = False , lazy_parse : bool = False , ** pymongo_kwargs , ,) -> Union [ | \"FindMany[FindQueryResultType]\" , \"FindMany[FindQueryProjectionType]\" | ] Find many documents by criteria Arguments : or a list of (key, direction) pairs specifying the sort order for this query. :param * pymongo_kwargs: pymongo native parameters for find operation (if Document class contains links, this parameter must fit the respective parameter of the aggregate MongoDB function) - args : Mapping[str, Any] - search criteria - skip : Optional[int] - The number of documents to omit. - limit : Optional[int] - The maximum number of results to return. - sort : Union[None, str, List[Tuple[str, SortDirection]]] - A key - projection_model : Optional[Type[BaseModel]] - projection model - session : Optional[ClientSession] - pymongo session - ignore_cache : bool Returns : FindMany - query instance","title":"FindMany.find_many"},{"location":"api-documentation/query/#findmanyproject","text":"| project ( projection_model : Optional [ Type [ FindQueryProjectionType ]]) -> Union [ | \"FindMany[FindQueryResultType]\" , \"FindMany[FindQueryProjectionType]\" | ] Apply projection parameter Arguments : projection_model : Optional[Type[BaseModel]] - projection model Returns : self","title":"FindMany.project"},{"location":"api-documentation/query/#findmanyfind","text":"| find ( * args : Union [ Mapping [ str , Any ], bool ], * , projection_model : Optional [ Type [ FindQueryProjectionType ]] = None , skip : Optional [ int ] = None , limit : Optional [ int ] = None , sort : Union [ None , str , List [ Tuple [ str , SortDirection ]]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , fetch_links : bool = False , lazy_parse : bool = False , ** pymongo_kwargs , ,) -> Union [ | \"FindMany[FindQueryResultType]\" , \"FindMany[FindQueryProjectionType]\" | ] The same as find_many(...)","title":"FindMany.find"},{"location":"api-documentation/query/#findmanysort","text":"| sort ( * args : Optional [ | Union [ | str , Tuple [ str , SortDirection ], List [ Tuple [ str , SortDirection ]] | ] | ]) -> \"FindMany[FindQueryResultType]\" Add sort parameters Arguments : List[Tuple[str, SortDirection]]] - A key or a tuple (key, direction) or a list of (key, direction) pairs specifying the sort order for this query. - args : Union[str, Tuple[str, SortDirection], Returns : self","title":"FindMany.sort"},{"location":"api-documentation/query/#findmanyskip","text":"| skip ( n : Optional [ int ]) -> \"FindMany[FindQueryResultType]\" Set skip parameter Arguments : n : int Returns : self","title":"FindMany.skip"},{"location":"api-documentation/query/#findmanylimit","text":"| limit ( n : Optional [ int ]) -> \"FindMany[FindQueryResultType]\" Set limit parameter Arguments : n : int Returns :","title":"FindMany.limit"},{"location":"api-documentation/query/#findmanyupdate_many","text":"| update_many ( * args : Mapping [ str , Any ], * , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) -> UpdateMany Provide search criteria to the UpdateMany query Arguments : args : *Mapping[str,Any] - the modifications to apply. session : Optional[ClientSession] Returns : UpdateMany query","title":"FindMany.update_many"},{"location":"api-documentation/query/#findmanydelete_many","text":"| delete_many ( session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) -> DeleteMany Provide search criteria to the DeleteMany query Arguments : session : Returns : DeleteMany query","title":"FindMany.delete_many"},{"location":"api-documentation/query/#findmanyaggregate","text":"| aggregate ( aggregation_pipeline : List [ Any ], projection_model : Optional [ Type [ FindQueryProjectionType ]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , ** pymongo_kwargs , ,) -> Union [ | AggregationQuery [ Dict [ str , Any ]], | AggregationQuery [ FindQueryProjectionType ], | ] Provide search criteria to the AggregationQuery Arguments : https://docs.mongodb.com/manual/core/aggregation-pipeline/ - aggregation_pipeline : list - aggregation pipeline. MongoDB doc: - projection_model : Type[BaseModel] - Projection Model - session : Optional[ClientSession] - PyMongo session - ignore_cache : bool Returns : AggregationQuery","title":"FindMany.aggregate"},{"location":"api-documentation/query/#findmanyfirst_or_none","text":"| async first_or_none () -> Optional [ FindQueryResultType ] Returns the first found element or None if no elements were found","title":"FindMany.first_or_none"},{"location":"api-documentation/query/#findone","text":"class FindOne ( FindQuery [ FindQueryResultType ]) Find One query class Inherited from: FindQuery","title":"FindOne"},{"location":"api-documentation/query/#findoneproject","text":"| project ( projection_model : Optional [ Type [ FindQueryProjectionType ]] = None ) -> Union [ | \"FindOne[FindQueryResultType]\" , \"FindOne[FindQueryProjectionType]\" | ] Apply projection parameter Arguments : projection_model : Optional[Type[BaseModel]] - projection model Returns : self","title":"FindOne.project"},{"location":"api-documentation/query/#findonefind_one","text":"| find_one ( * args : Union [ Mapping [ str , Any ], bool ], * , projection_model : Optional [ Type [ FindQueryProjectionType ]] = None , session : Optional [ ClientSession ] = None , ignore_cache : bool = False , fetch_links : bool = False , ** pymongo_kwargs , ,) -> Union [ | \"FindOne[FindQueryResultType]\" , \"FindOne[FindQueryProjectionType]\" | ] Find one document by criteria Arguments : :param * pymongo_kwargs: pymongo native parameters for find operation (if Document class contains links, this parameter must fit the respective parameter of the aggregate MongoDB function) - args : Mapping[str, Any] - search criteria - projection_model : Optional[Type[BaseModel]] - projection model - session : Optional[ClientSession] - pymongo session - ignore_cache : bool Returns : FindOne - query instance","title":"FindOne.find_one"},{"location":"api-documentation/query/#findoneupdate_one","text":"| update_one ( * args : Mapping [ str , Any ], * , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) -> UpdateOne Create UpdateOne query using modifications and provide search criteria there Arguments : args : *Mapping[str,Any] - the modifications to apply session : Optional[ClientSession] - PyMongo sessions Returns : UpdateOne query","title":"FindOne.update_one"},{"location":"api-documentation/query/#findonedelete_one","text":"| delete_one ( session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None , ** pymongo_kwargs , ,) -> DeleteOne Provide search criteria to the DeleteOne query Arguments : session : Optional[ClientSession] - PyMongo sessions Returns : DeleteOne query","title":"FindOne.delete_one"},{"location":"api-documentation/query/#findonereplace_one","text":"| async replace_one ( document : \"DocType\" , session : Optional [ ClientSession ] = None , bulk_writer : Optional [ BulkWriter ] = None ) -> Optional [ UpdateResult ] Replace found document by provided Arguments : document : Document - document, which will replace the found one session : Optional[ClientSession] - PyMongo session bulk_writer : Optional[BulkWriter] - Beanie bulk writer Returns : UpdateResult","title":"FindOne.replace_one"},{"location":"api-documentation/query/#findone__await__","text":"| __await__ () -> Generator [ Coroutine , Any , Optional [ FindQueryResultType ]] Run the query Returns : BaseModel","title":"FindOne.__await__"},{"location":"api-documentation/query/#beanieodmqueriesaggregation","text":"","title":"beanie.odm.queries.aggregation"},{"location":"api-documentation/query/#aggregationquery","text":"class AggregationQuery ( Generic [ AggregationProjectionType ], BaseCursorQuery [ AggregationProjectionType ], SessionMethods , CloneInterface ) Aggregation Query Inherited from: SessionMethods - session methods BaseCursorQuery - async generator","title":"AggregationQuery"},{"location":"api-documentation/operators/find/","text":"beanie.odm.operators.find.bitwise BitsAllClear class BitsAllClear ( BaseFindBitwiseOperator ) $bitsAllClear query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/bitsAllClear/ BitsAllSet class BitsAllSet ( BaseFindBitwiseOperator ) $bitsAllSet query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/bitsAllSet/ BitsAnyClear class BitsAnyClear ( BaseFindBitwiseOperator ) $bitsAnyClear query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/bitsAnyClear/ BitsAnySet class BitsAnySet ( BaseFindBitwiseOperator ) $bitsAnySet query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/bitsAnySet/ beanie.odm.operators.find.comparison Eq class Eq ( BaseFindComparisonOperator ) equal query operator Example : class Product ( Document ): price : float Eq ( Product . price , 2 ) Will return query object like { \"price\" : 2 } MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/eq/ GT class GT ( BaseFindComparisonOperator ) $gt query operator Example : class Product ( Document ): price : float GT ( Product . price , 2 ) Will return query object like { \"price\" : { \"$gt\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/gt/ GTE class GTE ( BaseFindComparisonOperator ) $gte query operator Example : class Product ( Document ): price : float GTE ( Product . price , 2 ) Will return query object like { \"price\" : { \"$gte\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/gte/ In class In ( BaseFindComparisonOperator ) $in query operator Example : class Product ( Document ): price : float In ( Product . price , [ 2 , 3 , 4 ]) Will return query object like { \"price\" : { \"$in\" : [ 2 , 3 , 4 ]}} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/in/ NotIn class NotIn ( BaseFindComparisonOperator ) $nin query operator Example : class Product ( Document ): price : float NotIn ( Product . price , [ 2 , 3 , 4 ]) Will return query object like { \"price\" : { \"$nin\" : [ 2 , 3 , 4 ]}} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/nin/ LT class LT ( BaseFindComparisonOperator ) $lt query operator Example : class Product ( Document ): price : float LT ( Product . price , 2 ) Will return query object like { \"price\" : { \"$lt\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/lt/ LTE class LTE ( BaseFindComparisonOperator ) $lte query operator Example : class Product ( Document ): price : float LTE ( Product . price , 2 ) Will return query object like { \"price\" : { \"$lte\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/lte/ NE class NE ( BaseFindComparisonOperator ) $ne query operator Example : class Product ( Document ): price : float NE ( Product . price , 2 ) Will return query object like { \"price\" : { \"$ne\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/ne/ beanie.odm.operators.find.element Exists class Exists ( BaseFindElementOperator ) $exists query operator Example : class Product ( Document ): price : float Exists ( Product . price , True ) Will return query object like { \"price\" : { \"$exists\" : True }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/exists/ Type class Type ( BaseFindElementOperator ) $type query operator Example : class Product ( Document ): price : float Type ( Product . price , \"decimal\" ) Will return query object like { \"price\" : { \"$type\" : \"decimal\" }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/type/ beanie.odm.operators.find.logical Or class Or ( LogicalOperatorForListOfExpressions ) $or query operator Example : class Product ( Document ): price : float category : str Or ({ Product . price < 10 }, { Product . category == \"Sweets\" }) Will return query object like { \"$or\" : [{ \"price\" : { \"$lt\" : 10 }}, { \"category\" : \"Sweets\" }]} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/or/ And class And ( LogicalOperatorForListOfExpressions ) $and query operator Example : class Product ( Document ): price : float category : str And ({ Product . price < 10 }, { Product . category == \"Sweets\" }) Will return query object like { \"$and\" : [{ \"price\" : { \"$lt\" : 10 }}, { \"category\" : \"Sweets\" }]} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/and/ Nor class Nor ( BaseFindLogicalOperator ) $nor query operator Example : class Product ( Document ): price : float category : str Nor ({ Product . price < 10 }, { Product . category == \"Sweets\" }) Will return query object like { \"$nor\" : [{ \"price\" : { \"$lt\" : 10 }}, { \"category\" : \"Sweets\" }]} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/nor/ Not class Not ( BaseFindLogicalOperator ) $not query operator Example : class Product ( Document ): price : float category : str Not ({ Product . price < 10 }) Will return query object like { \"$not\" : { \"price\" : { \"$lt\" : 10 }}} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/not/ beanie.odm.operators.find.geospatial GeoIntersects class GeoIntersects ( BaseFindGeospatialOperator ) $geoIntersects query operator Example : class GeoObject ( BaseModel ): type : str = \"Point\" coordinates : Tuple [ float , float ] class Place ( Document ): geo : GeoObject class Collection : name = \"places\" indexes = [ [( \"geo\" , pymongo . GEOSPHERE )], # GEO index ] GeoIntersects ( Place . geo , \"Polygon\" , [[ 0 , 0 ], [ 1 , 1 ], [ 3 , 3 ]]) Will return query object like { \"geo\" : { \"$geoIntersects\" : { \"$geometry\" : { \"type\" : \"Polygon\" , \"coordinates\" : [[ 0 , 0 ], [ 1 , 1 ], [ 3 , 3 ]], } } } } MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/geoIntersects/ GeoWithin class GeoWithin ( BaseFindGeospatialOperator ) $geoWithin query operator Example : class GeoObject ( BaseModel ): type : str = \"Point\" coordinates : Tuple [ float , float ] class Place ( Document ): geo : GeoObject class Collection : name = \"places\" indexes = [ [( \"geo\" , pymongo . GEOSPHERE )], # GEO index ] GeoWithin ( Place . geo , \"Polygon\" , [[ 0 , 0 ], [ 1 , 1 ], [ 3 , 3 ]]) Will return query object like { \"geo\" : { \"$geoWithin\" : { \"$geometry\" : { \"type\" : \"Polygon\" , \"coordinates\" : [[ 0 , 0 ], [ 1 , 1 ], [ 3 , 3 ]], } } } } MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/geoWithin/ Near class Near ( BaseFindGeospatialOperator ) $near query operator Example : class GeoObject ( BaseModel ): type : str = \"Point\" coordinates : Tuple [ float , float ] class Place ( Document ): geo : GeoObject class Collection : name = \"places\" indexes = [ [( \"geo\" , pymongo . GEOSPHERE )], # GEO index ] Near ( Place . geo , 1.2345 , 2.3456 , min_distance = 500 ) Will return query object like { \"geo\" : { \"$near\" : { \"$geometry\" : { \"type\" : \"Point\" , \"coordinates\" : [ 1.2345 , 2.3456 ], }, \"$maxDistance\" : 500 , } } } MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/near/ NearSphere class NearSphere ( Near ) $nearSphere query operator Example : class GeoObject ( BaseModel ): type : str = \"Point\" coordinates : Tuple [ float , float ] class Place ( Document ): geo : GeoObject class Collection : name = \"places\" indexes = [ [( \"geo\" , pymongo . GEOSPHERE )], # GEO index ] NearSphere ( Place . geo , 1.2345 , 2.3456 , min_distance = 500 ) Will return query object like { \"geo\" : { \"$nearSphere\" : { \"$geometry\" : { \"type\" : \"Point\" , \"coordinates\" : [ 1.2345 , 2.3456 ], }, \"$maxDistance\" : 500 , } } } MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/nearSphere/ beanie.odm.operators.find.evaluation Expr class Expr ( BaseFindEvaluationOperator ) $type query operator Example : class Sample ( Document ): one : int two : int Expr ({ \"$gt\" : [ \"$one\" , \"$two\" ]}) Will return query object like { \"$expr\" : { \"$gt\" : [ \"$one\" , \"$two\" ]}} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/expr/ JsonSchema class JsonSchema ( BaseFindEvaluationOperator ) $jsonSchema query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/jsonSchema/ Mod class Mod ( BaseFindEvaluationOperator ) $mod query operator Example : class Sample ( Document ): one : int Mod ( Sample . one , 4 , 0 ) Will return query object like { \"one\" : { \"$mod\" : [ 4 , 0 ] } } MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/mod/ RegEx class RegEx ( BaseFindEvaluationOperator ) $regex query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/regex/ Text class Text ( BaseFindEvaluationOperator ) $text query operator Example : class Sample ( Document ): description : Indexed ( str , pymongo . TEXT ) Text ( \"coffee\" ) Will return query object like { \"$text\" : { \"$search\" : \"coffee\" , \"$caseSensitive\" : False , \"$diacriticSensitive\" : False } } MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/text/ Text.__init__ | __init__ ( search : str , language : Optional [ str ] = None , case_sensitive : bool = False , diacritic_sensitive : bool = False ) Arguments : search : str language : Optional[str] = None case_sensitive : bool = False diacritic_sensitive : bool = False Where class Where ( BaseFindEvaluationOperator ) $where query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/where/ beanie.odm.operators.find.array All class All ( BaseFindArrayOperator ) $all array query operator Example : class Sample ( Document ): results : List [ int ] All ( Sample . results , [ 80 , 85 ]) Will return query object like { \"results\" : { \"$all\" : [ 80 , 85 ]}} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/all ElemMatch class ElemMatch ( BaseFindArrayOperator ) $elemMatch array query operator Example : class Sample ( Document ): results : List [ int ] ElemMatch ( Sample . results , [ 80 , 85 ]) Will return query object like { \"results\" : { \"$elemMatch\" : [ 80 , 85 ]}} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/elemMatch/ Size class Size ( BaseFindArrayOperator ) $size array query operator Example : class Sample ( Document ): results : List [ int ] Size ( Sample . results , 2 ) Will return query object like { \"results\" : { \"$size\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/size/","title":"Find"},{"location":"api-documentation/operators/find/#beanieodmoperatorsfindbitwise","text":"","title":"beanie.odm.operators.find.bitwise"},{"location":"api-documentation/operators/find/#bitsallclear","text":"class BitsAllClear ( BaseFindBitwiseOperator ) $bitsAllClear query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/bitsAllClear/","title":"BitsAllClear"},{"location":"api-documentation/operators/find/#bitsallset","text":"class BitsAllSet ( BaseFindBitwiseOperator ) $bitsAllSet query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/bitsAllSet/","title":"BitsAllSet"},{"location":"api-documentation/operators/find/#bitsanyclear","text":"class BitsAnyClear ( BaseFindBitwiseOperator ) $bitsAnyClear query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/bitsAnyClear/","title":"BitsAnyClear"},{"location":"api-documentation/operators/find/#bitsanyset","text":"class BitsAnySet ( BaseFindBitwiseOperator ) $bitsAnySet query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/bitsAnySet/","title":"BitsAnySet"},{"location":"api-documentation/operators/find/#beanieodmoperatorsfindcomparison","text":"","title":"beanie.odm.operators.find.comparison"},{"location":"api-documentation/operators/find/#eq","text":"class Eq ( BaseFindComparisonOperator ) equal query operator Example : class Product ( Document ): price : float Eq ( Product . price , 2 ) Will return query object like { \"price\" : 2 } MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/eq/","title":"Eq"},{"location":"api-documentation/operators/find/#gt","text":"class GT ( BaseFindComparisonOperator ) $gt query operator Example : class Product ( Document ): price : float GT ( Product . price , 2 ) Will return query object like { \"price\" : { \"$gt\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/gt/","title":"GT"},{"location":"api-documentation/operators/find/#gte","text":"class GTE ( BaseFindComparisonOperator ) $gte query operator Example : class Product ( Document ): price : float GTE ( Product . price , 2 ) Will return query object like { \"price\" : { \"$gte\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/gte/","title":"GTE"},{"location":"api-documentation/operators/find/#in","text":"class In ( BaseFindComparisonOperator ) $in query operator Example : class Product ( Document ): price : float In ( Product . price , [ 2 , 3 , 4 ]) Will return query object like { \"price\" : { \"$in\" : [ 2 , 3 , 4 ]}} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/in/","title":"In"},{"location":"api-documentation/operators/find/#notin","text":"class NotIn ( BaseFindComparisonOperator ) $nin query operator Example : class Product ( Document ): price : float NotIn ( Product . price , [ 2 , 3 , 4 ]) Will return query object like { \"price\" : { \"$nin\" : [ 2 , 3 , 4 ]}} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/nin/","title":"NotIn"},{"location":"api-documentation/operators/find/#lt","text":"class LT ( BaseFindComparisonOperator ) $lt query operator Example : class Product ( Document ): price : float LT ( Product . price , 2 ) Will return query object like { \"price\" : { \"$lt\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/lt/","title":"LT"},{"location":"api-documentation/operators/find/#lte","text":"class LTE ( BaseFindComparisonOperator ) $lte query operator Example : class Product ( Document ): price : float LTE ( Product . price , 2 ) Will return query object like { \"price\" : { \"$lte\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/lte/","title":"LTE"},{"location":"api-documentation/operators/find/#ne","text":"class NE ( BaseFindComparisonOperator ) $ne query operator Example : class Product ( Document ): price : float NE ( Product . price , 2 ) Will return query object like { \"price\" : { \"$ne\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/ne/","title":"NE"},{"location":"api-documentation/operators/find/#beanieodmoperatorsfindelement","text":"","title":"beanie.odm.operators.find.element"},{"location":"api-documentation/operators/find/#exists","text":"class Exists ( BaseFindElementOperator ) $exists query operator Example : class Product ( Document ): price : float Exists ( Product . price , True ) Will return query object like { \"price\" : { \"$exists\" : True }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/exists/","title":"Exists"},{"location":"api-documentation/operators/find/#type","text":"class Type ( BaseFindElementOperator ) $type query operator Example : class Product ( Document ): price : float Type ( Product . price , \"decimal\" ) Will return query object like { \"price\" : { \"$type\" : \"decimal\" }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/type/","title":"Type"},{"location":"api-documentation/operators/find/#beanieodmoperatorsfindlogical","text":"","title":"beanie.odm.operators.find.logical"},{"location":"api-documentation/operators/find/#or","text":"class Or ( LogicalOperatorForListOfExpressions ) $or query operator Example : class Product ( Document ): price : float category : str Or ({ Product . price < 10 }, { Product . category == \"Sweets\" }) Will return query object like { \"$or\" : [{ \"price\" : { \"$lt\" : 10 }}, { \"category\" : \"Sweets\" }]} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/or/","title":"Or"},{"location":"api-documentation/operators/find/#and","text":"class And ( LogicalOperatorForListOfExpressions ) $and query operator Example : class Product ( Document ): price : float category : str And ({ Product . price < 10 }, { Product . category == \"Sweets\" }) Will return query object like { \"$and\" : [{ \"price\" : { \"$lt\" : 10 }}, { \"category\" : \"Sweets\" }]} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/and/","title":"And"},{"location":"api-documentation/operators/find/#nor","text":"class Nor ( BaseFindLogicalOperator ) $nor query operator Example : class Product ( Document ): price : float category : str Nor ({ Product . price < 10 }, { Product . category == \"Sweets\" }) Will return query object like { \"$nor\" : [{ \"price\" : { \"$lt\" : 10 }}, { \"category\" : \"Sweets\" }]} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/nor/","title":"Nor"},{"location":"api-documentation/operators/find/#not","text":"class Not ( BaseFindLogicalOperator ) $not query operator Example : class Product ( Document ): price : float category : str Not ({ Product . price < 10 }) Will return query object like { \"$not\" : { \"price\" : { \"$lt\" : 10 }}} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/not/","title":"Not"},{"location":"api-documentation/operators/find/#beanieodmoperatorsfindgeospatial","text":"","title":"beanie.odm.operators.find.geospatial"},{"location":"api-documentation/operators/find/#geointersects","text":"class GeoIntersects ( BaseFindGeospatialOperator ) $geoIntersects query operator Example : class GeoObject ( BaseModel ): type : str = \"Point\" coordinates : Tuple [ float , float ] class Place ( Document ): geo : GeoObject class Collection : name = \"places\" indexes = [ [( \"geo\" , pymongo . GEOSPHERE )], # GEO index ] GeoIntersects ( Place . geo , \"Polygon\" , [[ 0 , 0 ], [ 1 , 1 ], [ 3 , 3 ]]) Will return query object like { \"geo\" : { \"$geoIntersects\" : { \"$geometry\" : { \"type\" : \"Polygon\" , \"coordinates\" : [[ 0 , 0 ], [ 1 , 1 ], [ 3 , 3 ]], } } } } MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/geoIntersects/","title":"GeoIntersects"},{"location":"api-documentation/operators/find/#geowithin","text":"class GeoWithin ( BaseFindGeospatialOperator ) $geoWithin query operator Example : class GeoObject ( BaseModel ): type : str = \"Point\" coordinates : Tuple [ float , float ] class Place ( Document ): geo : GeoObject class Collection : name = \"places\" indexes = [ [( \"geo\" , pymongo . GEOSPHERE )], # GEO index ] GeoWithin ( Place . geo , \"Polygon\" , [[ 0 , 0 ], [ 1 , 1 ], [ 3 , 3 ]]) Will return query object like { \"geo\" : { \"$geoWithin\" : { \"$geometry\" : { \"type\" : \"Polygon\" , \"coordinates\" : [[ 0 , 0 ], [ 1 , 1 ], [ 3 , 3 ]], } } } } MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/geoWithin/","title":"GeoWithin"},{"location":"api-documentation/operators/find/#near","text":"class Near ( BaseFindGeospatialOperator ) $near query operator Example : class GeoObject ( BaseModel ): type : str = \"Point\" coordinates : Tuple [ float , float ] class Place ( Document ): geo : GeoObject class Collection : name = \"places\" indexes = [ [( \"geo\" , pymongo . GEOSPHERE )], # GEO index ] Near ( Place . geo , 1.2345 , 2.3456 , min_distance = 500 ) Will return query object like { \"geo\" : { \"$near\" : { \"$geometry\" : { \"type\" : \"Point\" , \"coordinates\" : [ 1.2345 , 2.3456 ], }, \"$maxDistance\" : 500 , } } } MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/near/","title":"Near"},{"location":"api-documentation/operators/find/#nearsphere","text":"class NearSphere ( Near ) $nearSphere query operator Example : class GeoObject ( BaseModel ): type : str = \"Point\" coordinates : Tuple [ float , float ] class Place ( Document ): geo : GeoObject class Collection : name = \"places\" indexes = [ [( \"geo\" , pymongo . GEOSPHERE )], # GEO index ] NearSphere ( Place . geo , 1.2345 , 2.3456 , min_distance = 500 ) Will return query object like { \"geo\" : { \"$nearSphere\" : { \"$geometry\" : { \"type\" : \"Point\" , \"coordinates\" : [ 1.2345 , 2.3456 ], }, \"$maxDistance\" : 500 , } } } MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/nearSphere/","title":"NearSphere"},{"location":"api-documentation/operators/find/#beanieodmoperatorsfindevaluation","text":"","title":"beanie.odm.operators.find.evaluation"},{"location":"api-documentation/operators/find/#expr","text":"class Expr ( BaseFindEvaluationOperator ) $type query operator Example : class Sample ( Document ): one : int two : int Expr ({ \"$gt\" : [ \"$one\" , \"$two\" ]}) Will return query object like { \"$expr\" : { \"$gt\" : [ \"$one\" , \"$two\" ]}} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/expr/","title":"Expr"},{"location":"api-documentation/operators/find/#jsonschema","text":"class JsonSchema ( BaseFindEvaluationOperator ) $jsonSchema query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/jsonSchema/","title":"JsonSchema"},{"location":"api-documentation/operators/find/#mod","text":"class Mod ( BaseFindEvaluationOperator ) $mod query operator Example : class Sample ( Document ): one : int Mod ( Sample . one , 4 , 0 ) Will return query object like { \"one\" : { \"$mod\" : [ 4 , 0 ] } } MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/mod/","title":"Mod"},{"location":"api-documentation/operators/find/#regex","text":"class RegEx ( BaseFindEvaluationOperator ) $regex query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/regex/","title":"RegEx"},{"location":"api-documentation/operators/find/#text","text":"class Text ( BaseFindEvaluationOperator ) $text query operator Example : class Sample ( Document ): description : Indexed ( str , pymongo . TEXT ) Text ( \"coffee\" ) Will return query object like { \"$text\" : { \"$search\" : \"coffee\" , \"$caseSensitive\" : False , \"$diacriticSensitive\" : False } } MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/text/","title":"Text"},{"location":"api-documentation/operators/find/#text__init__","text":"| __init__ ( search : str , language : Optional [ str ] = None , case_sensitive : bool = False , diacritic_sensitive : bool = False ) Arguments : search : str language : Optional[str] = None case_sensitive : bool = False diacritic_sensitive : bool = False","title":"Text.__init__"},{"location":"api-documentation/operators/find/#where","text":"class Where ( BaseFindEvaluationOperator ) $where query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/where/","title":"Where"},{"location":"api-documentation/operators/find/#beanieodmoperatorsfindarray","text":"","title":"beanie.odm.operators.find.array"},{"location":"api-documentation/operators/find/#all","text":"class All ( BaseFindArrayOperator ) $all array query operator Example : class Sample ( Document ): results : List [ int ] All ( Sample . results , [ 80 , 85 ]) Will return query object like { \"results\" : { \"$all\" : [ 80 , 85 ]}} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/all","title":"All"},{"location":"api-documentation/operators/find/#elemmatch","text":"class ElemMatch ( BaseFindArrayOperator ) $elemMatch array query operator Example : class Sample ( Document ): results : List [ int ] ElemMatch ( Sample . results , [ 80 , 85 ]) Will return query object like { \"results\" : { \"$elemMatch\" : [ 80 , 85 ]}} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/elemMatch/","title":"ElemMatch"},{"location":"api-documentation/operators/find/#size","text":"class Size ( BaseFindArrayOperator ) $size array query operator Example : class Sample ( Document ): results : List [ int ] Size ( Sample . results , 2 ) Will return query object like { \"results\" : { \"$size\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/query/size/","title":"Size"},{"location":"api-documentation/operators/update/","text":"beanie.odm.operators.update.bitwise Bit class Bit ( BaseUpdateBitwiseOperator ) $bit update query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/bit/ beanie.odm.operators.update.general Set class Set ( BaseUpdateGeneralOperator ) $set update query operator Example : class Sample ( Document ): one : int Set ({ Sample . one : 2 }) Will return query object like { \"$set\" : { \"one\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/set/ CurrentDate class CurrentDate ( BaseUpdateGeneralOperator ) $currentDate update query operator Example : class Sample ( Document ): ts : datetime CurrentDate ({ Sample . ts , True }) Will return query object like { \"$currentDate\" : { \"ts\" : True }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/currentDate/ Inc class Inc ( BaseUpdateGeneralOperator ) $inc update query operator Example : class Sample ( Document ): one : int Inc ({ Sample . one , 2 }) Will return query object like { \"$inc\" : { \"one\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/inc/ Min class Min ( BaseUpdateGeneralOperator ) $min update query operator Example : class Sample ( Document ): one : int Min ({ Sample . one , 2 }) Will return query object like { \"$min\" : { \"one\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/min/ Max class Max ( BaseUpdateGeneralOperator ) $max update query operator Example : class Sample ( Document ): one : int Max ({ Sample . one , 2 }) Will return query object like { \"$max\" : { \"one\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/max/ Mul class Mul ( BaseUpdateGeneralOperator ) $mul update query operator Example : class Sample ( Document ): one : int Mul ({ Sample . one , 2 }) Will return query object like { \"$mul\" : { \"one\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/mul/ Rename class Rename ( BaseUpdateGeneralOperator ) $rename update query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/rename/ SetOnInsert class SetOnInsert ( BaseUpdateGeneralOperator ) $setOnInsert update query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/setOnInsert/ Unset class Unset ( BaseUpdateGeneralOperator ) $unset update query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/unset/ beanie.odm.operators.update.array AddToSet class AddToSet ( BaseUpdateArrayOperator ) $addToSet update array query operator Example : class Sample ( Document ): results : List [ int ] AddToSet ({ Sample . results , 2 }) Will return query object like { \"$addToSet\" : { \"results\" : 2 }} MongoDB docs: https://docs.mongodb.com/manual/reference/operator/update/addToSet/ Pop class Pop ( BaseUpdateArrayOperator ) $pop update array query operator Example : class Sample ( Document ): results : List [ int ] Pop ({ Sample . results , 2 }) Will return query object like { \"$pop\" : { \"results\" : - 1 }} MongoDB docs: https://docs.mongodb.com/manual/reference/operator/update/pop/ Pull class Pull ( BaseUpdateArrayOperator ) $pull update array query operator Example : class Sample ( Document ): results : List [ int ] Pull ( In ( Sample . result , [ 1 , 2 , 3 , 4 , 5 ]) Will return query object like { \"$pull\" : { \"results\" : { $ in : [ 1 , 2 , 3 , 4 , 5 ] }}} MongoDB docs: https://docs.mongodb.com/manual/reference/operator/update/pull/ Push class Push ( BaseUpdateArrayOperator ) $push update array query operator Example : class Sample ( Document ): results : List [ int ] Push ({ Sample . results : 1 }) Will return query object like { \"$push\" : { \"results\" : 1 }} MongoDB docs: https://docs.mongodb.com/manual/reference/operator/update/push/ PullAll class PullAll ( BaseUpdateArrayOperator ) $pullAll update array query operator Example : class Sample ( Document ): results : List [ int ] PullAll ({ Sample . results : [ 0 , 5 ] }) Will return query object like { \"$pullAll\" : { \"results\" : [ 0 , 5 ] }} MongoDB docs: https://docs.mongodb.com/manual/reference/operator/update/pullAll/","title":"Update"},{"location":"api-documentation/operators/update/#beanieodmoperatorsupdatebitwise","text":"","title":"beanie.odm.operators.update.bitwise"},{"location":"api-documentation/operators/update/#bit","text":"class Bit ( BaseUpdateBitwiseOperator ) $bit update query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/bit/","title":"Bit"},{"location":"api-documentation/operators/update/#beanieodmoperatorsupdategeneral","text":"","title":"beanie.odm.operators.update.general"},{"location":"api-documentation/operators/update/#set","text":"class Set ( BaseUpdateGeneralOperator ) $set update query operator Example : class Sample ( Document ): one : int Set ({ Sample . one : 2 }) Will return query object like { \"$set\" : { \"one\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/set/","title":"Set"},{"location":"api-documentation/operators/update/#currentdate","text":"class CurrentDate ( BaseUpdateGeneralOperator ) $currentDate update query operator Example : class Sample ( Document ): ts : datetime CurrentDate ({ Sample . ts , True }) Will return query object like { \"$currentDate\" : { \"ts\" : True }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/currentDate/","title":"CurrentDate"},{"location":"api-documentation/operators/update/#inc","text":"class Inc ( BaseUpdateGeneralOperator ) $inc update query operator Example : class Sample ( Document ): one : int Inc ({ Sample . one , 2 }) Will return query object like { \"$inc\" : { \"one\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/inc/","title":"Inc"},{"location":"api-documentation/operators/update/#min","text":"class Min ( BaseUpdateGeneralOperator ) $min update query operator Example : class Sample ( Document ): one : int Min ({ Sample . one , 2 }) Will return query object like { \"$min\" : { \"one\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/min/","title":"Min"},{"location":"api-documentation/operators/update/#max","text":"class Max ( BaseUpdateGeneralOperator ) $max update query operator Example : class Sample ( Document ): one : int Max ({ Sample . one , 2 }) Will return query object like { \"$max\" : { \"one\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/max/","title":"Max"},{"location":"api-documentation/operators/update/#mul","text":"class Mul ( BaseUpdateGeneralOperator ) $mul update query operator Example : class Sample ( Document ): one : int Mul ({ Sample . one , 2 }) Will return query object like { \"$mul\" : { \"one\" : 2 }} MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/mul/","title":"Mul"},{"location":"api-documentation/operators/update/#rename","text":"class Rename ( BaseUpdateGeneralOperator ) $rename update query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/rename/","title":"Rename"},{"location":"api-documentation/operators/update/#setoninsert","text":"class SetOnInsert ( BaseUpdateGeneralOperator ) $setOnInsert update query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/setOnInsert/","title":"SetOnInsert"},{"location":"api-documentation/operators/update/#unset","text":"class Unset ( BaseUpdateGeneralOperator ) $unset update query operator MongoDB doc: https://docs.mongodb.com/manual/reference/operator/update/unset/","title":"Unset"},{"location":"api-documentation/operators/update/#beanieodmoperatorsupdatearray","text":"","title":"beanie.odm.operators.update.array"},{"location":"api-documentation/operators/update/#addtoset","text":"class AddToSet ( BaseUpdateArrayOperator ) $addToSet update array query operator Example : class Sample ( Document ): results : List [ int ] AddToSet ({ Sample . results , 2 }) Will return query object like { \"$addToSet\" : { \"results\" : 2 }} MongoDB docs: https://docs.mongodb.com/manual/reference/operator/update/addToSet/","title":"AddToSet"},{"location":"api-documentation/operators/update/#pop","text":"class Pop ( BaseUpdateArrayOperator ) $pop update array query operator Example : class Sample ( Document ): results : List [ int ] Pop ({ Sample . results , 2 }) Will return query object like { \"$pop\" : { \"results\" : - 1 }} MongoDB docs: https://docs.mongodb.com/manual/reference/operator/update/pop/","title":"Pop"},{"location":"api-documentation/operators/update/#pull","text":"class Pull ( BaseUpdateArrayOperator ) $pull update array query operator Example : class Sample ( Document ): results : List [ int ] Pull ( In ( Sample . result , [ 1 , 2 , 3 , 4 , 5 ]) Will return query object like { \"$pull\" : { \"results\" : { $ in : [ 1 , 2 , 3 , 4 , 5 ] }}} MongoDB docs: https://docs.mongodb.com/manual/reference/operator/update/pull/","title":"Pull"},{"location":"api-documentation/operators/update/#push","text":"class Push ( BaseUpdateArrayOperator ) $push update array query operator Example : class Sample ( Document ): results : List [ int ] Push ({ Sample . results : 1 }) Will return query object like { \"$push\" : { \"results\" : 1 }} MongoDB docs: https://docs.mongodb.com/manual/reference/operator/update/push/","title":"Push"},{"location":"api-documentation/operators/update/#pullall","text":"class PullAll ( BaseUpdateArrayOperator ) $pullAll update array query operator Example : class Sample ( Document ): results : List [ int ] PullAll ({ Sample . results : [ 0 , 5 ] }) Will return query object like { \"$pullAll\" : { \"results\" : [ 0 , 5 ] }} MongoDB docs: https://docs.mongodb.com/manual/reference/operator/update/pullAll/","title":"PullAll"},{"location":"tutorial/aggregation/","text":"Aggregations You can perform aggregation queries through beanie as well. For example, to calculate the average: # With a search: avg_price = await Product . find ( Product . category . name == \"Chocolate\" ) . avg ( Product . price ) # Over the whole collection: avg_price = await Product . avg ( Product . price ) A full list of available methods can be found here . You can also use the native PyMongo syntax by calling the aggregate method. However, as Beanie will not know what output to expect, you will have to supply a projection model yourself. If you do not supply a projection model, then a dictionary will be returned. class OutputItem ( BaseModel ): id : str = Field ( None , alias = \"_id\" ) total : float result = await Product . find ( Product . category . name == \"Chocolate\" ) . aggregate ( [{ \"$group\" : { \"_id\" : \"$category.name\" , \"total\" : { \"$avg\" : \"$price\" }}}], projection_model = OutputItem ) . to_list ()","title":"Aggregation"},{"location":"tutorial/aggregation/#aggregations","text":"You can perform aggregation queries through beanie as well. For example, to calculate the average: # With a search: avg_price = await Product . find ( Product . category . name == \"Chocolate\" ) . avg ( Product . price ) # Over the whole collection: avg_price = await Product . avg ( Product . price ) A full list of available methods can be found here . You can also use the native PyMongo syntax by calling the aggregate method. However, as Beanie will not know what output to expect, you will have to supply a projection model yourself. If you do not supply a projection model, then a dictionary will be returned. class OutputItem ( BaseModel ): id : str = Field ( None , alias = \"_id\" ) total : float result = await Product . find ( Product . category . name == \"Chocolate\" ) . aggregate ( [{ \"$group\" : { \"_id\" : \"$category.name\" , \"total\" : { \"$avg\" : \"$price\" }}}], projection_model = OutputItem ) . to_list ()","title":"Aggregations"},{"location":"tutorial/cache/","text":"Cache All query results could be locally cached. This feature must be explicitly turned on in the Settings inner class. class Sample ( Document ): num : int name : str class Settings : use_cache = True Beanie uses LRU cache with expiration time. You can set capacity (the maximum number of the cached queries) and expiration time in the Settings inner class. class Sample ( Document ): num : int name : str class Settings : use_cache = True cache_expiration_time = datetime . timedelta ( seconds = 10 ) cache_capacity = 5 Any query will be cached for this document class. # on the first call it will go to the database samples = await Sample . find ( num > 10 ) . to_list () # on the second - it will use cache instead samples = await Sample . find ( num > 10 ) . to_list () await asyncio . sleep ( 15 ) # if the expiration time was reached it will go to the database again samples = await Sample . find ( num > 10 ) . to_list ()","title":"Cache"},{"location":"tutorial/cache/#cache","text":"All query results could be locally cached. This feature must be explicitly turned on in the Settings inner class. class Sample ( Document ): num : int name : str class Settings : use_cache = True Beanie uses LRU cache with expiration time. You can set capacity (the maximum number of the cached queries) and expiration time in the Settings inner class. class Sample ( Document ): num : int name : str class Settings : use_cache = True cache_expiration_time = datetime . timedelta ( seconds = 10 ) cache_capacity = 5 Any query will be cached for this document class. # on the first call it will go to the database samples = await Sample . find ( num > 10 ) . to_list () # on the second - it will use cache instead samples = await Sample . find ( num > 10 ) . to_list () await asyncio . sleep ( 15 ) # if the expiration time was reached it will go to the database again samples = await Sample . find ( num > 10 ) . to_list ()","title":"Cache"},{"location":"tutorial/defining-a-document/","text":"Defining a document The Document class in Beanie is responsible for mapping and handling the data from the collection. It is inherited from the BaseModel Pydantic class, so it follows the same data typing and parsing behavior. from typing import Optional import pymongo from pydantic import BaseModel from beanie import Document , Indexed class Category ( BaseModel ): name : str description : str class Product ( Document ): # This is the model name : str description : Optional [ str ] = None price : Indexed ( float , pymongo . DESCENDING ) category : Category class Settings : name = \"products\" indexes = [ [ ( \"name\" , pymongo . TEXT ), ( \"description\" , pymongo . TEXT ), ], ] Fields As it was mentioned before, the Document class is inherited from the Pydantic BaseModel class. It uses all the same patterns of BaseModel . But also it has special types of fields: id Indexed id id field of the Document class reflects the unique _id field of the MongoDB document. Each object of the Document type has this field. The default type of this is PydanticObjectId . class Sample ( Document ): num : int description : str foo = await Sample . find_one ( Sample . num > 5 ) print ( foo . id ) # This will print id bar = await Sample . get ( foo . id ) # get by id If you prefer another type, you can set it up too. For example, UUID: from uuid import UUID , uuid4 from pydantic import Field class Sample ( Document ): id : UUID = Field ( default_factory = uuid4 ) num : int description : str Indexed To set up an index over a single field, the Indexed function can be used to wrap the type: from beanie import Indexed class Sample ( Document ): num : Indexed ( int ) description : str The Indexed function takes an optional argument index_type , which may be set to a pymongo index type: class Sample ( Document ): description : Indexed ( str , index_type = pymongo . TEXT ) The Indexed function also supports pymongo IndexModel kwargs arguments ( PyMongo Documentation ). For example, to create a unique index: class Sample ( Document ): name : Indexed ( str , unique = True ) Settings The inner class Settings is used to configure: MongoDB collection name Indexes Encoders Use of revision_id Use of cache Use of state management Validation on save Collection name To set MongoDB collection name, you can use the name field of the Settings inner class. class Sample ( Document ): num : int description : str class Settings : name = \"samples\" Indexes The indexes field of the inner Settings class is responsible for the indexes' setup. It is a list where items can be: Single key. Name of the document's field (this is equivalent to using the Indexed function described above) List of (key, direction) pairs. Key - string, name of the document's field. Direction - pymongo direction ( example: pymongo.ASCENDING ) pymongo.IndexModel instance - the most flexible option. PyMongo Documentation class DocumentTestModelWithIndex ( Document ): test_int : int test_list : List [ SubDocument ] test_str : str class Settings : indexes = [ \"test_int\" , [ ( \"test_int\" , pymongo . ASCENDING ), ( \"test_str\" , pymongo . DESCENDING ), ], IndexModel ( [( \"test_str\" , pymongo . DESCENDING )], name = \"test_string_index_DESCENDING\" , ), ] Encoders The bson_encoders field of the inner Settings class defines how the Python types are going to be represented when saved in the database. The default conversions can be overridden with this. The ip field in the following example is converted to String by default: from ipaddress import IPv4Address class Sample ( Document ): ip : IPv4Address Note: Default conversions are defined in beanie.odm.utils.bson.ENCODERS_BY_TYPE . However, if you want the ip field to be represented as Integer in the database, you need to override the default encoders like this: from ipaddress import IPv4Address class Sample ( Document ): ip : IPv4Address class Settings : bson_encoders = { IPv4Address : int } You can also define your own function for the encoding: from ipaddress import IPv4Address def ipv4address_to_int ( v : IPv4Address ): return int ( v ) class Sample ( Document ): ip : IPv4Address class Settings : bson_encoders = { IPv4Address : ipv4address_to_int }","title":"Defining a document"},{"location":"tutorial/defining-a-document/#defining-a-document","text":"The Document class in Beanie is responsible for mapping and handling the data from the collection. It is inherited from the BaseModel Pydantic class, so it follows the same data typing and parsing behavior. from typing import Optional import pymongo from pydantic import BaseModel from beanie import Document , Indexed class Category ( BaseModel ): name : str description : str class Product ( Document ): # This is the model name : str description : Optional [ str ] = None price : Indexed ( float , pymongo . DESCENDING ) category : Category class Settings : name = \"products\" indexes = [ [ ( \"name\" , pymongo . TEXT ), ( \"description\" , pymongo . TEXT ), ], ]","title":"Defining a document"},{"location":"tutorial/defining-a-document/#fields","text":"As it was mentioned before, the Document class is inherited from the Pydantic BaseModel class. It uses all the same patterns of BaseModel . But also it has special types of fields: id Indexed","title":"Fields"},{"location":"tutorial/defining-a-document/#id","text":"id field of the Document class reflects the unique _id field of the MongoDB document. Each object of the Document type has this field. The default type of this is PydanticObjectId . class Sample ( Document ): num : int description : str foo = await Sample . find_one ( Sample . num > 5 ) print ( foo . id ) # This will print id bar = await Sample . get ( foo . id ) # get by id If you prefer another type, you can set it up too. For example, UUID: from uuid import UUID , uuid4 from pydantic import Field class Sample ( Document ): id : UUID = Field ( default_factory = uuid4 ) num : int description : str","title":"id"},{"location":"tutorial/defining-a-document/#indexed","text":"To set up an index over a single field, the Indexed function can be used to wrap the type: from beanie import Indexed class Sample ( Document ): num : Indexed ( int ) description : str The Indexed function takes an optional argument index_type , which may be set to a pymongo index type: class Sample ( Document ): description : Indexed ( str , index_type = pymongo . TEXT ) The Indexed function also supports pymongo IndexModel kwargs arguments ( PyMongo Documentation ). For example, to create a unique index: class Sample ( Document ): name : Indexed ( str , unique = True )","title":"Indexed"},{"location":"tutorial/defining-a-document/#settings","text":"The inner class Settings is used to configure: MongoDB collection name Indexes Encoders Use of revision_id Use of cache Use of state management Validation on save","title":"Settings"},{"location":"tutorial/defining-a-document/#collection-name","text":"To set MongoDB collection name, you can use the name field of the Settings inner class. class Sample ( Document ): num : int description : str class Settings : name = \"samples\"","title":"Collection name"},{"location":"tutorial/defining-a-document/#indexes","text":"The indexes field of the inner Settings class is responsible for the indexes' setup. It is a list where items can be: Single key. Name of the document's field (this is equivalent to using the Indexed function described above) List of (key, direction) pairs. Key - string, name of the document's field. Direction - pymongo direction ( example: pymongo.ASCENDING ) pymongo.IndexModel instance - the most flexible option. PyMongo Documentation class DocumentTestModelWithIndex ( Document ): test_int : int test_list : List [ SubDocument ] test_str : str class Settings : indexes = [ \"test_int\" , [ ( \"test_int\" , pymongo . ASCENDING ), ( \"test_str\" , pymongo . DESCENDING ), ], IndexModel ( [( \"test_str\" , pymongo . DESCENDING )], name = \"test_string_index_DESCENDING\" , ), ]","title":"Indexes"},{"location":"tutorial/defining-a-document/#encoders","text":"The bson_encoders field of the inner Settings class defines how the Python types are going to be represented when saved in the database. The default conversions can be overridden with this. The ip field in the following example is converted to String by default: from ipaddress import IPv4Address class Sample ( Document ): ip : IPv4Address Note: Default conversions are defined in beanie.odm.utils.bson.ENCODERS_BY_TYPE . However, if you want the ip field to be represented as Integer in the database, you need to override the default encoders like this: from ipaddress import IPv4Address class Sample ( Document ): ip : IPv4Address class Settings : bson_encoders = { IPv4Address : int } You can also define your own function for the encoding: from ipaddress import IPv4Address def ipv4address_to_int ( v : IPv4Address ): return int ( v ) class Sample ( Document ): ip : IPv4Address class Settings : bson_encoders = { IPv4Address : ipv4address_to_int }","title":"Encoders"},{"location":"tutorial/event-based-actions/","text":"Event-based actions You can register methods as pre- or post- actions for document events. Currently supported events: Insert Replace Update SaveChanges Delete ValidateOnSave Currently supported directions: Before After Current operations creating events: insert() for Insert replace() for Replace save() triggers Insert if it is creating a new document, triggers Replace if it replaces an existing document save_changes() for SaveChanges insert() , replace() , save_changes() , and save() for ValidateOnSave set() , update() for Update delete() for Delete To register an action, you can use @before_event and @after_event decorators respectively: from beanie import Insert , Replace class Sample ( Document ): num : int name : str @before_event ( Insert ) def capitalize_name ( self ): self . name = self . name . capitalize () @after_event ( Replace ) def num_change ( self ): self . num -= 1 It is possible to register action for several events: from beanie import Insert , Replace class Sample ( Document ): num : int name : str @before_event ( Insert , Replace ) def capitalize_name ( self ): self . name = self . name . capitalize () This will capitalize the name field value before each document's Insert and Replace. And sync and async methods could work as actions. from beanie import Insert , Replace class Sample ( Document ): num : int name : str @after_event ( Insert , Replace ) async def send_callback ( self ): await client . send ( self . id ) Actions can be selectively skipped by passing the skip_actions argument when calling the operations that trigger events. skip_actions accepts a list of directions and action names. from beanie import After , Before , Insert , Replace class Sample ( Document ): num : int name : str @before_event ( Insert ) def capitalize_name ( self ): self . name = self . name . capitalize () @before_event ( Replace ) def redact_name ( self ): self . name = \"[REDACTED]\" @after_event ( Replace ) def num_change ( self ): self . num -= 1 sample = Sample () # capitalize_name will not be executed await sample . insert ( skip_actions = [ 'capitalize_name' ]) # num_change will not be executed await sample . replace ( skip_actions = [ After ]) # redact_name and num_change will not be executed await sample . replace ( skip_actions [ Before , 'num_change' ])","title":"Event-based actions"},{"location":"tutorial/event-based-actions/#event-based-actions","text":"You can register methods as pre- or post- actions for document events. Currently supported events: Insert Replace Update SaveChanges Delete ValidateOnSave Currently supported directions: Before After Current operations creating events: insert() for Insert replace() for Replace save() triggers Insert if it is creating a new document, triggers Replace if it replaces an existing document save_changes() for SaveChanges insert() , replace() , save_changes() , and save() for ValidateOnSave set() , update() for Update delete() for Delete To register an action, you can use @before_event and @after_event decorators respectively: from beanie import Insert , Replace class Sample ( Document ): num : int name : str @before_event ( Insert ) def capitalize_name ( self ): self . name = self . name . capitalize () @after_event ( Replace ) def num_change ( self ): self . num -= 1 It is possible to register action for several events: from beanie import Insert , Replace class Sample ( Document ): num : int name : str @before_event ( Insert , Replace ) def capitalize_name ( self ): self . name = self . name . capitalize () This will capitalize the name field value before each document's Insert and Replace. And sync and async methods could work as actions. from beanie import Insert , Replace class Sample ( Document ): num : int name : str @after_event ( Insert , Replace ) async def send_callback ( self ): await client . send ( self . id ) Actions can be selectively skipped by passing the skip_actions argument when calling the operations that trigger events. skip_actions accepts a list of directions and action names. from beanie import After , Before , Insert , Replace class Sample ( Document ): num : int name : str @before_event ( Insert ) def capitalize_name ( self ): self . name = self . name . capitalize () @before_event ( Replace ) def redact_name ( self ): self . name = \"[REDACTED]\" @after_event ( Replace ) def num_change ( self ): self . num -= 1 sample = Sample () # capitalize_name will not be executed await sample . insert ( skip_actions = [ 'capitalize_name' ]) # num_change will not be executed await sample . replace ( skip_actions = [ After ]) # redact_name and num_change will not be executed await sample . replace ( skip_actions [ Before , 'num_change' ])","title":"Event-based actions"},{"location":"tutorial/finding-documents/","text":"To populate the database, please run the examples from the previous section of the tutorial as we will be using the same setup here. Finding documents The basic syntax for finding multiple documents in the database is to call the class method find() or it's synonym find_many() with some search criteria (see next section): findresult = Product . find ( search_criteria ) This returns a FindMany object, which can be used to access the results in different ways. To loop through the results, use a async for loop: async for result in Product . find ( search_criteria ): print ( result ) If you prefer a list of the results, then you can call to_list() method: result = await Product . find ( search_criteria ) . to_list () To get the first document, you can use .first_or_none() method. It returns the first found document or None , if no documents were found. result = await Product . find ( search_criteria ) . first_or_none () Search criteria As search criteria, Beanie supports Python-based syntax. For comparisons Python comparison operators can be used on the class fields (and nested fields): products = await Product . find ( Product . price < 10 ) . to_list () This is supported for the following operators: == , > , >= , < , <= , != . Other MongoDB query operators can be used with the included wrappers. For example, the $in operator can be used as follows: from beanie.operators import In products = await Product . find ( In ( Product . category . name , [ \"Chocolate\" , \"Fruits\" ]) ) . to_list () The whole list of the find query operators can be found here . For more complex cases native PyMongo syntax is also supported: products = await Product . find ({ \"price\" : 1000 }) . to_list () Finding single documents Sometimes you will only need to find a single document. If you are searching by id , then you can use the get method: bar = await Product . get ( \"608da169eb9e17281f0ab2ff\" ) To find a single document via a single search criterion, you can use the find_one method: bar = await Product . find_one ( Product . name == \"Peanut Bar\" ) More complex queries Multiple search criteria If you have multiple criteria to search against, you can pass them as separate arguments to any of the find functions: chocolates = await Product . find ( Product . category . name == \"Chocolate\" , Product . price < 5 ) . to_list () Alternatively, you can chain find methods: chocolates = await Product . find ( Product . category . name == \"Chocolate\" ) . find ( Product . price < 5 ) . to_list () Sorting Sorting can be done with the sort method. You can pass it one or multiple fields to sort by. You may optionally specify a + or - (denoting ascending and descending respectively). chocolates = await Product . find ( Product . category . name == \"Chocolate\" ) . sort ( - Product . price , + Product . name ) . to_list () You can also specify fields as strings or as tuples: chocolates = await Product . find ( Product . category . name == \"Chocolate\" ) . sort ( \"-price\" , \"+name\" ) . to_list () chocolates = await Product . find ( Product . category . name == \"Chocolate\" ) . sort ( [ ( Product . price , pymongo . DESCENDING ), ( Product . name , pymongo . ASCENDING ), ] ) . to_list () Skip and limit To skip a certain number of documents, or limit the total number of elements returned, the skip and limit methods can be used: chocolates = await Product . find ( Product . category . name == \"Chocolate\" ) . skip ( 2 ) . to_list () chocolates = await Product . find ( Product . category . name == \"Chocolate\" ) . limit ( 2 ) . to_list () Projections When only a part of a document is required, projections can save a lot of database bandwidth and processing. For simple projections we can just define a pydantic model with the required fields and pass it to project() method: class ProductShortView ( BaseModel ): name : str price : float chocolates = await Product . find ( Product . category . name == \"Chocolate\" ) . project ( ProductShortView ) . to_list () For more complex projections an inner Settings class with a projection field can be added: class ProductView ( BaseModel ): name : str category : str class Settings : projection = { \"name\" : 1 , \"category\" : \"$category.name\" } chocolates = await Product . find ( Product . category . name == \"Chocolate\" ) . project ( ProductView ) . to_list () Finding all documents If you ever want to find all documents, you can use the find_all() class method. This is equivalent to find({}) .","title":"Finding documents"},{"location":"tutorial/finding-documents/#finding-documents","text":"The basic syntax for finding multiple documents in the database is to call the class method find() or it's synonym find_many() with some search criteria (see next section): findresult = Product . find ( search_criteria ) This returns a FindMany object, which can be used to access the results in different ways. To loop through the results, use a async for loop: async for result in Product . find ( search_criteria ): print ( result ) If you prefer a list of the results, then you can call to_list() method: result = await Product . find ( search_criteria ) . to_list () To get the first document, you can use .first_or_none() method. It returns the first found document or None , if no documents were found. result = await Product . find ( search_criteria ) . first_or_none ()","title":"Finding documents"},{"location":"tutorial/finding-documents/#search-criteria","text":"As search criteria, Beanie supports Python-based syntax. For comparisons Python comparison operators can be used on the class fields (and nested fields): products = await Product . find ( Product . price < 10 ) . to_list () This is supported for the following operators: == , > , >= , < , <= , != . Other MongoDB query operators can be used with the included wrappers. For example, the $in operator can be used as follows: from beanie.operators import In products = await Product . find ( In ( Product . category . name , [ \"Chocolate\" , \"Fruits\" ]) ) . to_list () The whole list of the find query operators can be found here . For more complex cases native PyMongo syntax is also supported: products = await Product . find ({ \"price\" : 1000 }) . to_list ()","title":"Search criteria"},{"location":"tutorial/finding-documents/#finding-single-documents","text":"Sometimes you will only need to find a single document. If you are searching by id , then you can use the get method: bar = await Product . get ( \"608da169eb9e17281f0ab2ff\" ) To find a single document via a single search criterion, you can use the find_one method: bar = await Product . find_one ( Product . name == \"Peanut Bar\" )","title":"Finding single documents"},{"location":"tutorial/finding-documents/#more-complex-queries","text":"","title":"More complex queries"},{"location":"tutorial/finding-documents/#multiple-search-criteria","text":"If you have multiple criteria to search against, you can pass them as separate arguments to any of the find functions: chocolates = await Product . find ( Product . category . name == \"Chocolate\" , Product . price < 5 ) . to_list () Alternatively, you can chain find methods: chocolates = await Product . find ( Product . category . name == \"Chocolate\" ) . find ( Product . price < 5 ) . to_list ()","title":"Multiple search criteria"},{"location":"tutorial/finding-documents/#sorting","text":"Sorting can be done with the sort method. You can pass it one or multiple fields to sort by. You may optionally specify a + or - (denoting ascending and descending respectively). chocolates = await Product . find ( Product . category . name == \"Chocolate\" ) . sort ( - Product . price , + Product . name ) . to_list () You can also specify fields as strings or as tuples: chocolates = await Product . find ( Product . category . name == \"Chocolate\" ) . sort ( \"-price\" , \"+name\" ) . to_list () chocolates = await Product . find ( Product . category . name == \"Chocolate\" ) . sort ( [ ( Product . price , pymongo . DESCENDING ), ( Product . name , pymongo . ASCENDING ), ] ) . to_list ()","title":"Sorting"},{"location":"tutorial/finding-documents/#skip-and-limit","text":"To skip a certain number of documents, or limit the total number of elements returned, the skip and limit methods can be used: chocolates = await Product . find ( Product . category . name == \"Chocolate\" ) . skip ( 2 ) . to_list () chocolates = await Product . find ( Product . category . name == \"Chocolate\" ) . limit ( 2 ) . to_list ()","title":"Skip and limit"},{"location":"tutorial/finding-documents/#projections","text":"When only a part of a document is required, projections can save a lot of database bandwidth and processing. For simple projections we can just define a pydantic model with the required fields and pass it to project() method: class ProductShortView ( BaseModel ): name : str price : float chocolates = await Product . find ( Product . category . name == \"Chocolate\" ) . project ( ProductShortView ) . to_list () For more complex projections an inner Settings class with a projection field can be added: class ProductView ( BaseModel ): name : str category : str class Settings : projection = { \"name\" : 1 , \"category\" : \"$category.name\" } chocolates = await Product . find ( Product . category . name == \"Chocolate\" ) . project ( ProductView ) . to_list ()","title":"Projections"},{"location":"tutorial/finding-documents/#finding-all-documents","text":"If you ever want to find all documents, you can use the find_all() class method. This is equivalent to find({}) .","title":"Finding all documents"},{"location":"tutorial/indexes/","text":"Indexes setup There are more than one way to set up indexes using Beanie Indexed function To set up an index over a single field, the Indexed function can be used to wrap the type and does not require a Settings class: from beanie import Document , Indexed class Sample ( Document ): num : Indexed ( int ) description : str The Indexed function takes an optional index_type argument, which may be set to a pymongo index type: import pymongo from beanie import Document , Indexed class Sample ( Document ): description : Indexed ( str , index_type = pymongo . TEXT ) The Indexed function also supports PyMongo's IndexModel kwargs arguments (see the PyMongo Documentation for details). For example, to create a unique index: from beanie import Document , Indexed class Sample ( Document ): name : Indexed ( str , unique = True ) Multi-field indexes The indexes field of the inner Settings class is responsible for more complex indexes. It is a list where items can be: Single key. Name of the document's field (this is equivalent to using the Indexed function described above without any additional arguments) List of (key, direction) pairs. Key - string, name of the document's field. Direction - pymongo direction ( example: pymongo.ASCENDING ) pymongo.IndexModel instance - the most flexible option. PyMongo Documentation import pymongo from pymongo import IndexModel from beanie import Document class Sample ( Document ): test_int : int test_str : str class Settings : indexes = [ \"test_int\" , [ ( \"test_int\" , pymongo . ASCENDING ), ( \"test_str\" , pymongo . DESCENDING ), ], IndexModel ( [( \"test_str\" , pymongo . DESCENDING )], name = \"test_string_index_DESCENDING\" , ), ]","title":"Indexes"},{"location":"tutorial/indexes/#indexes-setup","text":"There are more than one way to set up indexes using Beanie","title":"Indexes setup"},{"location":"tutorial/indexes/#indexed-function","text":"To set up an index over a single field, the Indexed function can be used to wrap the type and does not require a Settings class: from beanie import Document , Indexed class Sample ( Document ): num : Indexed ( int ) description : str The Indexed function takes an optional index_type argument, which may be set to a pymongo index type: import pymongo from beanie import Document , Indexed class Sample ( Document ): description : Indexed ( str , index_type = pymongo . TEXT ) The Indexed function also supports PyMongo's IndexModel kwargs arguments (see the PyMongo Documentation for details). For example, to create a unique index: from beanie import Document , Indexed class Sample ( Document ): name : Indexed ( str , unique = True )","title":"Indexed function"},{"location":"tutorial/indexes/#multi-field-indexes","text":"The indexes field of the inner Settings class is responsible for more complex indexes. It is a list where items can be: Single key. Name of the document's field (this is equivalent to using the Indexed function described above without any additional arguments) List of (key, direction) pairs. Key - string, name of the document's field. Direction - pymongo direction ( example: pymongo.ASCENDING ) pymongo.IndexModel instance - the most flexible option. PyMongo Documentation import pymongo from pymongo import IndexModel from beanie import Document class Sample ( Document ): test_int : int test_str : str class Settings : indexes = [ \"test_int\" , [ ( \"test_int\" , pymongo . ASCENDING ), ( \"test_str\" , pymongo . DESCENDING ), ], IndexModel ( [( \"test_str\" , pymongo . DESCENDING )], name = \"test_string_index_DESCENDING\" , ), ]","title":"Multi-field indexes"},{"location":"tutorial/inheritance/","text":"Inheritance for multi-model use case Beanie Documents support inheritance as any other Python classes. But there are additional features available if you mark the root model with the parameter is_root = True in the inner Settings class. This behavior is similar to UnionDoc , but you don't need an additional entity. Parent Document act like a \"controller\", that handles proper storing and fetches different Document types. Also, parent Document can have some shared attributes which are propagated to all children. All classes in the inheritance chain can be used as Link in foreign Documents . Depending on the business logic, parent Document can be like an \"abstract\" class that is not used to store objects of its type (like in the example below), as well as can be a full-fledged entity, like its children. Defining models To set the root model you have to set is_root = True in the inner Settings class. All the inherited documents (on any level) will be stored in the same collection. from typing import Optional , List from motor.motor_asyncio import AsyncIOMotorClient from pydantic import BaseModel from beanie import Document , Link , init_beanie class Vehicle ( Document ): \"\"\"Inheritance scheme bellow\"\"\" # Vehicle # / | \\ # / | \\ # Bicycle Bike Car # \\ # \\ # Bus # shared attribute for all children color : str class Settings : is_root = True class Fuelled ( BaseModel ): \"\"\"Just a mixin\"\"\" fuel : Optional [ str ] class Bicycle ( Vehicle ): \"\"\"Derived from Vehicle, will use its collection\"\"\" frame : int wheels : int class Bike ( Vehicle , Fuelled ): ... class Car ( Vehicle , Fuelled ): body : str class Bus ( Car , Fuelled ): \"\"\"Inheritance chain is Vehicle -> Car -> Bus, it is also stored in Vehicle collection\"\"\" seats : int class Owner ( Document ): vehicles : Optional [ List [ Link [ Vehicle ]]] Inserts Inserts work the same way as usual client = AsyncIOMotorClient () await init_beanie ( client . test_db , document_models = [ Vehicle , Bicycle , Bike , Car , Bus ]) bike_1 = await Bike ( color = 'black' , fuel = 'gasoline' ) . insert () car_1 = await Car ( color = 'grey' , body = 'sedan' , fuel = 'gasoline' ) . insert () car_2 = await Car ( color = 'white' , body = 'crossover' , fuel = 'diesel' ) . insert () bus_1 = await Bus ( color = 'white' , seats = 80 , body = 'bus' , fuel = 'diesel' ) . insert () bus_2 = await Bus ( color = 'yellow' , seats = 26 , body = 'minibus' , fuel = 'diesel' ) . insert () owner = await Owner ( name = 'John' , vehicles = [ car_1 , car_2 , bus_1 ]) . insert () Find operations With parameter with_children = True the find query results will contain all the children classes' objects. # this query returns vehicles of all types that have white color, becuase `with_children` is True white_vehicles = await Vehicle . find ( Vehicle . color == 'white' , with_children = True ) . to_list () # [ # Bicycle(..., color='white', frame=54, wheels=29), # Car(fuel='diesel', ..., color='white', body='crossover'), # Bus(fuel='diesel', ..., color='white', body='bus', seats=80) # ] If the search is based on a child, the query returns this child type and all sub-children (with parameter with_children=True ) cars_and_buses = await Car . find ( Car . fuel == 'diesel' , with_children = True ) . to_list () # [ # Car(fuel='diesel', ..., color='white', body='crossover'), # Bus(fuel='diesel', ..., color='white', body='bus', seats=80), # Bus(fuel='diesel', ..., color='yellow', body='minibus', seats=26) # ] If you need to return objects of the specific class only, you can use this class for finding: # however it is possible to limit by Vehicle type cars_only = await Car . find () . to_list () # [ # Car(fuel='gasoline', ..., color='grey', body='sedan'), # Car(fuel='diesel', ..., color='white', body='crossover') # ] To get a single Document it is not necessary to know the type. You can query using the parent class await Vehicle . get ( bus_2 . id , with_children = True ) # returns Bus instance: # Bus(fuel='diesel', ..., color='yellow', body='minibus', seats=26) Relations Linked documents will be resolved into the respective classes owner = await Owner . get ( owner . id , fetch_links = True ) print ( owner . vehicles ) # [ # Car(fuel='diesel', ..., color='white', body='crossover'), # Bus(fuel='diesel', ..., color='white', body='bus', seats=80), # Car(fuel='gasoline', ..., color='grey', body='sedan') # ] The same result will be if the owner gets objects without fetching the links, and they will be fetched manually later Other All other operations work the same way as for simple Documents await Bike . find () . update ({ \"$set\" : { Bike . color : 'yellow' }}) await Car . find_one ( Car . body == 'sedan' )","title":"Inheritance"},{"location":"tutorial/inheritance/#inheritance-for-multi-model-use-case","text":"Beanie Documents support inheritance as any other Python classes. But there are additional features available if you mark the root model with the parameter is_root = True in the inner Settings class. This behavior is similar to UnionDoc , but you don't need an additional entity. Parent Document act like a \"controller\", that handles proper storing and fetches different Document types. Also, parent Document can have some shared attributes which are propagated to all children. All classes in the inheritance chain can be used as Link in foreign Documents . Depending on the business logic, parent Document can be like an \"abstract\" class that is not used to store objects of its type (like in the example below), as well as can be a full-fledged entity, like its children.","title":"Inheritance for multi-model use case"},{"location":"tutorial/inheritance/#defining-models","text":"To set the root model you have to set is_root = True in the inner Settings class. All the inherited documents (on any level) will be stored in the same collection. from typing import Optional , List from motor.motor_asyncio import AsyncIOMotorClient from pydantic import BaseModel from beanie import Document , Link , init_beanie class Vehicle ( Document ): \"\"\"Inheritance scheme bellow\"\"\" # Vehicle # / | \\ # / | \\ # Bicycle Bike Car # \\ # \\ # Bus # shared attribute for all children color : str class Settings : is_root = True class Fuelled ( BaseModel ): \"\"\"Just a mixin\"\"\" fuel : Optional [ str ] class Bicycle ( Vehicle ): \"\"\"Derived from Vehicle, will use its collection\"\"\" frame : int wheels : int class Bike ( Vehicle , Fuelled ): ... class Car ( Vehicle , Fuelled ): body : str class Bus ( Car , Fuelled ): \"\"\"Inheritance chain is Vehicle -> Car -> Bus, it is also stored in Vehicle collection\"\"\" seats : int class Owner ( Document ): vehicles : Optional [ List [ Link [ Vehicle ]]]","title":"Defining models"},{"location":"tutorial/inheritance/#inserts","text":"Inserts work the same way as usual client = AsyncIOMotorClient () await init_beanie ( client . test_db , document_models = [ Vehicle , Bicycle , Bike , Car , Bus ]) bike_1 = await Bike ( color = 'black' , fuel = 'gasoline' ) . insert () car_1 = await Car ( color = 'grey' , body = 'sedan' , fuel = 'gasoline' ) . insert () car_2 = await Car ( color = 'white' , body = 'crossover' , fuel = 'diesel' ) . insert () bus_1 = await Bus ( color = 'white' , seats = 80 , body = 'bus' , fuel = 'diesel' ) . insert () bus_2 = await Bus ( color = 'yellow' , seats = 26 , body = 'minibus' , fuel = 'diesel' ) . insert () owner = await Owner ( name = 'John' , vehicles = [ car_1 , car_2 , bus_1 ]) . insert ()","title":"Inserts"},{"location":"tutorial/inheritance/#find-operations","text":"With parameter with_children = True the find query results will contain all the children classes' objects. # this query returns vehicles of all types that have white color, becuase `with_children` is True white_vehicles = await Vehicle . find ( Vehicle . color == 'white' , with_children = True ) . to_list () # [ # Bicycle(..., color='white', frame=54, wheels=29), # Car(fuel='diesel', ..., color='white', body='crossover'), # Bus(fuel='diesel', ..., color='white', body='bus', seats=80) # ] If the search is based on a child, the query returns this child type and all sub-children (with parameter with_children=True ) cars_and_buses = await Car . find ( Car . fuel == 'diesel' , with_children = True ) . to_list () # [ # Car(fuel='diesel', ..., color='white', body='crossover'), # Bus(fuel='diesel', ..., color='white', body='bus', seats=80), # Bus(fuel='diesel', ..., color='yellow', body='minibus', seats=26) # ] If you need to return objects of the specific class only, you can use this class for finding: # however it is possible to limit by Vehicle type cars_only = await Car . find () . to_list () # [ # Car(fuel='gasoline', ..., color='grey', body='sedan'), # Car(fuel='diesel', ..., color='white', body='crossover') # ] To get a single Document it is not necessary to know the type. You can query using the parent class await Vehicle . get ( bus_2 . id , with_children = True ) # returns Bus instance: # Bus(fuel='diesel', ..., color='yellow', body='minibus', seats=26)","title":"Find operations"},{"location":"tutorial/inheritance/#relations","text":"Linked documents will be resolved into the respective classes owner = await Owner . get ( owner . id , fetch_links = True ) print ( owner . vehicles ) # [ # Car(fuel='diesel', ..., color='white', body='crossover'), # Bus(fuel='diesel', ..., color='white', body='bus', seats=80), # Car(fuel='gasoline', ..., color='grey', body='sedan') # ] The same result will be if the owner gets objects without fetching the links, and they will be fetched manually later","title":"Relations"},{"location":"tutorial/inheritance/#other","text":"All other operations work the same way as for simple Documents await Bike . find () . update ({ \"$set\" : { Bike . color : 'yellow' }}) await Car . find_one ( Car . body == 'sedan' )","title":"Other"},{"location":"tutorial/initialization/","text":"Beanie uses Motor as an async database engine. To initialize previously created documents, you should provide a Motor database instance and a list of your document models to the init_beanie(...) function, as it is shown in the example: from beanie import init_beanie , Document from motor.motor_asyncio import AsyncIOMotorClient class Sample ( Document ): name : str async def init (): # Create Motor client client = AsyncIOMotorClient ( \"mongodb://user:pass@host:27017\" ) # Initialize beanie with the Product document class and a database await init_beanie ( database = client . db_name , document_models = [ Sample ]) This creates the collection (if necessary) and sets up any indexes that are defined. init_beanie supports not only a list of classes as the document_models argument, but also strings with dot-separated paths: await init_beanie ( database = client . db_name , document_models = [ \"app.models.DemoDocument\" , ], ) Warning init_beanie supports the parameter named allow_index_dropping that will drop indexes from your collections. allow_index_dropping is by default set to False . If you set this to True , ensure that you are not managing your indexes in another manner. If you are, these will be deleted when setting allow_index_dropping=True .","title":"Initialization"},{"location":"tutorial/initialization/#warning","text":"init_beanie supports the parameter named allow_index_dropping that will drop indexes from your collections. allow_index_dropping is by default set to False . If you set this to True , ensure that you are not managing your indexes in another manner. If you are, these will be deleted when setting allow_index_dropping=True .","title":"Warning"},{"location":"tutorial/inserting-into-the-database/","text":"Insert the documents Beanie documents behave just like pydantic models (because they subclass pydantic.BaseModel ). Hence, a document can be created in a similar fashion to pydantic: from typing import Optional from pydantic import BaseModel from beanie import Document , Indexed class Category ( BaseModel ): name : str description : str class Product ( Document ): # This is the model name : str description : Optional [ str ] = None price : Indexed ( float ) category : Category class Settings : name = \"products\" chocolate = Category ( name = \"Chocolate\" , description = \"A preparation of roasted and ground cacao seeds.\" ) tonybar = Product ( name = \"Tony's\" , price = 5.95 , category = chocolate ) marsbar = Product ( name = \"Mars\" , price = 1 , category = chocolate ) This however does not save the documents to the database yet. Insert a single document To insert a document into the database, you can call either insert() or create() on it (they are synonyms): await tonybar . insert () await marsbar . create () # does exactly the same as insert() You can also call save() , which behaves in the same manner for new documents, but will also update existing documents. See the section on updating of this tutorial for more details. If you prefer, you can also call the insert_one class method: await Product . insert_one ( tonybar ) Inserting many documents To reduce the number of database queries, similarly typed documents should be inserted together by calling the class method insert_many : await Product . insert_many ([ tonybar , marsbar ])","title":"Inserting into the database"},{"location":"tutorial/inserting-into-the-database/#insert-the-documents","text":"Beanie documents behave just like pydantic models (because they subclass pydantic.BaseModel ). Hence, a document can be created in a similar fashion to pydantic: from typing import Optional from pydantic import BaseModel from beanie import Document , Indexed class Category ( BaseModel ): name : str description : str class Product ( Document ): # This is the model name : str description : Optional [ str ] = None price : Indexed ( float ) category : Category class Settings : name = \"products\" chocolate = Category ( name = \"Chocolate\" , description = \"A preparation of roasted and ground cacao seeds.\" ) tonybar = Product ( name = \"Tony's\" , price = 5.95 , category = chocolate ) marsbar = Product ( name = \"Mars\" , price = 1 , category = chocolate ) This however does not save the documents to the database yet.","title":"Insert the documents"},{"location":"tutorial/inserting-into-the-database/#insert-a-single-document","text":"To insert a document into the database, you can call either insert() or create() on it (they are synonyms): await tonybar . insert () await marsbar . create () # does exactly the same as insert() You can also call save() , which behaves in the same manner for new documents, but will also update existing documents. See the section on updating of this tutorial for more details. If you prefer, you can also call the insert_one class method: await Product . insert_one ( tonybar )","title":"Insert a single document"},{"location":"tutorial/inserting-into-the-database/#inserting-many-documents","text":"To reduce the number of database queries, similarly typed documents should be inserted together by calling the class method insert_many : await Product . insert_many ([ tonybar , marsbar ])","title":"Inserting many documents"},{"location":"tutorial/lazy-parsing/","text":"Using Lazy Parsing in Queries Lazy parsing allows you to skip the parsing and validation process for documents and instead call it on demand for each field separately. This can be useful for optimizing performance in certain scenarios. To use lazy parsing in your queries, you can pass the lazy_parse=True parameter to your find method. Here's an example of how to use lazy parsing in a find query: await Sample . find ( Sample . number == 10 , lazy_parse = True ) . to_list () By setting lazy_parse=True, the parsing and validation process will be skipped and be called on demand when the respective fields will be used. This can potentially improve the performance of your query by reducing the amount of processing required upfront. However, keep in mind that using lazy parsing may also introduce some additional overhead when accessing the fields later on.","title":"Lazy parsing"},{"location":"tutorial/lazy-parsing/#using-lazy-parsing-in-queries","text":"Lazy parsing allows you to skip the parsing and validation process for documents and instead call it on demand for each field separately. This can be useful for optimizing performance in certain scenarios. To use lazy parsing in your queries, you can pass the lazy_parse=True parameter to your find method. Here's an example of how to use lazy parsing in a find query: await Sample . find ( Sample . number == 10 , lazy_parse = True ) . to_list () By setting lazy_parse=True, the parsing and validation process will be skipped and be called on demand when the respective fields will be used. This can potentially improve the performance of your query by reducing the amount of processing required upfront. However, keep in mind that using lazy parsing may also introduce some additional overhead when accessing the fields later on.","title":"Using Lazy Parsing in Queries"},{"location":"tutorial/migrations/","text":"Attention! Migrations use transactions inside. They work only with MongoDB replica sets Create To create a new migration, run: beanie new-migration -n migration_name -p relative/path/to/migrations/directory/ It will create a file named *_migration_name.py in the directory relative/path/to/migrations/directory/ Migration file contains two classes: Forward and Backward . Each one contains instructions to roll migration respectively forward and backward. Run To roll one forward migration, run: beanie migrate -uri 'mongodb+srv://user:pass@host/db' -p relative/path/to/migrations/directory/ --distance 1 To roll all forward migrations, run: beanie migrate -uri 'mongodb+srv://user:pass@host/db' -p relative/path/to/migrations/directory/ To roll one backward migration, run: beanie migrate -uri 'mongodb+srv://user:pass@host/db' -p relative/path/to/migrations/directory/ --distance 1 --backward To roll all backward migrations, run: beanie migrate -uri 'mongodb+srv://user:pass@host/db' -p relative/path/to/migrations/directory/ --backward To show the help message with all the parameters and descriptions, run: beanie migrate --help Migration types Migration class contains instructions - decorated async functions. There are two types of instructions: Iterative migration - instruction that iterates over all the documents of the input_document collection and updates it. Most convenient to use, should be used in 99% cases. Free fall migrations - instruction where user can write any logic. Most flexible, but verbose. Iterative migrations To mark a function as iterative migration, @iterative_migration() decorator must be used. The function itself must accept typed input_document and output_document arguments. Like here: @iterative_migration () async def name_to_title ( self , input_document : OldNote , output_document : Note ): A simple example of field name changing There are the next models: class Tag ( BaseModel ): color : str name : str class OldNote ( Document ): name : str tag : Tag class Settings : name = \"notes\" class Note ( Document ): title : str tag : Tag class Settings : name = \"notes\" To migrate from OldNote to Note , file name has to be renamed to title . Forward migration: class Forward : @iterative_migration () async def name_to_title ( self , input_document : OldNote , output_document : Note ): output_document . title = input_document . name Backward migration: class Backward : @iterative_migration () async def title_to_name ( self , input_document : Note , output_document : OldNote ): output_document . name = input_document . title And a little more complex example: from pydantic.main import BaseModel from beanie import Document , iterative_migration class OldTag ( BaseModel ): color : str name : str class Tag ( BaseModel ): color : str title : str class OldNote ( Document ): title : str tag : OldTag class Settings : name = \"notes\" class Note ( Document ): title : str tag : Tag class Settings : name = \"notes\" class Forward : @iterative_migration () async def change_color ( self , input_document : OldNote , output_document : Note ): output_document . tag . title = input_document . tag . name class Backward : @iterative_migration () async def change_title ( self , input_document : Note , output_document : OldNote ): output_document . tag . name = input_document . tag . title All the examples of migrations can be found by link Free fall migrations It is a much more flexible migration type, which allows the implementation of any migration logic. But at the same time, it is more verbose. To mark function as a free fall migration, @free_fall_migration() decorator with the list of Document classes must be used. Function itself accepts session as an argument. It is used in order to roll back the migration in case something has gone wrong. To be able to roll back, please pass session to the Documents methods. Like here: @free_fall_migration ( document_models = [ OldNote , Note ]) async def name_to_title ( self , session ): async for old_note in OldNote . find_all (): new_note = Note ( id = old_note . id , title = old_note . name , tag = old_note . tag ) await new_note . replace ( session = session ) The same example as for the iterative migration, but with free fall migration type from pydantic.main import BaseModel from beanie import Document , free_fall_migration class Tag ( BaseModel ): color : str name : str class OldNote ( Document ): name : str tag : Tag class Settings : name = \"notes\" class Note ( Document ): title : str tag : Tag class Settings : name = \"notes\" class Forward : @free_fall_migration ( document_models = [ OldNote , Note ]) async def name_to_title ( self , session ): async for old_note in OldNote . find_all (): new_note = Note ( id = old_note . id , title = old_note . name , tag = old_note . tag ) await new_note . replace ( session = session ) class Backward : @free_fall_migration ( document_models = [ OldNote , Note ]) async def title_to_name ( self , session ): async for old_note in Note . find_all (): new_note = OldNote ( id = old_note . id , name = old_note . title , tag = old_note . tag ) await new_note . replace ( session = session ) All the examples of migrations can be found by link","title":"Migrations"},{"location":"tutorial/migrations/#attention","text":"Migrations use transactions inside. They work only with MongoDB replica sets","title":"Attention!"},{"location":"tutorial/migrations/#create","text":"To create a new migration, run: beanie new-migration -n migration_name -p relative/path/to/migrations/directory/ It will create a file named *_migration_name.py in the directory relative/path/to/migrations/directory/ Migration file contains two classes: Forward and Backward . Each one contains instructions to roll migration respectively forward and backward.","title":"Create"},{"location":"tutorial/migrations/#run","text":"To roll one forward migration, run: beanie migrate -uri 'mongodb+srv://user:pass@host/db' -p relative/path/to/migrations/directory/ --distance 1 To roll all forward migrations, run: beanie migrate -uri 'mongodb+srv://user:pass@host/db' -p relative/path/to/migrations/directory/ To roll one backward migration, run: beanie migrate -uri 'mongodb+srv://user:pass@host/db' -p relative/path/to/migrations/directory/ --distance 1 --backward To roll all backward migrations, run: beanie migrate -uri 'mongodb+srv://user:pass@host/db' -p relative/path/to/migrations/directory/ --backward To show the help message with all the parameters and descriptions, run: beanie migrate --help","title":"Run"},{"location":"tutorial/migrations/#migration-types","text":"Migration class contains instructions - decorated async functions. There are two types of instructions: Iterative migration - instruction that iterates over all the documents of the input_document collection and updates it. Most convenient to use, should be used in 99% cases. Free fall migrations - instruction where user can write any logic. Most flexible, but verbose.","title":"Migration types"},{"location":"tutorial/migrations/#iterative-migrations","text":"To mark a function as iterative migration, @iterative_migration() decorator must be used. The function itself must accept typed input_document and output_document arguments. Like here: @iterative_migration () async def name_to_title ( self , input_document : OldNote , output_document : Note ):","title":"Iterative migrations"},{"location":"tutorial/migrations/#a-simple-example-of-field-name-changing","text":"There are the next models: class Tag ( BaseModel ): color : str name : str class OldNote ( Document ): name : str tag : Tag class Settings : name = \"notes\" class Note ( Document ): title : str tag : Tag class Settings : name = \"notes\" To migrate from OldNote to Note , file name has to be renamed to title . Forward migration: class Forward : @iterative_migration () async def name_to_title ( self , input_document : OldNote , output_document : Note ): output_document . title = input_document . name Backward migration: class Backward : @iterative_migration () async def title_to_name ( self , input_document : Note , output_document : OldNote ): output_document . name = input_document . title And a little more complex example: from pydantic.main import BaseModel from beanie import Document , iterative_migration class OldTag ( BaseModel ): color : str name : str class Tag ( BaseModel ): color : str title : str class OldNote ( Document ): title : str tag : OldTag class Settings : name = \"notes\" class Note ( Document ): title : str tag : Tag class Settings : name = \"notes\" class Forward : @iterative_migration () async def change_color ( self , input_document : OldNote , output_document : Note ): output_document . tag . title = input_document . tag . name class Backward : @iterative_migration () async def change_title ( self , input_document : Note , output_document : OldNote ): output_document . tag . name = input_document . tag . title All the examples of migrations can be found by link","title":"A simple example of field name changing"},{"location":"tutorial/migrations/#free-fall-migrations","text":"It is a much more flexible migration type, which allows the implementation of any migration logic. But at the same time, it is more verbose. To mark function as a free fall migration, @free_fall_migration() decorator with the list of Document classes must be used. Function itself accepts session as an argument. It is used in order to roll back the migration in case something has gone wrong. To be able to roll back, please pass session to the Documents methods. Like here: @free_fall_migration ( document_models = [ OldNote , Note ]) async def name_to_title ( self , session ): async for old_note in OldNote . find_all (): new_note = Note ( id = old_note . id , title = old_note . name , tag = old_note . tag ) await new_note . replace ( session = session )","title":"Free fall migrations"},{"location":"tutorial/migrations/#the-same-example-as-for-the-iterative-migration-but-with-free-fall-migration-type","text":"from pydantic.main import BaseModel from beanie import Document , free_fall_migration class Tag ( BaseModel ): color : str name : str class OldNote ( Document ): name : str tag : Tag class Settings : name = \"notes\" class Note ( Document ): title : str tag : Tag class Settings : name = \"notes\" class Forward : @free_fall_migration ( document_models = [ OldNote , Note ]) async def name_to_title ( self , session ): async for old_note in OldNote . find_all (): new_note = Note ( id = old_note . id , title = old_note . name , tag = old_note . tag ) await new_note . replace ( session = session ) class Backward : @free_fall_migration ( document_models = [ OldNote , Note ]) async def title_to_name ( self , session ): async for old_note in Note . find_all (): new_note = OldNote ( id = old_note . id , name = old_note . title , tag = old_note . tag ) await new_note . replace ( session = session ) All the examples of migrations can be found by link","title":"The same example as for the iterative migration, but with free fall migration type"},{"location":"tutorial/multi-model-pattern/","text":"Multi-model pattern Documents with different schemas could be stored in a single collection and managed correctly. UnionDoc class is used for this. It supports find and aggregate methods. For find , it will fetch all the found documents into the respective Document classes. Documents that have union_doc in their settings can still be used in find and other queries. Queries of one such class will not see the data of others. Example Create documents: from beanie import Document , UnionDoc class Parent ( UnionDoc ): # Union class Settings : name = \"union_doc_collection\" # Collection name class One ( Document ): int_field : int = 0 shared : int = 0 class Settings : union_doc = Parent class Two ( Document ): str_field : str = \"test\" shared : int = 0 class Settings : union_doc = Parent The schemas could be incompatible. Insert a document await One () . insert () await One () . insert () await One () . insert () await Two () . insert () Find all the documents of the first type: docs = await One . all () . to_list () print ( len ( docs )) >> 3 # It found only documents of class One Of the second type: docs = await Two . all () . to_list () print ( len ( docs )) >> 1 # It found only documents of class One Of both: docs = await Parent . all () . to_list () print ( len ( docs )) >> 4 # instances of the both classes will be in the output here Aggregations will work separately for these two document classes too.","title":"Multi-model pattern"},{"location":"tutorial/multi-model-pattern/#multi-model-pattern","text":"Documents with different schemas could be stored in a single collection and managed correctly. UnionDoc class is used for this. It supports find and aggregate methods. For find , it will fetch all the found documents into the respective Document classes. Documents that have union_doc in their settings can still be used in find and other queries. Queries of one such class will not see the data of others.","title":"Multi-model pattern"},{"location":"tutorial/multi-model-pattern/#example","text":"Create documents: from beanie import Document , UnionDoc class Parent ( UnionDoc ): # Union class Settings : name = \"union_doc_collection\" # Collection name class One ( Document ): int_field : int = 0 shared : int = 0 class Settings : union_doc = Parent class Two ( Document ): str_field : str = \"test\" shared : int = 0 class Settings : union_doc = Parent The schemas could be incompatible. Insert a document await One () . insert () await One () . insert () await One () . insert () await Two () . insert () Find all the documents of the first type: docs = await One . all () . to_list () print ( len ( docs )) >> 3 # It found only documents of class One Of the second type: docs = await Two . all () . to_list () print ( len ( docs )) >> 1 # It found only documents of class One Of both: docs = await Parent . all () . to_list () print ( len ( docs )) >> 4 # instances of the both classes will be in the output here Aggregations will work separately for these two document classes too.","title":"Example"},{"location":"tutorial/on-save-validation/","text":"On save validation Pydantic has a very useful config to validate values on assignment - validate_assignment = True . But, unfortunately, this is an expensive operation and doesn't fit some use cases. You can validate all the values before saving the document ( insert , replace , save , save_changes ) with beanie config validate_on_save instead. This feature must be turned on in the Settings inner class explicitly: class Sample ( Document ): num : int name : str class Settings : validate_on_save = True If any field has a wrong value, it will raise an error on write operations ( insert , replace , save , save_changes ). sample = Sample . find_one ( Sample . name == \"Test\" ) sample . num = \"wrong value type\" # Next call will raise an error await sample . replace ()","title":"On save validation"},{"location":"tutorial/on-save-validation/#on-save-validation","text":"Pydantic has a very useful config to validate values on assignment - validate_assignment = True . But, unfortunately, this is an expensive operation and doesn't fit some use cases. You can validate all the values before saving the document ( insert , replace , save , save_changes ) with beanie config validate_on_save instead. This feature must be turned on in the Settings inner class explicitly: class Sample ( Document ): num : int name : str class Settings : validate_on_save = True If any field has a wrong value, it will raise an error on write operations ( insert , replace , save , save_changes ). sample = Sample . find_one ( Sample . name == \"Test\" ) sample . num = \"wrong value type\" # Next call will raise an error await sample . replace ()","title":"On save validation"},{"location":"tutorial/relations/","text":"Relations The document can contain links to other documents in their fields. Only top-level fields are fully supported for now. The following field types are supported: Link[...] Optional[Link[...]] List[Link[...]] Optional[List[Link[...]]] Direct link to the document: from beanie import Document , Link class Door ( Document ): height : int = 2 width : int = 1 class House ( Document ): name : str door : Link [ Door ] Optional direct link to the document: from typing import Optional from beanie import Document , Link class Door ( Document ): height : int = 2 width : int = 1 class House ( Document ): name : str door : Optional [ Link [ Door ]] List of the links: from typing import List from beanie import Document , Link class Window ( Document ): x : int = 10 y : int = 10 class House ( Document ): name : str door : Link [ Door ] windows : List [ Link [ Window ]] Optional list of the links: from typing import List , Optional from beanie import Document , Link class Window ( Document ): x : int = 10 y : int = 10 class Yard ( Document ): v : int = 10 y : int = 10 class House ( Document ): name : str door : Link [ Door ] windows : List [ Link [ Window ]] yards : Optional [ List [ Link [ Yard ]]] Other link patterns are not supported at this moment. If you need something more specific for your use-case, please open an issue on the GitHub page - https://github.com/roman-right/beanie Write The following write methods support relations: insert(...) replace(...) save(...) To apply a write method to the linked documents, you should pass the respective link_rule argument house . windows = [ Window ( x = 100 , y = 100 )] house . name = \"NEW NAME\" # The next call will insert a new window object and replace the house instance with updated data await house . save ( link_rule = WriteRules . WRITE ) # `insert` and `replace` methods will work the same way Otherwise, Beanie can ignore internal links with the link_rule parameter WriteRules.DO_NOTHING house . door . height = 3 house . name = \"NEW NAME\" # The next call will just replace the house instance with new data, but the linked door object will not be synced await house . replace ( link_rule = WriteRules . DO_NOTHING ) # `insert` and `save` methods will work the same way Fetch Prefetch You can fetch linked documents on the find query step using the fetch_links parameter houses = await House . find ( House . name == \"test\" , fetch_links = True ) . to_list () Supported find methods: - find - find_one - get Beanie uses the single aggregation query under the hood to fetch all the linked documents. This operation is very effective. If a direct link is referred to a non-existent document, after fetching it will remain the object of the Link class. Fetching will ignore non-existent documents for the list of links fields. Search by linked documents fields If the fetch_links parameter is set to True , search by linked documents fields is available. By field of the direct link: houses = await House . find ( House . door . height == 2 , fetch_links = True ) . to_list () By list of links: houses = await House . find ( House . windows . x > 10 , fetch_links = True ) . to_list () Search by id of the linked documents works using the following syntax: houses = await House . find ( House . door . id == \"DOOR_ID_HERE\" ) . to_list () It works the same way with fetch_links equal to True and False and for find_many and find_one methods. On-demand fetch If you don't use prefetching, linked documents will be presented as objects of the Link class. You can fetch them manually afterwards. To fetch all the linked documents, you can use the fetch_all_links method await house . fetch_all_links () It will fetch all the linked documents and replace Link objects with them. Otherwise, you can fetch a single field: await house . fetch_link ( House . door ) This will fetch the Door object and put it into the door field of the house object. Delete Delete method works the same way as write operations, but it uses other rules. To delete all the links on the document deletion, you should use the DeleteRules.DELETE_LINKS value for the link_rule parameter: await house . delete ( link_rule = DeleteRules . DELETE_LINKS ) To keep linked documents, you can use the DO_NOTHING rule: await house . delete ( link_rule = DeleteRules . DO_NOTHING )","title":"Relations"},{"location":"tutorial/relations/#relations","text":"The document can contain links to other documents in their fields. Only top-level fields are fully supported for now. The following field types are supported: Link[...] Optional[Link[...]] List[Link[...]] Optional[List[Link[...]]] Direct link to the document: from beanie import Document , Link class Door ( Document ): height : int = 2 width : int = 1 class House ( Document ): name : str door : Link [ Door ] Optional direct link to the document: from typing import Optional from beanie import Document , Link class Door ( Document ): height : int = 2 width : int = 1 class House ( Document ): name : str door : Optional [ Link [ Door ]] List of the links: from typing import List from beanie import Document , Link class Window ( Document ): x : int = 10 y : int = 10 class House ( Document ): name : str door : Link [ Door ] windows : List [ Link [ Window ]] Optional list of the links: from typing import List , Optional from beanie import Document , Link class Window ( Document ): x : int = 10 y : int = 10 class Yard ( Document ): v : int = 10 y : int = 10 class House ( Document ): name : str door : Link [ Door ] windows : List [ Link [ Window ]] yards : Optional [ List [ Link [ Yard ]]] Other link patterns are not supported at this moment. If you need something more specific for your use-case, please open an issue on the GitHub page - https://github.com/roman-right/beanie","title":"Relations"},{"location":"tutorial/relations/#write","text":"The following write methods support relations: insert(...) replace(...) save(...) To apply a write method to the linked documents, you should pass the respective link_rule argument house . windows = [ Window ( x = 100 , y = 100 )] house . name = \"NEW NAME\" # The next call will insert a new window object and replace the house instance with updated data await house . save ( link_rule = WriteRules . WRITE ) # `insert` and `replace` methods will work the same way Otherwise, Beanie can ignore internal links with the link_rule parameter WriteRules.DO_NOTHING house . door . height = 3 house . name = \"NEW NAME\" # The next call will just replace the house instance with new data, but the linked door object will not be synced await house . replace ( link_rule = WriteRules . DO_NOTHING ) # `insert` and `save` methods will work the same way","title":"Write"},{"location":"tutorial/relations/#fetch","text":"","title":"Fetch"},{"location":"tutorial/relations/#prefetch","text":"You can fetch linked documents on the find query step using the fetch_links parameter houses = await House . find ( House . name == \"test\" , fetch_links = True ) . to_list () Supported find methods: - find - find_one - get Beanie uses the single aggregation query under the hood to fetch all the linked documents. This operation is very effective. If a direct link is referred to a non-existent document, after fetching it will remain the object of the Link class. Fetching will ignore non-existent documents for the list of links fields.","title":"Prefetch"},{"location":"tutorial/relations/#search-by-linked-documents-fields","text":"If the fetch_links parameter is set to True , search by linked documents fields is available. By field of the direct link: houses = await House . find ( House . door . height == 2 , fetch_links = True ) . to_list () By list of links: houses = await House . find ( House . windows . x > 10 , fetch_links = True ) . to_list () Search by id of the linked documents works using the following syntax: houses = await House . find ( House . door . id == \"DOOR_ID_HERE\" ) . to_list () It works the same way with fetch_links equal to True and False and for find_many and find_one methods.","title":"Search by linked documents fields"},{"location":"tutorial/relations/#on-demand-fetch","text":"If you don't use prefetching, linked documents will be presented as objects of the Link class. You can fetch them manually afterwards. To fetch all the linked documents, you can use the fetch_all_links method await house . fetch_all_links () It will fetch all the linked documents and replace Link objects with them. Otherwise, you can fetch a single field: await house . fetch_link ( House . door ) This will fetch the Door object and put it into the door field of the house object.","title":"On-demand fetch"},{"location":"tutorial/relations/#delete","text":"Delete method works the same way as write operations, but it uses other rules. To delete all the links on the document deletion, you should use the DeleteRules.DELETE_LINKS value for the link_rule parameter: await house . delete ( link_rule = DeleteRules . DELETE_LINKS ) To keep linked documents, you can use the DO_NOTHING rule: await house . delete ( link_rule = DeleteRules . DO_NOTHING )","title":"Delete"},{"location":"tutorial/revision/","text":"Revision This feature helps with concurrent operations. It stores revision_id together with the document and changes it on each document update. If the application with an older local copy of the document tries to change it, an exception will be raised. Only when the local copy is synced with the database, the application will be allowed to change the data. This helps to avoid data losses. This feature must be explicitly turned on in the Settings inner class: class Sample ( Document ): num : int name : str class Settings : use_revision = True Any changing operation will check if the local copy of the document has the up-to-date revision_id value: s = await Sample . find_one ( Sample . name = \"TestName\" ) s . num = 10 # If a concurrent process already changed the doc, the next operation will raise an error await s . replace () If you want to ignore revision and apply all the changes even if the local copy is outdated, you can use the ignore_revision parameter: await s . replace ( ignore_revision = True )","title":"Revision"},{"location":"tutorial/revision/#revision","text":"This feature helps with concurrent operations. It stores revision_id together with the document and changes it on each document update. If the application with an older local copy of the document tries to change it, an exception will be raised. Only when the local copy is synced with the database, the application will be allowed to change the data. This helps to avoid data losses. This feature must be explicitly turned on in the Settings inner class: class Sample ( Document ): num : int name : str class Settings : use_revision = True Any changing operation will check if the local copy of the document has the up-to-date revision_id value: s = await Sample . find_one ( Sample . name = \"TestName\" ) s . num = 10 # If a concurrent process already changed the doc, the next operation will raise an error await s . replace () If you want to ignore revision and apply all the changes even if the local copy is outdated, you can use the ignore_revision parameter: await s . replace ( ignore_revision = True )","title":"Revision"},{"location":"tutorial/state-management/","text":"State Management Beanie can keep the document state synced with the database in order to find local changes and save only them. This feature must be explicitly turned on in the Settings inner class: class Sample ( Document ): num : int name : str class Settings : use_state_management = True Beanie keeps the current changes (not yet saved in the database) by default (with use_state_management = True ), AND the previous changes (saved to the database) with state_management_save_previous = True . class Sample ( Document ): num : int name : str class Settings : use_state_management = True state_management_save_previous = True Every new save override the previous changes and clears the current changes. Saving changes To save only changed values, the save_changes() method should be used. s = await Sample . find_one ( Sample . name == \"Test\" ) s . num = 100 await s . save_changes () The save_changes() method can only be used with already inserted documents. Interacting with changes Beanie exposes several methods that can be used to interact with the saved changes: s = await Sample . find_one ( Sample . name == \"Test\" ) s . is_changed == False s . get_changes == {} s . num = 200 s . is_changed == True s . get_changes () == { \"num\" : 200 } s . rollback () s . is_changed == False s . get_changes () == {} And similar methods can be used with the previous changes that have been saved in the database if state_management_save_previous is set to True : s = await Sample . find_one ( Sample . name == \"Test\" ) s . num = 200 await s . save_changes () s . has_changed == True s . get_previous_changes () == { \"num\" : 200 } s . get_changes () == {} Options By default, state management will merge the changes made to nested objects, which is fine for most cases as it is non-destructive and does not re-assign the whole object if only one of its attributes changed: from typing import Dict class Item ( Document ): name : str attributes : Dict [ str , float ] class Settings : use_state_management = True i = Item ( name = \"Test\" , attributes = { \"attribute_1\" : 1.0 , \"attribute_2\" : 2.0 }) await i . insert () i . attributes = { \"attribute_1\" : 1.0 } await i . save_changes () # Changes will consist of: {\"attributes.attribute_1\": 1.0} # Keeping attribute_2 However, there are some cases where you would want to replace the whole object when one of its attributes changed. You can enable the state_management_replace_objects attribute in your model's Settings inner class: from typing import Dict class Item ( Document ): name : str attributes : Dict [ str , float ] class Settings : use_state_management = True state_management_replace_objects = True With this setting activated, the whole object will be overridden when one attribute of the nested object is changed: i = Item ( name = \"Test\" , attributes = { \"attribute_1\" : 1.0 , \"attribute_2\" : 2.0 }) await i . insert () i . attributes . attribute_1 = 1.0 await i . save_changes () # Changes will consist of: {\"attributes.attribute_1\": 1.0, \"attributes.attribute_2\": 2.0} # Keeping attribute_2 When the whole object is assigned, the whole nested object will be overridden: i = Item ( name = \"Test\" , attributes = { \"attribute_1\" : 1.0 , \"attribute_2\" : 2.0 }) await i . insert () i . attributes = { \"attribute_1\" : 1.0 } await i . save_changes () # Changes will consist of: {\"attributes\": {\"attribute_1\": 1.0}} # Removing attribute_2","title":"State Management"},{"location":"tutorial/state-management/#state-management","text":"Beanie can keep the document state synced with the database in order to find local changes and save only them. This feature must be explicitly turned on in the Settings inner class: class Sample ( Document ): num : int name : str class Settings : use_state_management = True Beanie keeps the current changes (not yet saved in the database) by default (with use_state_management = True ), AND the previous changes (saved to the database) with state_management_save_previous = True . class Sample ( Document ): num : int name : str class Settings : use_state_management = True state_management_save_previous = True Every new save override the previous changes and clears the current changes.","title":"State Management"},{"location":"tutorial/state-management/#saving-changes","text":"To save only changed values, the save_changes() method should be used. s = await Sample . find_one ( Sample . name == \"Test\" ) s . num = 100 await s . save_changes () The save_changes() method can only be used with already inserted documents.","title":"Saving changes"},{"location":"tutorial/state-management/#interacting-with-changes","text":"Beanie exposes several methods that can be used to interact with the saved changes: s = await Sample . find_one ( Sample . name == \"Test\" ) s . is_changed == False s . get_changes == {} s . num = 200 s . is_changed == True s . get_changes () == { \"num\" : 200 } s . rollback () s . is_changed == False s . get_changes () == {} And similar methods can be used with the previous changes that have been saved in the database if state_management_save_previous is set to True : s = await Sample . find_one ( Sample . name == \"Test\" ) s . num = 200 await s . save_changes () s . has_changed == True s . get_previous_changes () == { \"num\" : 200 } s . get_changes () == {}","title":"Interacting with changes"},{"location":"tutorial/state-management/#options","text":"By default, state management will merge the changes made to nested objects, which is fine for most cases as it is non-destructive and does not re-assign the whole object if only one of its attributes changed: from typing import Dict class Item ( Document ): name : str attributes : Dict [ str , float ] class Settings : use_state_management = True i = Item ( name = \"Test\" , attributes = { \"attribute_1\" : 1.0 , \"attribute_2\" : 2.0 }) await i . insert () i . attributes = { \"attribute_1\" : 1.0 } await i . save_changes () # Changes will consist of: {\"attributes.attribute_1\": 1.0} # Keeping attribute_2 However, there are some cases where you would want to replace the whole object when one of its attributes changed. You can enable the state_management_replace_objects attribute in your model's Settings inner class: from typing import Dict class Item ( Document ): name : str attributes : Dict [ str , float ] class Settings : use_state_management = True state_management_replace_objects = True With this setting activated, the whole object will be overridden when one attribute of the nested object is changed: i = Item ( name = \"Test\" , attributes = { \"attribute_1\" : 1.0 , \"attribute_2\" : 2.0 }) await i . insert () i . attributes . attribute_1 = 1.0 await i . save_changes () # Changes will consist of: {\"attributes.attribute_1\": 1.0, \"attributes.attribute_2\": 2.0} # Keeping attribute_2 When the whole object is assigned, the whole nested object will be overridden: i = Item ( name = \"Test\" , attributes = { \"attribute_1\" : 1.0 , \"attribute_2\" : 2.0 }) await i . insert () i . attributes = { \"attribute_1\" : 1.0 } await i . save_changes () # Changes will consist of: {\"attributes\": {\"attribute_1\": 1.0}} # Removing attribute_2","title":"Options"},{"location":"tutorial/time-series/","text":"Time series You can set up a timeseries collection using the inner Settings class. Be aware, timeseries collections a supported by MongoDB 5.0 and higher only. from datetime import datetime from beanie import Document , TimeSeriesConfig , Granularity from pydantic import Field class Sample ( Document ): ts : datetime = Field ( default_factory = datetime . now ) meta : str class Settings : timeseries = TimeSeriesConfig ( time_field = \"ts\" , # Required meta_field = \"meta\" , # Optional granularity = Granularity . hours , # Optional expire_after_seconds = 2 # Optional ) TimeSeriesConfig fields reflect the respective parameters of the MongoDB timeseries creation function. MongoDB documentation: https://docs.mongodb.com/manual/core/timeseries-collections/","title":"Time Series"},{"location":"tutorial/time-series/#time-series","text":"You can set up a timeseries collection using the inner Settings class. Be aware, timeseries collections a supported by MongoDB 5.0 and higher only. from datetime import datetime from beanie import Document , TimeSeriesConfig , Granularity from pydantic import Field class Sample ( Document ): ts : datetime = Field ( default_factory = datetime . now ) meta : str class Settings : timeseries = TimeSeriesConfig ( time_field = \"ts\" , # Required meta_field = \"meta\" , # Optional granularity = Granularity . hours , # Optional expire_after_seconds = 2 # Optional ) TimeSeriesConfig fields reflect the respective parameters of the MongoDB timeseries creation function. MongoDB documentation: https://docs.mongodb.com/manual/core/timeseries-collections/","title":"Time series"},{"location":"tutorial/updating-%26-deleting/","text":"Updating & Deleting Now that we know how to find documents, how do we change them or delete them? Saving changes to existing documents The easiest way to change a document in the database is to use either the replace or save method on an altered document. These methods both write the document to the database, but replace will raise an exception when the document does not exist yet, while save will insert the document. Using save() method: bar = await Product . find_one ( Product . name == \"Mars\" ) bar . price = 10 await bar . save () Otherwise, use the replace() method, which throws: - a ValueError if the document does not have an id yet, or - a beanie.exceptions.DocumentNotFound if it does, but the id is not present in the collection bar . price = 10 try : await bar . replace () except ( ValueError , beanie . exceptions . DocumentNotFound ): print ( \"Can't replace a non existing document\" ) Note that these methods require multiple queries to the database and replace the entire document with the new version. A more tailored solution can often be created by applying update queries directly on the database level. Update queries Update queries can be performed on the result of a find or find_one query, or on a document that was returned from an earlier query. Simpler updates can be performed using the set , inc , and current_date methods: bar = await Product . find_one ( Product . name == \"Mars\" ) await bar . set ({ Product . name : \"Gold bar\" }) bar = await Product . find_all ( Product . price > .5 ) . inc ({ Product . price : 1 }) More complex update operations can be performed by calling update() with an update operator, similar to find queries: await Product . find_one ( Product . name == \"Tony's\" ) . update ( Set ({ Product . price : 3.33 })) The whole list of the update query operators can be found here . Native MongoDB syntax is also supported: await Product . find_one ( Product . name == \"Tony's\" ) . update ({ \"$set\" : { Product . price : 3.33 }}) Upsert To insert a document when no documents are matched against the search criteria, the upsert method can be used: await Product . find_one ( Product . name == \"Tony's\" ) . upsert ( Set ({ Product . price : 3.33 }), on_insert = Product ( name = \"Tony's\" , price = 3.33 , category = chocolate ) ) Deleting documents Deleting objects works just like updating them, you simply call delete() on the found documents: bar = await Product . find_one ( Product . name == \"Milka\" ) await bar . delete () await Product . find_one ( Product . name == \"Milka\" ) . delete () await Product . find ( Product . category . name == \"Chocolate\" ) . delete ()","title":"Updating & Deleting"},{"location":"tutorial/updating-%26-deleting/#updating-deleting","text":"Now that we know how to find documents, how do we change them or delete them?","title":"Updating &amp; Deleting"},{"location":"tutorial/updating-%26-deleting/#saving-changes-to-existing-documents","text":"The easiest way to change a document in the database is to use either the replace or save method on an altered document. These methods both write the document to the database, but replace will raise an exception when the document does not exist yet, while save will insert the document. Using save() method: bar = await Product . find_one ( Product . name == \"Mars\" ) bar . price = 10 await bar . save () Otherwise, use the replace() method, which throws: - a ValueError if the document does not have an id yet, or - a beanie.exceptions.DocumentNotFound if it does, but the id is not present in the collection bar . price = 10 try : await bar . replace () except ( ValueError , beanie . exceptions . DocumentNotFound ): print ( \"Can't replace a non existing document\" ) Note that these methods require multiple queries to the database and replace the entire document with the new version. A more tailored solution can often be created by applying update queries directly on the database level.","title":"Saving changes to existing documents"},{"location":"tutorial/updating-%26-deleting/#update-queries","text":"Update queries can be performed on the result of a find or find_one query, or on a document that was returned from an earlier query. Simpler updates can be performed using the set , inc , and current_date methods: bar = await Product . find_one ( Product . name == \"Mars\" ) await bar . set ({ Product . name : \"Gold bar\" }) bar = await Product . find_all ( Product . price > .5 ) . inc ({ Product . price : 1 }) More complex update operations can be performed by calling update() with an update operator, similar to find queries: await Product . find_one ( Product . name == \"Tony's\" ) . update ( Set ({ Product . price : 3.33 })) The whole list of the update query operators can be found here . Native MongoDB syntax is also supported: await Product . find_one ( Product . name == \"Tony's\" ) . update ({ \"$set\" : { Product . price : 3.33 }})","title":"Update queries"},{"location":"tutorial/updating-%26-deleting/#upsert","text":"To insert a document when no documents are matched against the search criteria, the upsert method can be used: await Product . find_one ( Product . name == \"Tony's\" ) . upsert ( Set ({ Product . price : 3.33 }), on_insert = Product ( name = \"Tony's\" , price = 3.33 , category = chocolate ) )","title":"Upsert"},{"location":"tutorial/updating-%26-deleting/#deleting-documents","text":"Deleting objects works just like updating them, you simply call delete() on the found documents: bar = await Product . find_one ( Product . name == \"Milka\" ) await bar . delete () await Product . find_one ( Product . name == \"Milka\" ) . delete () await Product . find ( Product . category . name == \"Chocolate\" ) . delete ()","title":"Deleting documents"},{"location":"tutorial/views/","text":"Views Virtual views are aggregation pipelines stored in MongoDB that act as collections for reading operations. You can use the View class the same way as Document for find and aggregate operations. Here are some examples. Create a view: from pydantic import Field from beanie import Document , View class Bike ( Document ): type : str frame_size : int is_new : bool class Metrics ( View ): type : str = Field ( alias = \"_id\" ) number : int new : int class Settings : source = Bike pipeline = [ { \"$group\" : { \"_id\" : \"$type\" , \"number\" : { \"$sum\" : 1 }, \"new\" : { \"$sum\" : { \"$cond\" : [ \"$is_new\" , 1 , 0 ]}} } }, ] Initialize Beanie: from motor.motor_asyncio import AsyncIOMotorClient from beanie import init_beanie async def main (): uri = \"mongodb://beanie:beanie@localhost:27017\" client = AsyncIOMotorClient ( uri ) db = client . bikes await init_beanie ( database = db , document_models = [ Bike , Metrics ], recreate_views = True , ) Create bikes: await Bike ( type = \"Mountain\" , frame_size = 54 , is_new = True ) . insert () await Bike ( type = \"Mountain\" , frame_size = 60 , is_new = False ) . insert () await Bike ( type = \"Road\" , frame_size = 52 , is_new = True ) . insert () await Bike ( type = \"Road\" , frame_size = 54 , is_new = True ) . insert () await Bike ( type = \"Road\" , frame_size = 58 , is_new = False ) . insert () Find metrics for type == \"Road\" results = await Metrics . find ( Metrics . type == \"Road\" ) . to_list () print ( results ) >> [ Metrics ( type = 'Road' , number = 3 , new = 2 )] Aggregate over metrics to get the count of all the new bikes: results = await Metrics . aggregate ([{ \"$group\" : { \"_id\" : None , \"new_total\" : { \"$sum\" : \"$new\" } } }]) . to_list () print ( results ) >> [{ '_id' : None , 'new_total' : 3 }] A better result can be achieved by using find query aggregation syntactic sugar: results = await Metrics . all () . sum ( Metrics . new ) print ( results ) >> 3","title":"Views"},{"location":"tutorial/views/#views","text":"Virtual views are aggregation pipelines stored in MongoDB that act as collections for reading operations. You can use the View class the same way as Document for find and aggregate operations.","title":"Views"},{"location":"tutorial/views/#here-are-some-examples","text":"Create a view: from pydantic import Field from beanie import Document , View class Bike ( Document ): type : str frame_size : int is_new : bool class Metrics ( View ): type : str = Field ( alias = \"_id\" ) number : int new : int class Settings : source = Bike pipeline = [ { \"$group\" : { \"_id\" : \"$type\" , \"number\" : { \"$sum\" : 1 }, \"new\" : { \"$sum\" : { \"$cond\" : [ \"$is_new\" , 1 , 0 ]}} } }, ] Initialize Beanie: from motor.motor_asyncio import AsyncIOMotorClient from beanie import init_beanie async def main (): uri = \"mongodb://beanie:beanie@localhost:27017\" client = AsyncIOMotorClient ( uri ) db = client . bikes await init_beanie ( database = db , document_models = [ Bike , Metrics ], recreate_views = True , ) Create bikes: await Bike ( type = \"Mountain\" , frame_size = 54 , is_new = True ) . insert () await Bike ( type = \"Mountain\" , frame_size = 60 , is_new = False ) . insert () await Bike ( type = \"Road\" , frame_size = 52 , is_new = True ) . insert () await Bike ( type = \"Road\" , frame_size = 54 , is_new = True ) . insert () await Bike ( type = \"Road\" , frame_size = 58 , is_new = False ) . insert () Find metrics for type == \"Road\" results = await Metrics . find ( Metrics . type == \"Road\" ) . to_list () print ( results ) >> [ Metrics ( type = 'Road' , number = 3 , new = 2 )] Aggregate over metrics to get the count of all the new bikes: results = await Metrics . aggregate ([{ \"$group\" : { \"_id\" : None , \"new_total\" : { \"$sum\" : \"$new\" } } }]) . to_list () print ( results ) >> [{ '_id' : None , 'new_total' : 3 }] A better result can be achieved by using find query aggregation syntactic sugar: results = await Metrics . all () . sum ( Metrics . new ) print ( results ) >> 3","title":"Here are some examples."}]}